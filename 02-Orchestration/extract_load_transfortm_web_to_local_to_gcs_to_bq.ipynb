{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from prefect import flow, task\n",
    "from prefect_gcp.cloud_storage import GcsBucket\n",
    "from prefect_gcp import GcpCredentials\n",
    "import io\n",
    "import os\n",
    "import requests\n",
    "import calendar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task(retries=3)\n",
    "def extract_load_web_data(year:int , month:int,file_name) -> None:\n",
    "    request_url =f\"https://use-land-property-data.service.gov.uk/datasets/td/download/history/{calendar.month_name[month]}%20{year}/{file_name}.csv\"\n",
    "    r = requests.get(request_url)\n",
    "    url_content=r.content\n",
    "    csv_file = open(f'{file_name}.csv', 'wb')\n",
    "    csv_file.write(url_content)\n",
    "    csv_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def load_csv_data (file_name: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(f\"{file_name}.csv\", sep=',', header=4, index_col=False)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def clean_local_data(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\" We need to add a date column for each DataFrame \"\"\"\n",
    "    new_df = df[df[\"Account Customer\"].str.contains(\"Total\")==False]\n",
    "    \"\"\" We are dropping the \"Total\" Column from the Dataframe \"\"\"\n",
    "    new_df = new_df.drop([\"Total\"], axis=1)\n",
    "    new_df.columns = new_df.columns.str.replace(\"[( )]\", \"_\")\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def transform_data(df: pd.DataFrame, year, month) -> None:\n",
    "    df[\"date_added\"] = f\"{year}-{month:02}-01\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def save_transformed_data(df: pd.DataFrame, file_name) -> None:\n",
    "    df.to_parquet(f\"{file_name}.parquet\", compression=\"gzip\", index=False)\n",
    "    df = pd.read_parquet(f\"{file_name}.parquet\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def write_gcs(file_name: str, path_gcp) -> None:\n",
    "    \"\"\"Upload local parquet FIle \"\"\"\n",
    "    gcp_cloud_storage_bucket_block = GcsBucket.load(\"de-gcp-bucket\")\n",
    "    gcp_cloud_storage_bucket_block.upload_from_path(\n",
    "        from_path = f\"{file_name}.parquet\",\n",
    "        to_path=f\"{path_gcp}/{file_name}\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def write_bq(df: pd.DataFrame) -> None:\n",
    "    \"\"\"Write DataFrame to BigQuery\"\"\"\n",
    "    gcp_credentials_block = GcpCredentials.load(\"de-gcp-cred\")\n",
    "    df.to_gbq(\n",
    "        destination_table=\"de_data_warehouse.land_and_property\", # Dataset.TableName\n",
    "        project_id=\"dtc-de-383113\",\n",
    "        credentials=gcp_credentials_block.get_credentials_from_service_account(),\n",
    "        chunksize=500.000,\n",
    "        if_exists=\"append\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@task()\n",
    "def delete_local_file(file_name) -> None:\n",
    "    os.remove(f\"{file_name}.parquet\")\n",
    "    os.remove(f\"{file_name}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow()\n",
    "def etl_web_to_local_to_gcs_to_bq(year: int, month: int) -> None:\n",
    "    file_name = f\"Number-and-types-of-applications-by-all-account-customers-{year}-{month:02}\"\n",
    "    extract_load_web_data(year, month, file_name)\n",
    "    raw_df = load_csv_data(file_name)\n",
    "    cleaned_df = clean_local_data(raw_df)\n",
    "    transformed_df = transform_data (cleaned_df, year, month)\n",
    "    final_df = save_transformed_data (transformed_df, file_name)\n",
    "    write_gcs(file_name, \"Land_and_Property\")\n",
    "    write_bq(final_df)\n",
    "    delete_local_file(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@flow()\n",
    "def etl_parent_flow(years:list[int] , months:list[int]) -> None:\n",
    "    for year in years:\n",
    "        for month in months:\n",
    "            etl_web_to_local_to_gcs_to_bq(year, month)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    years=[2022]\n",
    "    months=list(range(1,13))\n",
    "    etl_parent_flow(years, months) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
