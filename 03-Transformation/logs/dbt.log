

============================== 2023-04-20 22:32:33.432963 | a1de7519-bb1e-4c52-af67-f72a81e10618 ==============================
[0m22:32:33.432963 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:32:33.434807 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m22:32:33.435131 [debug] [MainThread]: Tracking: tracking
[0m22:32:33.457542 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ae0610>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106b8b110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10718d510>]}
[0m22:32:33.460703 [debug] [MainThread]: Set downloads directory='/var/folders/b0/5sk7vs2s2zj10lhp65p3qrh40000gn/T/dbt-downloads-12z4qac5'
[0m22:32:33.462289 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:32:33.891567 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:32:33.893397 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:32:34.195103 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:32:34.200284 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m22:32:34.398852 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m22:32:34.402346 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m22:32:34.787321 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m22:32:34.806850 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:32:35.452450 [info ] [MainThread]:   Installed from version 1.0.0
[0m22:32:35.453081 [info ] [MainThread]:   Up to date!
[0m22:32:35.453737 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'a1de7519-bb1e-4c52-af67-f72a81e10618', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10718cd50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106a0be90>]}
[0m22:32:35.454251 [info ] [MainThread]: Installing dbt-labs/codegen
[0m22:32:36.131212 [info ] [MainThread]:   Installed from version 0.9.0
[0m22:32:36.131852 [info ] [MainThread]:   Up to date!
[0m22:32:36.132484 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'a1de7519-bb1e-4c52-af67-f72a81e10618', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dce390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dcc990>]}
[0m22:32:36.133058 [info ] [MainThread]: Installing elementary-data/elementary
[0m22:32:37.115718 [info ] [MainThread]:   Installed from version 0.7.4
[0m22:32:37.116525 [info ] [MainThread]:   Updated version available: 0.7.5
[0m22:32:37.117117 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'a1de7519-bb1e-4c52-af67-f72a81e10618', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106dce390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106aaf610>]}
[0m22:32:37.117721 [info ] [MainThread]: 
[0m22:32:37.118328 [info ] [MainThread]: Updates available for packages: ['elementary-data/elementary']                 
Update your versions in packages.yml, then run dbt deps
[0m22:32:37.120340 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106ae01d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x107185990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106db77d0>]}
[0m22:32:37.120924 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:35:02.015742 | cb3fc847-6550-4704-bd64-aa5002bd4cb5 ==============================
[0m22:35:02.015742 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:35:02.018550 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m22:35:02.018874 [debug] [MainThread]: Tracking: tracking
[0m22:35:02.053416 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112451090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127ff8d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127ffed0>]}
[0m22:35:02.056733 [debug] [MainThread]: Set downloads directory='/var/folders/b0/5sk7vs2s2zj10lhp65p3qrh40000gn/T/dbt-downloads-c7pf41eg'
[0m22:35:02.057556 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:35:03.033028 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:35:03.034458 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:35:03.258281 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:35:03.265868 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m22:35:03.682004 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m22:35:03.685126 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m22:35:03.949719 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m22:35:03.972083 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:35:04.867855 [info ] [MainThread]:   Installed from version 1.0.0
[0m22:35:04.868568 [info ] [MainThread]:   Up to date!
[0m22:35:04.869452 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'cb3fc847-6550-4704-bd64-aa5002bd4cb5', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11215f350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123eec90>]}
[0m22:35:04.870157 [info ] [MainThread]: Installing dbt-labs/codegen
[0m22:35:05.387018 [info ] [MainThread]:   Installed from version 0.9.0
[0m22:35:05.387670 [info ] [MainThread]:   Up to date!
[0m22:35:05.388521 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'cb3fc847-6550-4704-bd64-aa5002bd4cb5', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123eec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11215f350>]}
[0m22:35:05.389057 [info ] [MainThread]: Installing elementary-data/elementary
[0m22:35:06.458408 [info ] [MainThread]:   Installed from version 0.7.5
[0m22:35:06.459239 [info ] [MainThread]:   Up to date!
[0m22:35:06.459832 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'cb3fc847-6550-4704-bd64-aa5002bd4cb5', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1123eec90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112202e90>]}
[0m22:35:06.461051 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1127fc390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1124522d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112453050>]}
[0m22:35:06.461837 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:35:42.084024 | b7993b58-e095-4524-9ac6-71abbdf73fb1 ==============================
[0m22:35:42.084024 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:35:42.095620 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:35:42.096408 [debug] [MainThread]: Tracking: tracking
[0m22:35:42.136512 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126e27e50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127c48410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127c48a50>]}
[0m22:35:42.198281 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:35:42.199022 [info ] [MainThread]: Unable to do partial parsing because saved manifest not found. Starting full parse.
[0m22:35:42.199382 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'b7993b58-e095-4524-9ac6-71abbdf73fb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126edca90>]}
[0m22:35:44.864926 [debug] [MainThread]: 1699: static parser successfully parsed core/final_land_and_property.sql
[0m22:35:44.886025 [debug] [MainThread]: 1603: static parser failed on transform/land_and_property_transform.sql
[0m22:35:44.900699 [debug] [MainThread]: 1602: parser fallback to jinja rendering on transform/land_and_property_transform.sql
[0m22:35:44.902890 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:35:44.955809 [debug] [MainThread]: 1699: static parser successfully parsed edr/run_results/snapshot_run_results.sql
[0m22:35:44.959831 [debug] [MainThread]: 1603: static parser failed on edr/run_results/job_run_results.sql
[0m22:35:44.984055 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/job_run_results.sql
[0m22:35:44.985983 [debug] [MainThread]: 1603: static parser failed on edr/run_results/model_run_results.sql
[0m22:35:45.001193 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/model_run_results.sql
[0m22:35:45.003057 [debug] [MainThread]: 1603: static parser failed on edr/run_results/test_result_rows.sql
[0m22:35:45.066392 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/test_result_rows.sql
[0m22:35:45.068943 [debug] [MainThread]: 1603: static parser failed on edr/run_results/elementary_test_results.sql
[0m22:35:45.117597 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/elementary_test_results.sql
[0m22:35:45.119139 [debug] [MainThread]: 1603: static parser failed on edr/run_results/dbt_source_freshness_results.sql
[0m22:35:45.147899 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/dbt_source_freshness_results.sql
[0m22:35:45.149610 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_tests.sql
[0m22:35:45.159477 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_tests.sql
[0m22:35:45.161447 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_schema_changes.sql
[0m22:35:45.175943 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_schema_changes.sql
[0m22:35:45.177775 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_source_freshness.sql
[0m22:35:45.184958 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_source_freshness.sql
[0m22:35:45.186456 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_anomaly_detection.sql
[0m22:35:45.197488 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_anomaly_detection.sql
[0m22:35:45.199188 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_models.sql
[0m22:35:45.207883 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_models.sql
[0m22:35:45.210341 [debug] [MainThread]: 1699: static parser successfully parsed edr/system/monitors_runs.sql
[0m22:35:45.213258 [debug] [MainThread]: 1603: static parser failed on edr/system/metadata.sql
[0m22:35:45.222955 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/system/metadata.sql
[0m22:35:45.224523 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_tests.sql
[0m22:35:45.276093 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_tests.sql
[0m22:35:45.278270 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_models.sql
[0m22:35:45.312147 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_models.sql
[0m22:35:45.313959 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_sources.sql
[0m22:35:45.349294 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_sources.sql
[0m22:35:45.351306 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_snapshots.sql
[0m22:35:45.381064 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_snapshots.sql
[0m22:35:45.382962 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_invocations.sql
[0m22:35:45.430325 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_invocations.sql
[0m22:35:45.432163 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_metrics.sql
[0m22:35:45.472422 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_metrics.sql
[0m22:35:45.473909 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_seeds.sql
[0m22:35:45.502888 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_seeds.sql
[0m22:35:45.504687 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_artifacts_hashes.sql
[0m22:35:45.513080 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_artifacts_hashes.sql
[0m22:35:45.514854 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_run_results.sql
[0m22:35:45.542538 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_run_results.sql
[0m22:35:45.544023 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_exposures.sql
[0m22:35:45.581659 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_exposures.sql
[0m22:35:45.583982 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql
[0m22:35:45.614532 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql
[0m22:35:45.617443 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql
[0m22:35:45.628460 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql
[0m22:35:45.630253 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/schema_changes/schema_columns_snapshot.sql
[0m22:35:45.645214 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/schema_changes/schema_columns_snapshot.sql
[0m22:35:45.646660 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql
[0m22:35:45.668500 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql
[0m22:35:45.671377 [debug] [MainThread]: 1603: static parser failed on edr/metadata_store/filtered_information_schema_columns.sql
[0m22:35:45.693878 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/metadata_store/filtered_information_schema_columns.sql
[0m22:35:45.695519 [debug] [MainThread]: 1603: static parser failed on edr/metadata_store/filtered_information_schema_tables.sql
[0m22:35:45.708222 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/metadata_store/filtered_information_schema_tables.sql
[0m22:35:45.994549 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': 'b7993b58-e095-4524-9ac6-71abbdf73fb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127e64610>]}
[0m22:35:46.020293 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': 'b7993b58-e095-4524-9ac6-71abbdf73fb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12826db90>]}
[0m22:35:46.020812 [info ] [MainThread]: Found 32 models, 0 tests, 0 snapshots, 0 analyses, 880 macros, 2 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m22:35:46.021642 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': 'b7993b58-e095-4524-9ac6-71abbdf73fb1', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127e8c490>]}
[0m22:35:46.027354 [info ] [MainThread]: 
[0m22:35:46.030090 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:35:46.034964 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dtc-de-383113'
[0m22:35:46.035702 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:35:46.036244 [debug] [ThreadPool]: BigQuery adapter: Got an error when attempting to create a bigquery client: '[Errno 2] No such file or directory: '$HOME/Downloads/dtc-de-383113-6b75631f67cd.json''
[0m22:35:46.037604 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:35:46.037904 [debug] [MainThread]: Connection 'list_dtc-de-383113' was properly closed.
[0m22:35:46.038124 [info ] [MainThread]: 
[0m22:35:46.038384 [info ] [MainThread]: Finished running  in 0 hours 0 minutes and 0.01 seconds (0.01s).
[0m22:35:46.038761 [error] [MainThread]: Encountered an error:
Database Error
  [Errno 2] No such file or directory: '$HOME/Downloads/dtc-de-383113-6b75631f67cd.json'
[0m22:35:46.039223 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127ff8d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127bcfb90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127f4e790>]}
[0m22:35:46.039582 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:36:50.521777 | af774a97-d2ec-42ad-adbe-5524a758c6e0 ==============================
[0m22:36:50.521777 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:36:50.523362 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m22:36:50.523731 [debug] [MainThread]: Tracking: tracking
[0m22:36:50.539925 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cc4ab10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbcde90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf73a90>]}
[0m22:36:50.555219 [debug] [MainThread]: Set downloads directory='/var/folders/b0/5sk7vs2s2zj10lhp65p3qrh40000gn/T/dbt-downloads-8rkpbu8x'
[0m22:36:50.556359 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:36:50.911393 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:36:50.912252 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:36:51.191753 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:36:51.198359 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m22:36:51.626150 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m22:36:51.629207 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m22:36:52.089709 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m22:36:52.113669 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:36:52.959543 [info ] [MainThread]:   Installed from version 1.0.0
[0m22:36:52.960193 [info ] [MainThread]:   Up to date!
[0m22:36:52.960966 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'af774a97-d2ec-42ad-adbe-5524a758c6e0', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf80850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf73a90>]}
[0m22:36:52.961457 [info ] [MainThread]: Installing dbt-labs/codegen
[0m22:36:53.470631 [info ] [MainThread]:   Installed from version 0.9.0
[0m22:36:53.471221 [info ] [MainThread]:   Up to date!
[0m22:36:53.471984 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'af774a97-d2ec-42ad-adbe-5524a758c6e0', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf705d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10ccb2f10>]}
[0m22:36:53.472658 [info ] [MainThread]: Installing elementary-data/elementary
[0m22:36:54.461083 [info ] [MainThread]:   Installed from version 0.7.5
[0m22:36:54.461498 [info ] [MainThread]:   Up to date!
[0m22:36:54.461989 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'af774a97-d2ec-42ad-adbe-5524a758c6e0', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cf80850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cba0bd0>]}
[0m22:36:54.463476 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10c9c5150>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cba0bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10cbb6b10>]}
[0m22:36:54.464122 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:37:47.104668 | 6b2f48a9-e937-49ce-aa12-250b3f26320f ==============================
[0m22:37:47.104668 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:37:47.106250 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m22:37:47.106503 [debug] [MainThread]: Tracking: tracking
[0m22:37:47.126763 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a6a2890>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a311d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a0564d0>]}
[0m22:37:47.131889 [debug] [MainThread]: Set downloads directory='/var/folders/b0/5sk7vs2s2zj10lhp65p3qrh40000gn/T/dbt-downloads-lnc4hkmn'
[0m22:37:47.133083 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:37:47.428690 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:37:47.429669 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:37:47.733062 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:37:47.740826 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m22:37:47.935123 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m22:37:47.937551 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m22:37:48.347414 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m22:37:48.377345 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:37:49.030365 [info ] [MainThread]:   Installed from version 1.0.0
[0m22:37:49.031024 [info ] [MainThread]:   Up to date!
[0m22:37:49.031807 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6b2f48a9-e937-49ce-aa12-250b3f26320f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a326090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a697f90>]}
[0m22:37:49.032249 [info ] [MainThread]: Installing dbt-labs/codegen
[0m22:37:50.378526 [info ] [MainThread]:   Installed from version 0.9.0
[0m22:37:50.379274 [info ] [MainThread]:   Up to date!
[0m22:37:50.380029 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6b2f48a9-e937-49ce-aa12-250b3f26320f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a036bd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a036590>]}
[0m22:37:50.380659 [info ] [MainThread]: Installing elementary-data/elementary
[0m22:37:51.197059 [info ] [MainThread]:   Installed from version 0.7.5
[0m22:37:51.197863 [info ] [MainThread]:   Up to date!
[0m22:37:51.198686 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '6b2f48a9-e937-49ce-aa12-250b3f26320f', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a325410>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a3f9310>]}
[0m22:37:51.201024 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a024090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1086ddb10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10a101f90>]}
[0m22:37:51.201579 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:38:32.894213 | 3b2cdcc9-d2c2-4956-9b2b-722740ee324f ==============================
[0m22:38:32.894213 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:38:32.897249 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:38:32.897771 [debug] [MainThread]: Tracking: tracking
[0m22:38:32.916272 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c429ad0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c438590>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c438bd0>]}
[0m22:38:32.961523 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:38:32.996128 [info ] [MainThread]: Unable to do partial parsing because profile has changed
[0m22:38:32.996751 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108d02490>]}
[0m22:38:35.450588 [debug] [MainThread]: 1699: static parser successfully parsed core/final_land_and_property.sql
[0m22:38:35.467624 [debug] [MainThread]: 1603: static parser failed on transform/land_and_property_transform.sql
[0m22:38:35.476472 [debug] [MainThread]: 1602: parser fallback to jinja rendering on transform/land_and_property_transform.sql
[0m22:38:35.478060 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:38:35.516857 [debug] [MainThread]: 1699: static parser successfully parsed edr/run_results/snapshot_run_results.sql
[0m22:38:35.521646 [debug] [MainThread]: 1603: static parser failed on edr/run_results/job_run_results.sql
[0m22:38:35.545482 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/job_run_results.sql
[0m22:38:35.547036 [debug] [MainThread]: 1603: static parser failed on edr/run_results/model_run_results.sql
[0m22:38:35.558344 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/model_run_results.sql
[0m22:38:35.559857 [debug] [MainThread]: 1603: static parser failed on edr/run_results/test_result_rows.sql
[0m22:38:35.628816 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/test_result_rows.sql
[0m22:38:35.630585 [debug] [MainThread]: 1603: static parser failed on edr/run_results/elementary_test_results.sql
[0m22:38:35.669280 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/elementary_test_results.sql
[0m22:38:35.672100 [debug] [MainThread]: 1603: static parser failed on edr/run_results/dbt_source_freshness_results.sql
[0m22:38:35.699180 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/dbt_source_freshness_results.sql
[0m22:38:35.701503 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_tests.sql
[0m22:38:35.711726 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_tests.sql
[0m22:38:35.714068 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_schema_changes.sql
[0m22:38:35.726358 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_schema_changes.sql
[0m22:38:35.729783 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_source_freshness.sql
[0m22:38:35.737011 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_source_freshness.sql
[0m22:38:35.738742 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_anomaly_detection.sql
[0m22:38:35.747887 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_anomaly_detection.sql
[0m22:38:35.749607 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_models.sql
[0m22:38:35.757551 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_models.sql
[0m22:38:35.759644 [debug] [MainThread]: 1699: static parser successfully parsed edr/system/monitors_runs.sql
[0m22:38:35.762583 [debug] [MainThread]: 1603: static parser failed on edr/system/metadata.sql
[0m22:38:35.776600 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/system/metadata.sql
[0m22:38:35.780498 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_tests.sql
[0m22:38:35.832096 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_tests.sql
[0m22:38:35.834241 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_models.sql
[0m22:38:35.864298 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_models.sql
[0m22:38:35.867121 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_sources.sql
[0m22:38:35.905389 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_sources.sql
[0m22:38:35.907038 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_snapshots.sql
[0m22:38:35.943723 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_snapshots.sql
[0m22:38:35.945951 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_invocations.sql
[0m22:38:36.008257 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_invocations.sql
[0m22:38:36.009875 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_metrics.sql
[0m22:38:36.054003 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_metrics.sql
[0m22:38:36.055491 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_seeds.sql
[0m22:38:36.086957 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_seeds.sql
[0m22:38:36.089234 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_artifacts_hashes.sql
[0m22:38:36.096415 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_artifacts_hashes.sql
[0m22:38:36.097993 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_run_results.sql
[0m22:38:36.128793 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_run_results.sql
[0m22:38:36.130311 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_exposures.sql
[0m22:38:36.160574 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_exposures.sql
[0m22:38:36.162477 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql
[0m22:38:36.196612 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql
[0m22:38:36.198200 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql
[0m22:38:36.209385 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql
[0m22:38:36.210829 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/schema_changes/schema_columns_snapshot.sql
[0m22:38:36.228518 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/schema_changes/schema_columns_snapshot.sql
[0m22:38:36.231349 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql
[0m22:38:36.250597 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql
[0m22:38:36.252742 [debug] [MainThread]: 1603: static parser failed on edr/metadata_store/filtered_information_schema_columns.sql
[0m22:38:36.274709 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/metadata_store/filtered_information_schema_columns.sql
[0m22:38:36.276315 [debug] [MainThread]: 1603: static parser failed on edr/metadata_store/filtered_information_schema_tables.sql
[0m22:38:36.289753 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/metadata_store/filtered_information_schema_tables.sql
[0m22:38:36.542690 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c687d90>]}
[0m22:38:36.563568 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c89a610>]}
[0m22:38:36.564152 [info ] [MainThread]: Found 32 models, 0 tests, 0 snapshots, 0 analyses, 880 macros, 2 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m22:38:36.564586 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c3f69d0>]}
[0m22:38:36.568204 [info ] [MainThread]: 
[0m22:38:36.572852 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:38:36.576557 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dtc-de-383113'
[0m22:38:36.577731 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:38:37.665001 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dtc-de-383113_de_data_warehouse'
[0m22:38:37.665655 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:38:38.275595 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c9d40d0>]}
[0m22:38:38.276394 [info ] [MainThread]: 
[0m22:38:38.277011 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:38:38.292784 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:38:38.295191 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:38:38.295804 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.00s]
[0m22:38:38.297348 [info ] [MainThread]: 
[0m22:38:38.299290 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m22:38:38.299764 [info ] [MainThread]: 
[0m22:38:38.308211 [debug] [Thread-1 (]: Began running node model.de_project.land_and_property_optimized_raw
[0m22:38:38.309496 [debug] [Thread-2 (]: Began running node model.elementary.data_monitoring_metrics
[0m22:38:38.309936 [debug] [Thread-3 (]: Began running node model.elementary.dbt_exposures
[0m22:38:38.308945 [info ] [Thread-1 (]: 1 of 32 START sql view model de_data_warehouse.land_and_property_optimized_raw . [RUN]
[0m22:38:38.310555 [debug] [Thread-4 (]: Began running node model.elementary.dbt_invocations
[0m22:38:38.311049 [info ] [Thread-2 (]: 2 of 32 START sql incremental model de_data_warehouse.data_monitoring_metrics .. [RUN]
[0m22:38:38.311677 [info ] [Thread-3 (]: 3 of 32 START sql incremental model de_data_warehouse.dbt_exposures ............ [RUN]
[0m22:38:38.313068 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.de_project.land_and_property_optimized_raw'
[0m22:38:38.313967 [info ] [Thread-4 (]: 4 of 32 START sql incremental model de_data_warehouse.dbt_invocations .......... [RUN]
[0m22:38:38.315357 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.data_monitoring_metrics'
[0m22:38:38.316550 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_exposures'
[0m22:38:38.317533 [debug] [Thread-1 (]: Began compiling node model.de_project.land_and_property_optimized_raw
[0m22:38:38.319906 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_invocations'
[0m22:38:38.320612 [debug] [Thread-2 (]: Began compiling node model.elementary.data_monitoring_metrics
[0m22:38:38.321220 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_exposures
[0m22:38:38.326673 [debug] [Thread-1 (]: Writing injected SQL for node "model.de_project.land_and_property_optimized_raw"
[0m22:38:38.327123 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_invocations
[0m22:38:38.355529 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_exposures"
[0m22:38:38.406938 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_invocations"
[0m22:38:38.422871 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.data_monitoring_metrics"
[0m22:38:38.423554 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_optimized_raw (compile): 2023-04-20 22:38:38.321857 => 2023-04-20 22:38:38.423365
[0m22:38:38.424350 [debug] [Thread-1 (]: Began executing node model.de_project.land_and_property_optimized_raw
[0m22:38:38.424727 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_invocations (compile): 2023-04-20 22:38:38.358035 => 2023-04-20 22:38:38.424595
[0m22:38:38.425104 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_exposures (compile): 2023-04-20 22:38:38.334365 => 2023-04-20 22:38:38.424986
[0m22:38:38.456030 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_invocations
[0m22:38:38.456638 [debug] [Thread-2 (]: Timing info for model.elementary.data_monitoring_metrics (compile): 2023-04-20 22:38:38.327605 => 2023-04-20 22:38:38.456574
[0m22:38:38.464526 [debug] [Thread-1 (]: Writing runtime sql for node "model.de_project.land_and_property_optimized_raw"
[0m22:38:38.465141 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_exposures
[0m22:38:38.489139 [debug] [Thread-2 (]: Began executing node model.elementary.data_monitoring_metrics
[0m22:38:38.633471 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_exposures"
[0m22:38:38.634775 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_invocations"
[0m22:38:38.639320 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.data_monitoring_metrics"
[0m22:38:38.640680 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:38.641771 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m22:38:38.642069 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m22:38:38.643151 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m22:38:38.694725 [debug] [Thread-1 (]: On model.de_project.land_and_property_optimized_raw: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.land_and_property_optimized_raw"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`
  OPTIONS()
  as with source as (
      select * from `dtc-de-383113`.`project_dwh`.`land_and_property_optimized`
)
select * from source;


[0m22:38:38.695082 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as maturity

,
                
        cast('dummy_string' as string) as type

,
                
        cast('dummy_string' as string) as owner_email

,
                
        cast('dummy_string' as string) as owner_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as url

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:38.696423 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.data_monitoring_metrics"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`
    
    
    OPTIONS()
    as (
      


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as id

,
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as metric_name

,
                
        cast(123456789.99 as FLOAT64) as metric_value

,
                
        cast('dummy_string' as string) as source_value

,
                cast('2091-02-17' as TIMESTAMP) as bucket_start

,
                cast('2091-02-17' as TIMESTAMP) as bucket_end

,
                
        cast(123456789 as INT64) as bucket_duration_hours

,
                cast('2091-02-17' as TIMESTAMP) as updated_at

,
                
        cast('dummy_string' as string) as dimension

,
                
        cast('dummy_string' as string) as dimension_value

,
                
        cast('dummy_string' as string) as metric_properties


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m22:38:38.696911 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_invocations"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as invocation_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_run_id

,
                
        cast('dummy_string' as string) as run_started_at

,
                
        cast('dummy_string' as string) as run_completed_at

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as command

,
                
        cast('dummy_string' as string) as dbt_version

,
                
        cast('dummy_string' as string) as elementary_version

,
                
        cast (True as BOOL) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as string) as invocation_vars

,
                
        cast('this_is_just_a_long_dummy_string' as string) as vars

,
                
        cast('dummy_string' as string) as target_name

,
                
        cast('dummy_string' as string) as target_database

,
                
        cast('dummy_string' as string) as target_schema

,
                
        cast('dummy_string' as string) as target_profile_name

,
                
        cast(123456789 as INT64) as threads

,
                
        cast('this_is_just_a_long_dummy_string' as string) as selected

,
                
        cast('this_is_just_a_long_dummy_string' as string) as yaml_selector

,
                
        cast('dummy_string' as string) as project_id

,
                
        cast('dummy_string' as string) as project_name

,
                
        cast('dummy_string' as string) as env

,
                
        cast('dummy_string' as string) as env_id

,
                
        cast('dummy_string' as string) as cause_category

,
                
        cast('this_is_just_a_long_dummy_string' as string) as cause

,
                
        cast('dummy_string' as string) as pull_request_id

,
                
        cast('dummy_string' as string) as git_sha

,
                
        cast('dummy_string' as string) as orchestrator

,
                
        cast('dummy_string' as string) as dbt_user


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:39.574611 [debug] [Thread-1 (]: BigQuery adapter: Unhandled error while running:
/* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.land_and_property_optimized_raw"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`
  OPTIONS()
  as with source as (
      select * from `dtc-de-383113`.`project_dwh`.`land_and_property_optimized`
)
select * from source;


[0m22:38:39.578151 [debug] [Thread-1 (]: BigQuery adapter: 404 Not found: Dataset dtc-de-383113:project_dwh was not found in location europe-west6

Location: europe-west6
Job ID: 6bb899ab-6b50-4354-9049-ecccfa078226

[0m22:38:39.579883 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_optimized_raw (execute): 2023-04-20 22:38:38.425573 => 2023-04-20 22:38:39.579771
[0m22:38:39.597330 [debug] [Thread-1 (]: Runtime Error in model land_and_property_optimized_raw (models/raw/land_and_property_optimized_raw.sql)
  404 Not found: Dataset dtc-de-383113:project_dwh was not found in location europe-west6
  
  Location: europe-west6
  Job ID: 6bb899ab-6b50-4354-9049-ecccfa078226
  
[0m22:38:39.597975 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cb18ad0>]}
[0m22:38:39.598599 [error] [Thread-1 (]: 1 of 32 ERROR creating sql view model de_data_warehouse.land_and_property_optimized_raw  [[31mERROR[0m in 1.29s]
[0m22:38:39.600494 [debug] [Thread-1 (]: Finished running node model.de_project.land_and_property_optimized_raw
[0m22:38:39.601007 [debug] [Thread-1 (]: Began running node model.elementary.dbt_metrics
[0m22:38:39.601575 [info ] [Thread-1 (]: 5 of 32 START sql incremental model de_data_warehouse.dbt_metrics .............. [RUN]
[0m22:38:39.602394 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_metrics'
[0m22:38:39.602677 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_metrics
[0m22:38:39.632589 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_metrics"
[0m22:38:39.633298 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_metrics (compile): 2023-04-20 22:38:39.602850 => 2023-04-20 22:38:39.633220
[0m22:38:39.633583 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_metrics
[0m22:38:39.641106 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_metrics"
[0m22:38:39.641936 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:39.694126 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as label

,
                
        cast('dummy_string' as string) as model

,
                
        cast('dummy_string' as string) as type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as sql

,
                
        cast('dummy_string' as string) as timestamp

,
                
        cast('this_is_just_a_long_dummy_string' as string) as filters

,
                
        cast('this_is_just_a_long_dummy_string' as string) as time_grains

,
                
        cast('this_is_just_a_long_dummy_string' as string) as dimensions

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:41.372555 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ac8c27cb-7462-4544-a8eb-bfdabb3502d3&page=queryresults
[0m22:38:41.401307 [debug] [Thread-3 (]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m22:38:41.404699 [debug] [Thread-3 (]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m22:38:41.436063 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__tmp_20230420223841419320`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
        WHERE 1 = 0
    
    );
  
  
[0m22:38:41.669120 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:a6226447-d4b5-41fb-9e1b-d8473a6b0cd5&page=queryresults
[0m22:38:41.670371 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:0bad5525-ba90-4d89-b9ec-ca9af4784b33&page=queryresults
[0m22:38:41.701124 [debug] [Thread-2 (]: Timing info for model.elementary.data_monitoring_metrics (execute): 2023-04-20 22:38:38.546595 => 2023-04-20 22:38:41.701061
[0m22:38:41.703169 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_invocations (execute): 2023-04-20 22:38:38.465778 => 2023-04-20 22:38:41.703111
[0m22:38:41.704105 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c579050>]}
[0m22:38:41.704983 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c54c910>]}
[0m22:38:41.705856 [info ] [Thread-2 (]: 2 of 32 OK created sql incremental model de_data_warehouse.data_monitoring_metrics  [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 3.39s]
[0m22:38:41.706440 [info ] [Thread-4 (]: 4 of 32 OK created sql incremental model de_data_warehouse.dbt_invocations ..... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 3.39s]
[0m22:38:41.707030 [debug] [Thread-2 (]: Finished running node model.elementary.data_monitoring_metrics
[0m22:38:41.707520 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_invocations
[0m22:38:41.707916 [debug] [Thread-2 (]: Began running node model.elementary.dbt_models
[0m22:38:41.708473 [debug] [Thread-4 (]: Began running node model.elementary.dbt_run_results
[0m22:38:41.708962 [info ] [Thread-2 (]: 6 of 32 START sql incremental model de_data_warehouse.dbt_models ............... [RUN]
[0m22:38:41.709460 [info ] [Thread-4 (]: 7 of 32 START sql incremental model de_data_warehouse.dbt_run_results .......... [RUN]
[0m22:38:41.710662 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.dbt_models'
[0m22:38:41.711511 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_run_results'
[0m22:38:41.711946 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_models
[0m22:38:41.712191 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_run_results
[0m22:38:41.744906 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_models"
[0m22:38:41.761946 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_run_results"
[0m22:38:41.762623 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_models (compile): 2023-04-20 22:38:41.712396 => 2023-04-20 22:38:41.762545
[0m22:38:41.763031 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_models
[0m22:38:41.763341 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_run_results (compile): 2023-04-20 22:38:41.736365 => 2023-04-20 22:38:41.763276
[0m22:38:41.771846 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_models"
[0m22:38:41.772199 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_run_results
[0m22:38:41.783521 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_run_results"
[0m22:38:41.784170 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:38:41.784726 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:38:41.833230 [debug] [Thread-4 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_run_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as model_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as invocation_id

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('this_is_just_a_long_dummy_string' as string) as name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as message

,
                
        cast('dummy_string' as string) as status

,
                
        cast('dummy_string' as string) as resource_type

,
                
        cast(123456789.99 as FLOAT64) as execution_time

,
                
        cast('dummy_string' as string) as execute_started_at

,
                
        cast('dummy_string' as string) as execute_completed_at

,
                
        cast('dummy_string' as string) as compile_started_at

,
                
        cast('dummy_string' as string) as compile_completed_at

,
                
        cast(31474836478 as bigint) as rows_affected

,
                
        cast (True as BOOL) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as string) as compiled_code

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as string) as query_id

,
                
        cast('dummy_string' as string) as thread_id


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:41.834632 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('dummy_string' as string) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:42.211421 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ad822600-2da5-480c-a87c-d4ae3f53dfb5&page=queryresults
[0m22:38:42.215349 [debug] [Thread-1 (]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m22:38:42.217437 [debug] [Thread-1 (]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m22:38:42.223719 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__tmp_20230420223842219801`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
        WHERE 1 = 0
    
    );
  
  
[0m22:38:43.433279 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:6d3e0bb5-03a9-4876-996e-ade03e4d7e73&page=queryresults
[0m22:38:43.462512 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__tmp_20230420223841419320`
    );
  
  
[0m22:38:44.305376 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:4129a2d4-a0b9-4115-ad35-2ee1fd35ed1f&page=queryresults
[0m22:38:44.311107 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__tmp_20230420223842219801`
    );
  
  
[0m22:38:44.314995 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:35e245d6-c772-4dc7-8d7b-590371539c05&page=queryresults
[0m22:38:44.318319 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_run_results (execute): 2023-04-20 22:38:41.772582 => 2023-04-20 22:38:44.318251
[0m22:38:44.319400 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c5296d0>]}
[0m22:38:44.322828 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:d930b8aa-03cd-415b-bd8e-0844895c71bf&page=queryresults
[0m22:38:44.322141 [info ] [Thread-4 (]: 7 of 32 OK created sql incremental model de_data_warehouse.dbt_run_results ..... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 2.61s]
[0m22:38:44.331270 [debug] [Thread-2 (]: Elementary: [dbt_models] Flattening the artifacts.
[0m22:38:44.331897 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_run_results
[0m22:38:44.350766 [debug] [Thread-4 (]: Began running node model.elementary.dbt_seeds
[0m22:38:44.367149 [info ] [Thread-4 (]: 8 of 32 START sql incremental model de_data_warehouse.dbt_seeds ................ [RUN]
[0m22:38:44.384362 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_seeds'
[0m22:38:44.407222 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_seeds
[0m22:38:44.497720 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_seeds"
[0m22:38:44.523030 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_seeds (compile): 2023-04-20 22:38:44.413888 => 2023-04-20 22:38:44.522832
[0m22:38:44.527586 [debug] [Thread-2 (]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m22:38:44.528145 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_seeds
[0m22:38:44.534195 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420223844531715`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
        WHERE 1 = 0
    
    );
  
  
[0m22:38:44.543409 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_seeds"
[0m22:38:44.545671 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:38:44.599340 [debug] [Thread-4 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:45.205828 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:68f1e53f-da50-468e-afda-5c2d2d759acf&page=queryresults
[0m22:38:45.208533 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_exposures (execute): 2023-04-20 22:38:38.512153 => 2023-04-20 22:38:45.208439
[0m22:38:45.209660 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c5b7f90>]}
[0m22:38:45.210179 [info ] [Thread-3 (]: 3 of 32 OK created sql incremental model de_data_warehouse.dbt_exposures ....... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 6.89s]
[0m22:38:45.210594 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_exposures
[0m22:38:45.210961 [debug] [Thread-3 (]: Began running node model.elementary.dbt_snapshots
[0m22:38:45.211440 [info ] [Thread-3 (]: 9 of 32 START sql incremental model de_data_warehouse.dbt_snapshots ............ [RUN]
[0m22:38:45.212270 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_snapshots'
[0m22:38:45.212758 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_snapshots
[0m22:38:45.241148 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_snapshots"
[0m22:38:45.242360 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_snapshots (compile): 2023-04-20 22:38:45.212983 => 2023-04-20 22:38:45.242260
[0m22:38:45.242754 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_snapshots
[0m22:38:45.249831 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_snapshots"
[0m22:38:45.250683 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:38:45.301244 [debug] [Thread-3 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('dummy_string' as string) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:46.256045 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:05c71ac4-dd06-4036-84bb-5e84bc5e8292&page=queryresults
[0m22:38:46.257035 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:0449ac84-7040-4ca8-9f8f-be962afe17dd&page=queryresults
[0m22:38:46.263069 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_metrics (execute): 2023-04-20 22:38:39.633789 => 2023-04-20 22:38:46.263015
[0m22:38:46.263764 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c899ed0>]}
[0m22:38:46.264992 [info ] [Thread-1 (]: 5 of 32 OK created sql incremental model de_data_warehouse.dbt_metrics ......... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 6.66s]
[0m22:38:46.267058 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_metrics
[0m22:38:46.268279 [debug] [Thread-1 (]: Began running node model.elementary.dbt_source_freshness_results
[0m22:38:46.269145 [info ] [Thread-1 (]: 10 of 32 START sql incremental model de_data_warehouse.dbt_source_freshness_results  [RUN]
[0m22:38:46.270609 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_source_freshness_results'
[0m22:38:46.271303 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_source_freshness_results
[0m22:38:46.294283 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_source_freshness_results"
[0m22:38:46.295013 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_source_freshness_results (compile): 2023-04-20 22:38:46.271759 => 2023-04-20 22:38:46.294943
[0m22:38:46.295269 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_source_freshness_results
[0m22:38:46.303695 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_source_freshness_results"
[0m22:38:46.304476 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:46.355773 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_source_freshness_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`
    
    
    OPTIONS()
    as (
      


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as source_freshness_execution_id

,
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as max_loaded_at

,
                
        cast('dummy_string' as string) as snapshotted_at

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast(123456789.99 as FLOAT64) as max_loaded_at_time_ago_in_s

,
                
        cast('dummy_string' as string) as status

,
                
        cast('dummy_string' as string) as error

,
                
        cast('dummy_string' as string) as compile_started_at

,
                
        cast('dummy_string' as string) as compile_completed_at

,
                
        cast('dummy_string' as string) as execute_started_at

,
                
        cast('dummy_string' as string) as execute_completed_at

,
                
        cast('dummy_string' as string) as invocation_id


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m22:38:46.384630 [debug] [Thread-2 (]: Elementary: Inserting 32 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420223844531715`
[0m22:38:47.137700 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:378c2f31-cc07-4414-a5bb-93583b72707d&page=queryresults
[0m22:38:47.168932 [debug] [Thread-4 (]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m22:38:47.171230 [debug] [Thread-4 (]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m22:38:47.191532 [debug] [Thread-4 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__tmp_20230420223847180895`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`
        WHERE 1 = 0
    
    );
  
  
[0m22:38:47.204950 [debug] [Thread-2 (]: Elementary: [1/1] Running insert query.
[0m22:38:47.209546 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420223844531715`
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,generated_at,metadata_hash) values
    ('model.de_project.final_land_and_property','final_land_and_property','630617aeffb59ffe66475bed6ccc49f56b5c1b14ad0d98b3bf06fdf56b9beeef','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.de_project.land_and_property_transform"]','','final_land_and_property','de_project','models/core/final_land_and_property.sql','core/final_land_and_property.sql','2023-04-20 22:38:44','e00a803282655eab912faaa4afa92cf4'),('model.de_project.land_and_property_transform','land_and_property_transform','705aa5a5fe5a0d2d7e54e62b9cad3c679e12969b56a45015a64b4fe8d843ed80','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.de_project.land_and_property_optimized_raw"]','','land_and_property_transform','de_project','models/transform/land_and_property_transform.sql','transform/land_and_property_transform.sql','2023-04-20 22:38:44','77f3e269736e203f5c332cf385ce803b'),('model.de_project.land_and_property_optimized_raw','land_and_property_optimized_raw','a11379caf3262a0b7ffe70a9cd89704359ea44d4151cc9029347356bccc9c8ca','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["source.de_project.project_dwh.land_and_property_optimized"]','','land_and_property_optimized_raw','de_project','models/raw/land_and_property_optimized_raw.sql','raw/land_and_property_optimized_raw.sql','2023-04-20 22:38:44','5ae3b3d8b2ba23e726c93ded56112e5b'),('model.elementary.snapshot_run_results','snapshot_run_results','25bf33e62e7405e06cff77de7ee9e748c7d9c6f28889e88eeb2975cdec933457','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.dbt_run_results", "model.elementary.dbt_snapshots"]','Run results of dbt snapshots, enriched with snapshots metadata. Each row is the result of a single snapshot. This is a view that joins data from `dbt_run_results` and `dbt_snapshots`.\n','snapshot_run_results','elementary','models/edr/run_results/snapshot_run_results.sql','edr/run_results/snapshot_run_results.sql','2023-04-20 22:38:44','b2e8ee2ee6429401a1749565ce18bbb8'),('model.elementary.job_run_results','job_run_results','4f77bef7722550578b36f29135d6c77fc2f0985e3e9362881f857f2bdf99ccdf','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.timediff"]','["model.elementary.dbt_invocations"]','Run results of dbt invocations, enriched with jobs metadata. Each row is the result of a single job. This is a view on `dbt_invocations`.','job_run_results','elementary','models/edr/run_results/job_run_results.sql','edr/run_results/job_run_results.sql','2023-04-20 22:38:44','cfe6d470f7287227f3b9d941e5ed6763'),('model.elementary.model_run_results','model_run_results','b13f8a6604ca22e1f7b968c6383ca9333cf443c852cc677e4b25985a5750d42c','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_time_trunc"]','["model.elementary.dbt_models", "model.elementary.dbt_run_results"]','Run results of dbt models, enriched with models metadata. Each row is the result of a single model. This is a view that joins data from `dbt_run_results` and `dbt_models`.\n','model_run_results','elementary','models/edr/run_results/model_run_results.sql','edr/run_results/model_run_results.sql','2023-04-20 22:38:44','b1b27b2c855f8f443b7a29ad7caf349f'),('model.elementary.test_result_rows','test_result_rows','f882d86b0cf618b35fd6f0825316eacf1be69fe55009f74551898a5be31962fc','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.backfill_result_rows", "macro.elementary.empty_table", "macro.elementary.get_config_var"]','["model.elementary.elementary_test_results", "model.elementary.elementary_test_results", "model.elementary.elementary_test_results"]','','test_result_rows','elementary','models/edr/run_results/test_result_rows.sql','edr/run_results/test_result_rows.sql','2023-04-20 22:38:44','aa11986de0436f139683e212b22e9e9b'),('model.elementary.elementary_test_results','elementary_test_results','7b92ed7eb8aa32dd1af920bc70ab408480f469992371aaa6e2fa9722927beb08','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_elementary_test_results", "macro.elementary.get_config_var"]','[]','Run results of all dbt tests, with fields and metadata needed to produce the Elementary report UI. Each row is the result of a single test, including native dbt tests, packages tests and elementary tests. New data is loaded to this model on an on-run-end hook named `elementary.handle_tests_results`.\n','elementary_test_results','elementary','models/edr/run_results/elementary_test_results.sql','edr/run_results/elementary_test_results.sql','2023-04-20 22:38:44','a24cdc13f2a59ca31fce11149bf64905'),('model.elementary.dbt_source_freshness_results','dbt_source_freshness_results','400e5c6af2b56ab6dc10bb33edfecb74988b768bf1091087e13795a5a32a0cdf','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_dbt_source_freshness_results", "macro.elementary.get_config_var"]','[]','','dbt_source_freshness_results','elementary','models/edr/run_results/dbt_source_freshness_results.sql','edr/run_results/dbt_source_freshness_results.sql','2023-04-20 22:38:44','1168a7a7f029edabcf6dc34051f5ca37'),('model.elementary.alerts_dbt_tests','alerts_dbt_tests','644e6360ece0829a8d77509903a110b8fca81b1dedf34b8cb8b5bdcc75f83922','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate dbt tests alerts, including all the fields the alert will include such as owner, tags, error message, etc. This view includes data about all dbt tests except elementary tests. It filters alerts according to configuration.\n','alerts_dbt_tests','elementary','models/edr/alerts/alerts_dbt_tests.sql','edr/alerts/alerts_dbt_tests.sql','2023-04-20 22:38:44','277e4a40cf57ab225729f6aa6a27be08'),('model.elementary.alerts_schema_changes','alerts_schema_changes','96c9a42ca06d726bff66c903a314b13c6beb1641347aba54d93710161d2391e1','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on schema changes detected using elementary tests. The view filters alerts according to configuration.','alerts_schema_changes','elementary','models/edr/alerts/alerts_schema_changes.sql','edr/alerts/alerts_schema_changes.sql','2023-04-20 22:38:44','257b4ac15bd154e52b832da313def902'),('model.elementary.alerts_dbt_source_freshness','alerts_dbt_source_freshness','ec03b412a62d28d45853ddb68502724c9bee8ae8bf16d203391711546f5904b0','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.dbt_source_freshness_results", "model.elementary.dbt_sources"]','','alerts_dbt_source_freshness','elementary','models/edr/alerts/alerts_dbt_source_freshness.sql','edr/alerts/alerts_dbt_source_freshness.sql','2023-04-20 22:38:44','f8d27490eeb21de3c129459fedd42899'),('model.elementary.alerts_anomaly_detection','alerts_anomaly_detection','0d2bb9c33ded81e6501643abeeacde1b21695f406b861f748923e4bd9ce0c4c8','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on data anomalies detected using the elementary anomaly detection tests. The view filters alerts according to configuration.\n','alerts_anomaly_detection','elementary','models/edr/alerts/alerts_anomaly_detection.sql','edr/alerts/alerts_anomaly_detection.sql','2023-04-20 22:38:44','abc8859218c6d0216fac24f1207f1bd9'),('model.elementary.alerts_dbt_models','alerts_dbt_models','aad00742146b5339efa4fbb9e8f475745116c1a6603d7a0999a2ba5d9e4392c6','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.model_run_results", "model.elementary.snapshot_run_results"]','A view that is used by the Elementary CLI to generate models alerts, including all the fields the alert will include such as owner, tags, error message, etc. It joins data about models and snapshots run results, and filters alerts according to configuration.\n','alerts_dbt_models','elementary','models/edr/alerts/alerts_dbt_models.sql','edr/alerts/alerts_dbt_models.sql','2023-04-20 22:38:44','853e5956cb3d5201c1f6ab18a3194491'),('model.elementary.monitors_runs','monitors_runs','3720e206635d4f2f95c193835727b0d533ec1a5fa56e5dec79331418d07e934f','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that is used to determine when a specific anomaly detection test was last executed. Each anomaly detection test queries this view to decide on a start time for collecting metrics.\n','monitors_runs','elementary','models/edr/system/monitors_runs.sql','edr/system/monitors_runs.sql','2023-04-20 22:38:44','fc5b979579f0fd4a9060a6f588a30220'),('model.elementary.metadata','metadata','08d0f5a6af1433ddf3b0077d85b594442a49901cd430729fd050c0417c48b5a2','table','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_elementary_package_version"]','[]','','metadata','elementary','models/edr/system/metadata.sql','edr/system/metadata.sql','2023-04-20 22:38:44','2d7e3e5b23a516456a352ca0fbc1603f'),('model.elementary.dbt_tests','dbt_tests','741409041141e4601052d37da988d545419809fd0c630fa7cfee31d75e66a5c2','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_tests_empty_table_query", "macro.elementary.upload_dbt_tests"]','[]','Metadata about tests in the project, including configuration and properties from the dbt graph. Each row contains information about a single test. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_tests','elementary','models/edr/dbt_artifacts/dbt_tests.sql','edr/dbt_artifacts/dbt_tests.sql','2023-04-20 22:38:44','582352ecff6170098dc8b5fd9c6b2de4'),('model.elementary.dbt_models','dbt_models','593b000e1d5ce7b219e4de4086c067491fb0333274ab375e793ccb2fb9fd3759','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.upload_dbt_models"]','[]','Metadata about models in the project, including configuration and properties from the dbt graph. Each row contains information about a single model. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_models','elementary','models/edr/dbt_artifacts/dbt_models.sql','edr/dbt_artifacts/dbt_models.sql','2023-04-20 22:38:44','45a6667f857b50814c08963227979fb7'),('model.elementary.dbt_sources','dbt_sources','d8a8439c596b52172075bc5b4106ba6c38d6dbfddbb83677b08815ea400bc712','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_sources_empty_table_query", "macro.elementary.upload_dbt_sources"]','[]','Metadata about sources in the project, including configuration and properties from the dbt graph. Each row contains information about a single source. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_sources','elementary','models/edr/dbt_artifacts/dbt_sources.sql','edr/dbt_artifacts/dbt_sources.sql','2023-04-20 22:38:44','4f5a6af3fc8463f8cba80ff847ac92e9'),('model.elementary.dbt_snapshots','dbt_snapshots','e9a4dd4bf0b0a9ec362d517a263768f9c09d319b49297618b0e68201241db006','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.upload_dbt_snapshots"]','[]','Metadata about snapshots in the project, including configuration and properties from the dbt graph. Each row contains information about a single snapshot. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_snapshots','elementary','models/edr/dbt_artifacts/dbt_snapshots.sql','edr/dbt_artifacts/dbt_snapshots.sql','2023-04-20 22:38:44','1fad44195b8c7d17da299adf691e5839'),('model.elementary.dbt_invocations','dbt_invocations','eb905380b5a7d9d7a1daab283bae14bea8800fff22a3a6d25f5d44fea739717f','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_invocations_empty_table_query"]','[]','Attributes associated with each dbt invocation. Inserted at the end of each invocation.\n','dbt_invocations','elementary','models/edr/dbt_artifacts/dbt_invocations.sql','edr/dbt_artifacts/dbt_invocations.sql','2023-04-20 22:38:44','21c91fb0fa00307fdb36d4ccfc5d13f5'),('model.elementary.dbt_metrics','dbt_metrics','346d0ae98ddf568e9102387d30aa7d9ee4c8c3c3ea58cd254e5e57fcb800f7e9','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_metrics_empty_table_query", "macro.elementary.upload_dbt_metrics"]','[]','Metadata about metics in the project, including configuration and properties from the dbt graph. Each row contains information about a single metric. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_metrics','elementary','models/edr/dbt_artifacts/dbt_metrics.sql','edr/dbt_artifacts/dbt_metrics.sql','2023-04-20 22:38:44','3996cb4cd74bfefd0fd9a88f5b170024'),('model.elementary.dbt_seeds','dbt_seeds','8daecb4cb68c55a0ad53ba73468d4537965acf2ccdc5c4343b9e1f4e3ae6f197','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_seeds_empty_table_query", "macro.elementary.upload_dbt_seeds"]','[]','','dbt_seeds','elementary','models/edr/dbt_artifacts/dbt_seeds.sql','edr/dbt_artifacts/dbt_seeds.sql','2023-04-20 22:38:44','f1d124eda9e29d0b21e9c31e6cf99aee'),('model.elementary.dbt_artifacts_hashes','dbt_artifacts_hashes','a493a63069e8e18354eb9fe4d6e0cd21f83f7efb7c9ffc1ff5cece8943b74f85','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.dbt_exposures", "model.elementary.dbt_metrics", "model.elementary.dbt_models", "model.elementary.dbt_seeds", "model.elementary.dbt_snapshots", "model.elementary.dbt_sources", "model.elementary.dbt_tests"]','','dbt_artifacts_hashes','elementary','models/edr/dbt_artifacts/dbt_artifacts_hashes.sql','edr/dbt_artifacts/dbt_artifacts_hashes.sql','2023-04-20 22:38:44','c11fe71d307067d4412509b15de1ed21'),('model.elementary.dbt_run_results','dbt_run_results','ecee798e20623bd3fe0d1822356a14c63f8a99e251ccf1aff743b0b3759c548d','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_run_results_empty_table_query"]','[]','Run results of dbt invocations, inserted at the end of each invocation. Each row is the invocation result of a single resource (model, test, snapshot, etc). New data is loaded to this model on an on-run-end hook named \'elementary.upload_run_results\' from each invocation that produces a result object. This is an incremental model.\n','dbt_run_results','elementary','models/edr/dbt_artifacts/dbt_run_results.sql','edr/dbt_artifacts/dbt_run_results.sql','2023-04-20 22:38:44','2bff3e8c2c1d0e9f67b04bb75ea7007e'),('model.elementary.dbt_exposures','dbt_exposures','8a682af36a6af01c41098c007da5b2fbe040cc282350e2817269b1b20b0f0e36','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_exposures_empty_table_query", "macro.elementary.upload_dbt_exposures"]','[]','Metadata about exposures in the project, including configuration and properties from the dbt graph. Each row contains information about a single exposure. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_exposures','elementary','models/edr/dbt_artifacts/dbt_exposures.sql','edr/dbt_artifacts/dbt_exposures.sql','2023-04-20 22:38:44','3db9239b91b8669ccd9a93cdc10b8901'),('model.elementary.metrics_anomaly_score','metrics_anomaly_score','abfd27ad29f3a4da67885dfd0c82ed98c043958f705c4258175db6c306d0795e','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.dbt_utils.group_by", "macro.elementary.edr_current_timestamp", "macro.elementary.edr_date_trunc", "macro.elementary.edr_timeadd", "macro.elementary.get_config_var"]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that runs the same query the anomaly detection tests run to calculate anomaly scores. The purpose of this view is to provide visibility to the results of anomaly detection tests.\n','metrics_anomaly_score','elementary','models/edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','2023-04-20 22:38:44','40815ab8a31b1886c8776436d0eeb6be'),('model.elementary.anomaly_threshold_sensitivity','anomaly_threshold_sensitivity','193ea3f501e775b7e3865e489edfff8936fed64d1f9063393292082e8a69d005','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_quote_column"]','["model.elementary.metrics_anomaly_score"]','This is a view on `metrics_anomaly_score` that calculates if values of metrics from latest runs would have been considered anomalies in different anomaly scores. This can help you decide if there is a need to adjust the `anomaly_score_threshold`.\n','anomaly_threshold_sensitivity','elementary','models/edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','2023-04-20 22:38:44','19252671a087e268e34e867f994c44ba'),('model.elementary.schema_columns_snapshot','schema_columns_snapshot','4026dd4e8a55d4d5811bdb27cd4214398607ed24bc5b3940ee40dbb4b42a4f2f','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_schema_columns_snapshot", "macro.elementary.get_config_var"]','[]','Stores the schema details for tables that are monitored with elementary schema changes test. In order to compare current schema to previous state, we must store the previous state. The data is from a view that queries the data warehouse information schema. This is an incremental table.\n','schema_columns_snapshot','elementary','models/edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','2023-04-20 22:38:44','85e17bc2cee1e746f638449c1f9c0dce'),('model.elementary.data_monitoring_metrics','data_monitoring_metrics','4654d1519d81eca2b622d05e7fd6a0c85fea9126025078173a6b99ff3418bbd2','incremental','[]','{"timestamp_column": "updated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_data_monitoring_metrics", "macro.elementary.get_config_var"]','[]','Elementary anomaly detection tests monitor metrics such as volume, freshness and data quality metrics. This incremental table is used to store the metrics over time. On each anomaly detection test, the test queries this table for historical metrics, and compares to the latest values. The table is updated with new metrics on the on-run-end named handle_test_results that is executed at the end of dbt test invocations.\n','data_monitoring_metrics','elementary','models/edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','2023-04-20 22:38:44','f04d74fc1abcf2f5ccce035084f09076'),('model.elementary.filtered_information_schema_columns','filtered_information_schema_columns','8b0602cbf990730afd02271c018d6843414aaff35c5d6e191c8711e570178d7b','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_table", "macro.elementary.get_configured_schemas_from_graph"]','[]','Queries the columns view from the information schema of the schemas in the project. This view is generated using an adapter specific macro, as information schema is different between platforms. This is a view to make the work with the information schema more convinient.\n','filtered_information_schema_columns','elementary','models/edr/metadata_store/filtered_information_schema_columns.sql','edr/metadata_store/filtered_information_schema_columns.sql','2023-04-20 22:38:44','7770ea68471155c6ad930fa2c688dcd7'),('model.elementary.filtered_information_schema_tables','filtered_information_schema_tables','89284ddd42994a960605b4f4de200adbdfc7e467e4bebb7d1debefbe8718839d','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_table", "macro.elementary.get_configured_schemas_from_graph"]','[]','Queries the tables and schemas views from the information schema of the schemas in the project. This view is generated using an adapter specific macro, as information schema is different between platforms. This is a view to make the work with the information schema more convinient.','filtered_information_schema_tables','elementary','models/edr/metadata_store/filtered_information_schema_tables.sql','edr/metadata_store/filtered_information_schema_tables.sql','2023-04-20 22:38:44','2d8307a460561db81f97c4a08828ee9f')
  
[0m22:38:47.459301 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:4be3090c-715d-4d36-a5ed-6f283f367849&page=queryresults
[0m22:38:47.462310 [debug] [Thread-3 (]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m22:38:47.465467 [debug] [Thread-3 (]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m22:38:47.474996 [debug] [Thread-3 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__tmp_20230420223847471091`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
        WHERE 1 = 0
    
    );
  
  
[0m22:38:48.787103 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:dd84ebec-7858-48f4-88e1-c55f26d1b52e&page=queryresults
[0m22:38:48.791973 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420223844531715`
    );
  
  
[0m22:38:49.011660 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:6437b266-352b-47bb-9364-d023d5ce4288&page=queryresults
[0m22:38:49.012499 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:7ec5a8e4-ab4c-4095-98e8-c9771f1bd59b&page=queryresults
[0m22:38:49.016836 [debug] [Thread-4 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__tmp_20230420223847180895`
    );
  
  
[0m22:38:49.019860 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_source_freshness_results (execute): 2023-04-20 22:38:46.295446 => 2023-04-20 22:38:49.019800
[0m22:38:49.023616 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11caf1450>]}
[0m22:38:49.024819 [info ] [Thread-1 (]: 10 of 32 OK created sql incremental model de_data_warehouse.dbt_source_freshness_results  [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 2.75s]
[0m22:38:49.026146 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_source_freshness_results
[0m22:38:49.027217 [debug] [Thread-1 (]: Began running node model.elementary.dbt_sources
[0m22:38:49.027713 [info ] [Thread-1 (]: 11 of 32 START sql incremental model de_data_warehouse.dbt_sources ............. [RUN]
[0m22:38:49.029061 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_sources'
[0m22:38:49.029382 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_sources
[0m22:38:49.061874 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_sources"
[0m22:38:49.062560 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_sources (compile): 2023-04-20 22:38:49.029561 => 2023-04-20 22:38:49.062479
[0m22:38:49.062965 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_sources
[0m22:38:49.071333 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_sources"
[0m22:38:49.072029 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:49.125960 [debug] [Thread-1 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as source_name

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as identifier

,
                
        cast('dummy_string' as string) as loaded_at_field

,
                
        cast('dummy_string' as string) as freshness_warn_after

,
                
        cast('dummy_string' as string) as freshness_error_after

,
                
        cast('this_is_just_a_long_dummy_string' as string) as freshness_filter

,
                
        cast('dummy_string' as string) as relation_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('this_is_just_a_long_dummy_string' as string) as source_description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:49.400037 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e63b19c8-a9a3-4abc-8ec2-74e88724acdc&page=queryresults
[0m22:38:49.403840 [debug] [Thread-3 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__tmp_20230420223847471091`
    );
  
  
[0m22:38:50.596269 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:a719f932-4d9c-484b-bbf5-1b19ec438624&page=queryresults
[0m22:38:50.599849 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_seeds (execute): 2023-04-20 22:38:44.534485 => 2023-04-20 22:38:50.599773
[0m22:38:50.601469 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:89e47d56-793d-46f4-a5f7-ec5d11c7ae45&page=queryresults
[0m22:38:50.602531 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c898ed0>]}
[0m22:38:50.604982 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_models (execute): 2023-04-20 22:38:41.763473 => 2023-04-20 22:38:50.604907
[0m22:38:50.605753 [info ] [Thread-4 (]: 8 of 32 OK created sql incremental model de_data_warehouse.dbt_seeds ........... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 6.22s]
[0m22:38:50.607303 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c52a7d0>]}
[0m22:38:50.607817 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_seeds
[0m22:38:50.608461 [info ] [Thread-2 (]: 6 of 32 OK created sql incremental model de_data_warehouse.dbt_models .......... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 8.90s]
[0m22:38:50.609408 [debug] [Thread-4 (]: Began running node model.elementary.dbt_tests
[0m22:38:50.610100 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_models
[0m22:38:50.610644 [info ] [Thread-4 (]: 12 of 32 START sql incremental model de_data_warehouse.dbt_tests ............... [RUN]
[0m22:38:50.611344 [debug] [Thread-2 (]: Began running node model.elementary.elementary_test_results
[0m22:38:50.612360 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_tests'
[0m22:38:50.612828 [info ] [Thread-2 (]: 13 of 32 START sql incremental model de_data_warehouse.elementary_test_results . [RUN]
[0m22:38:50.613377 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_tests
[0m22:38:50.614123 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.elementary_test_results'
[0m22:38:50.637582 [debug] [Thread-2 (]: Began compiling node model.elementary.elementary_test_results
[0m22:38:50.654817 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_tests"
[0m22:38:50.683092 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.elementary_test_results"
[0m22:38:50.683649 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_tests (compile): 2023-04-20 22:38:50.614478 => 2023-04-20 22:38:50.683581
[0m22:38:50.684069 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_tests
[0m22:38:50.690277 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_tests"
[0m22:38:50.690601 [debug] [Thread-2 (]: Timing info for model.elementary.elementary_test_results (compile): 2023-04-20 22:38:50.649235 => 2023-04-20 22:38:50.690525
[0m22:38:50.691035 [debug] [Thread-2 (]: Began executing node model.elementary.elementary_test_results
[0m22:38:50.696415 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.elementary_test_results"
[0m22:38:50.696951 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:38:50.697853 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:38:50.745254 [debug] [Thread-4 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
    
    
    OPTIONS()
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as short_name

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as test_column_name

,
                
        cast('dummy_string' as string) as severity

,
                
        cast('dummy_string' as string) as warn_if

,
                
        cast('dummy_string' as string) as error_if

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_params

,
                
        cast('dummy_string' as string) as test_namespace

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_owners

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('dummy_string' as string) as parent_model_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('dummy_string' as string) as type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:50.746481 [debug] [Thread-2 (]: On model.elementary.elementary_test_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.elementary_test_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
    
    
    OPTIONS()
    as (
      


    with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as id

,
                
        cast('dummy_string' as string) as data_issue_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_unique_id

,
                
        cast('dummy_string' as string) as invocation_id

,
                cast('2091-02-17' as TIMESTAMP) as detected_at

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as test_type

,
                
        cast('dummy_string' as string) as test_sub_type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_results_description

,
                
        cast('dummy_string' as string) as owners

,
                
        cast('dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_results_query

,
                
        cast('dummy_string' as string) as other

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_params

,
                
        cast('dummy_string' as string) as severity

,
                
        cast('dummy_string' as string) as status

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as string) as test_short_name

,
                
        cast('dummy_string' as string) as test_alias

,
                
        cast('this_is_just_a_long_dummy_string' as string) as result_rows


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m22:38:51.105555 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:553ec834-a8fb-4a1a-beba-a944fecb46ad&page=queryresults
[0m22:38:51.109038 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_snapshots (execute): 2023-04-20 22:38:45.242945 => 2023-04-20 22:38:51.108941
[0m22:38:51.111863 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c681590>]}
[0m22:38:51.112765 [info ] [Thread-3 (]: 9 of 32 OK created sql incremental model de_data_warehouse.dbt_snapshots ....... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 5.90s]
[0m22:38:51.113874 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_snapshots
[0m22:38:51.114833 [debug] [Thread-3 (]: Began running node model.elementary.filtered_information_schema_columns
[0m22:38:51.116433 [info ] [Thread-3 (]: 14 of 32 START sql view model de_data_warehouse.filtered_information_schema_columns  [RUN]
[0m22:38:51.117534 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.filtered_information_schema_columns'
[0m22:38:51.118166 [debug] [Thread-3 (]: Began compiling node model.elementary.filtered_information_schema_columns
[0m22:38:51.131760 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.filtered_information_schema_columns"
[0m22:38:51.134174 [debug] [Thread-3 (]: Timing info for model.elementary.filtered_information_schema_columns (compile): 2023-04-20 22:38:51.118575 => 2023-04-20 22:38:51.134038
[0m22:38:51.153839 [debug] [Thread-3 (]: Began executing node model.elementary.filtered_information_schema_columns
[0m22:38:51.161589 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.filtered_information_schema_columns"
[0m22:38:51.175653 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:38:51.221490 [debug] [Thread-3 (]: On model.elementary.filtered_information_schema_columns: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.filtered_information_schema_columns"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`filtered_information_schema_columns`
  OPTIONS()
  as 



with filtered_information_schema_columns as (
        with empty_table as (
            select
            
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as data_type


            )
        select * from empty_table
        where 1 = 0

)

select *
from filtered_information_schema_columns
where full_table_name is not null;


[0m22:38:51.379211 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:86b2a8c3-465d-4f92-8aaa-ee05ee80a909&page=queryresults
[0m22:38:51.384235 [debug] [Thread-1 (]: Elementary: [dbt_sources] Flattening the artifacts.
[0m22:38:51.403474 [debug] [Thread-1 (]: Elementary: [dbt_sources] Flattened 1 artifacts.
[0m22:38:51.409315 [debug] [Thread-1 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420223851405772`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
        WHERE 1 = 0
    
    );
  
  
[0m22:38:53.219389 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:003e8cc9-8790-46b4-b273-643068d5229c&page=queryresults
[0m22:38:53.226839 [debug] [Thread-3 (]: Timing info for model.elementary.filtered_information_schema_columns (execute): 2023-04-20 22:38:51.154397 => 2023-04-20 22:38:53.226778
[0m22:38:53.228588 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c5b2c10>]}
[0m22:38:53.230425 [info ] [Thread-3 (]: 14 of 32 OK created sql view model de_data_warehouse.filtered_information_schema_columns  [[32mCREATE VIEW (0 processed)[0m in 2.11s]
[0m22:38:53.232459 [debug] [Thread-3 (]: Finished running node model.elementary.filtered_information_schema_columns
[0m22:38:53.232887 [debug] [Thread-3 (]: Began running node model.elementary.filtered_information_schema_tables
[0m22:38:53.233414 [info ] [Thread-3 (]: 15 of 32 START sql view model de_data_warehouse.filtered_information_schema_tables  [RUN]
[0m22:38:53.234160 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.filtered_information_schema_tables'
[0m22:38:53.234493 [debug] [Thread-3 (]: Began compiling node model.elementary.filtered_information_schema_tables
[0m22:38:53.246658 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.filtered_information_schema_tables"
[0m22:38:53.247369 [debug] [Thread-3 (]: Timing info for model.elementary.filtered_information_schema_tables (compile): 2023-04-20 22:38:53.234679 => 2023-04-20 22:38:53.247284
[0m22:38:53.247705 [debug] [Thread-3 (]: Began executing node model.elementary.filtered_information_schema_tables
[0m22:38:53.252059 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.filtered_information_schema_tables"
[0m22:38:53.252661 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:38:53.301051 [debug] [Thread-3 (]: On model.elementary.filtered_information_schema_tables: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.filtered_information_schema_tables"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`filtered_information_schema_tables`
  OPTIONS()
  as 



with filtered_information_schema_tables as (
        with empty_table as (
            select
            
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as full_schema_name

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name


            )
        select * from empty_table
        where 1 = 0

)

select *
from filtered_information_schema_tables
where schema_name is not null;


[0m22:38:53.355093 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:15a977dc-fd82-498d-964e-62a104e59b4c&page=queryresults
[0m22:38:53.360369 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:6df72838-aca4-4ca0-8214-5b000a57c99f&page=queryresults
[0m22:38:53.362375 [debug] [Thread-2 (]: Timing info for model.elementary.elementary_test_results (execute): 2023-04-20 22:38:50.691360 => 2023-04-20 22:38:53.362328
[0m22:38:53.362780 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:51a18b63-42fa-484f-8d28-136fc4e62fb9&page=queryresults
[0m22:38:53.363373 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ca37cd0>]}
[0m22:38:53.365846 [debug] [Thread-4 (]: Elementary: [dbt_tests] Flattening the artifacts.
[0m22:38:53.366470 [info ] [Thread-2 (]: 13 of 32 OK created sql incremental model de_data_warehouse.elementary_test_results  [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 2.75s]
[0m22:38:53.369651 [debug] [Thread-4 (]: Elementary: [dbt_tests] Flattened 0 artifacts.
[0m22:38:53.370974 [debug] [Thread-2 (]: Finished running node model.elementary.elementary_test_results
[0m22:38:53.381612 [debug] [Thread-4 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__tmp_20230420223853377115`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
        WHERE 1 = 0
    
    );
  
  
[0m22:38:53.382190 [debug] [Thread-2 (]: Began running node model.elementary.metadata
[0m22:38:53.383830 [info ] [Thread-2 (]: 16 of 32 START sql table model de_data_warehouse.metadata ...................... [RUN]
[0m22:38:53.384899 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.metadata'
[0m22:38:53.385470 [debug] [Thread-2 (]: Began compiling node model.elementary.metadata
[0m22:38:53.390191 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.metadata"
[0m22:38:53.391634 [debug] [Thread-2 (]: Timing info for model.elementary.metadata (compile): 2023-04-20 22:38:53.385948 => 2023-04-20 22:38:53.391494
[0m22:38:53.392388 [debug] [Thread-2 (]: Began executing node model.elementary.metadata
[0m22:38:53.413555 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.metadata"
[0m22:38:53.414284 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:38:53.464665 [debug] [Thread-2 (]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.metadata"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`metadata`
    
    
    OPTIONS()
    as (
      

SELECT
    '0.7.5' as dbt_pkg_version
    );
  
[0m22:38:53.506224 [debug] [Thread-1 (]: Elementary: Inserting 1 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420223851405772`
[0m22:38:53.545663 [debug] [Thread-1 (]: Elementary: [1/1] Running insert query.
[0m22:38:53.547572 [debug] [Thread-1 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420223851405772`
         (unique_id,database_name,schema_name,source_name,name,identifier,loaded_at_field,freshness_warn_after,freshness_error_after,freshness_filter,relation_name,tags,meta,owner,package_name,original_path,path,source_description,description,generated_at,metadata_hash) values
    ('source.de_project.project_dwh.land_and_property_optimized','dtc-de-383113','project_dwh','project_dwh','land_and_property_optimized','land_and_property_optimized',NULL,'{"count": null, "period": null}','{"count": null, "period": null}',NULL,'`dtc-de-383113`.`project_dwh`.`land_and_property_optimized`','[]','{}',NULL,'de_project','models/raw/sources.yml','models/raw/sources.yml','','','2023-04-20 22:38:51','7aa3a0c9651057f4707b57c70a605438')
  
[0m22:38:54.505179 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8f4fbf22-b758-442b-b0b9-4c112e6e87e1&page=queryresults
[0m22:38:54.507555 [debug] [Thread-3 (]: Timing info for model.elementary.filtered_information_schema_tables (execute): 2023-04-20 22:38:53.247868 => 2023-04-20 22:38:54.507498
[0m22:38:54.508306 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cd67f50>]}
[0m22:38:54.508764 [info ] [Thread-3 (]: 15 of 32 OK created sql view model de_data_warehouse.filtered_information_schema_tables  [[32mCREATE VIEW (0 processed)[0m in 1.27s]
[0m22:38:54.509147 [debug] [Thread-3 (]: Finished running node model.elementary.filtered_information_schema_tables
[0m22:38:54.509460 [debug] [Thread-3 (]: Began running node model.elementary.schema_columns_snapshot
[0m22:38:54.509868 [info ] [Thread-3 (]: 17 of 32 START sql incremental model de_data_warehouse.schema_columns_snapshot . [RUN]
[0m22:38:54.510598 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.schema_columns_snapshot'
[0m22:38:54.510961 [debug] [Thread-3 (]: Began compiling node model.elementary.schema_columns_snapshot
[0m22:38:54.527841 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.schema_columns_snapshot"
[0m22:38:54.528774 [debug] [Thread-3 (]: Timing info for model.elementary.schema_columns_snapshot (compile): 2023-04-20 22:38:54.511164 => 2023-04-20 22:38:54.528690
[0m22:38:54.529089 [debug] [Thread-3 (]: Began executing node model.elementary.schema_columns_snapshot
[0m22:38:54.538023 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.schema_columns_snapshot"
[0m22:38:54.538949 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:38:54.595477 [debug] [Thread-3 (]: On model.elementary.schema_columns_snapshot: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.schema_columns_snapshot"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`schema_columns_snapshot`
    
    
    OPTIONS()
    as (
      


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as column_state_id

,
                
        cast('dummy_string' as string) as full_column_name

,
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as data_type

,
                
        cast (True as BOOL) as is_new

,
                cast('2091-02-17' as TIMESTAMP) as detected_at


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m22:38:55.022423 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ecd20f62-c7a9-4f43-8fcb-a3423ce7df7e&page=queryresults
[0m22:38:55.024750 [debug] [Thread-1 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420223851405772`
    );
  
  
[0m22:38:55.531116 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:caa4264c-481b-45c2-b76b-42fe32819df1&page=queryresults
[0m22:38:55.533083 [debug] [Thread-2 (]: Timing info for model.elementary.metadata (execute): 2023-04-20 22:38:53.392921 => 2023-04-20 22:38:55.533034
[0m22:38:55.533674 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ca0cd90>]}
[0m22:38:55.534184 [info ] [Thread-2 (]: 16 of 32 OK created sql table model de_data_warehouse.metadata ................. [[32mCREATE TABLE (1.0 rows, 0 processed)[0m in 2.15s]
[0m22:38:55.534908 [debug] [Thread-2 (]: Finished running node model.elementary.metadata
[0m22:38:55.535331 [debug] [Thread-2 (]: Began running node model.de_project.land_and_property_transform
[0m22:38:55.535763 [info ] [Thread-2 (]: 18 of 32 SKIP relation de_data_warehouse.land_and_property_transform ........... [[33mSKIP[0m]
[0m22:38:55.536258 [debug] [Thread-2 (]: Finished running node model.de_project.land_and_property_transform
[0m22:38:55.536870 [debug] [Thread-2 (]: Began running node model.elementary.metrics_anomaly_score
[0m22:38:55.537453 [info ] [Thread-2 (]: 19 of 32 START sql view model de_data_warehouse.metrics_anomaly_score .......... [RUN]
[0m22:38:55.538197 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.metrics_anomaly_score'
[0m22:38:55.538502 [debug] [Thread-2 (]: Began compiling node model.elementary.metrics_anomaly_score
[0m22:38:55.555599 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.metrics_anomaly_score"
[0m22:38:55.556333 [debug] [Thread-2 (]: Timing info for model.elementary.metrics_anomaly_score (compile): 2023-04-20 22:38:55.538919 => 2023-04-20 22:38:55.556252
[0m22:38:55.556668 [debug] [Thread-2 (]: Began executing node model.elementary.metrics_anomaly_score
[0m22:38:55.564697 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.metrics_anomaly_score"
[0m22:38:55.565400 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:38:55.614982 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.metrics_anomaly_score"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`
  OPTIONS()
  as 

with data_monitoring_metrics as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`

),

time_window_aggregation as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        metric_value,
        source_value,
        bucket_start,
        bucket_end,
        bucket_duration_hours,
        updated_at,
        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,
        stddev(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,
        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,
        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,
        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start
    from data_monitoring_metrics
    group by 1,2,3,4,5,6,7,8,9,10,11,12
),

metrics_anomaly_score as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        case
            when training_stddev is null then null
            when training_stddev = 0 then 0
            else (metric_value - training_avg) / (training_stddev)
        end as anomaly_score,
        metric_value as latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        max(updated_at) as updated_at
    from time_window_aggregation
        where
            metric_value is not null
            and training_avg is not null
            and training_set_size >= 14
            and bucket_end >= 
       timestamp_add(cast(
    timestamp_trunc(cast(current_timestamp as timestamp), day)
 as TIMESTAMP), INTERVAL cast(-7 as INT64) day)

    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    order by bucket_end desc


),

final as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        anomaly_score,
        latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        updated_at,
        case
            when abs(anomaly_score) > 3 then true
            else false end
        as is_anomaly
    from metrics_anomaly_score
)

select * from final;


[0m22:38:55.995576 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8be40385-50b6-4d60-8b13-3a6c1493e688&page=queryresults
[0m22:38:55.999564 [debug] [Thread-4 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__tmp_20230420223853377115`
    );
  
  
[0m22:38:56.607039 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:47b8806f-6ec1-4f6d-a6c6-9a80d24357c9&page=queryresults
[0m22:38:56.613010 [debug] [Thread-2 (]: Timing info for model.elementary.metrics_anomaly_score (execute): 2023-04-20 22:38:55.556849 => 2023-04-20 22:38:56.612868
[0m22:38:56.614734 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8b3010>]}
[0m22:38:56.615674 [info ] [Thread-2 (]: 19 of 32 OK created sql view model de_data_warehouse.metrics_anomaly_score ..... [[32mCREATE VIEW (0 processed)[0m in 1.08s]
[0m22:38:56.616282 [debug] [Thread-2 (]: Finished running node model.elementary.metrics_anomaly_score
[0m22:38:56.616850 [debug] [Thread-2 (]: Began running node model.elementary.monitors_runs
[0m22:38:56.617553 [info ] [Thread-2 (]: 20 of 32 START sql view model de_data_warehouse.monitors_runs .................. [RUN]
[0m22:38:56.619956 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.monitors_runs'
[0m22:38:56.620896 [debug] [Thread-2 (]: Began compiling node model.elementary.monitors_runs
[0m22:38:56.630074 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.monitors_runs"
[0m22:38:56.631040 [debug] [Thread-2 (]: Timing info for model.elementary.monitors_runs (compile): 2023-04-20 22:38:56.621280 => 2023-04-20 22:38:56.630959
[0m22:38:56.631347 [debug] [Thread-2 (]: Began executing node model.elementary.monitors_runs
[0m22:38:56.636406 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.monitors_runs"
[0m22:38:56.638169 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:38:56.656442 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:928ae14c-476b-4085-b4f6-97d913669c50&page=queryresults
[0m22:38:56.660929 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_sources (execute): 2023-04-20 22:38:49.063179 => 2023-04-20 22:38:56.660848
[0m22:38:56.661883 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c5b2490>]}
[0m22:38:56.662584 [info ] [Thread-1 (]: 11 of 32 OK created sql incremental model de_data_warehouse.dbt_sources ........ [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 7.63s]
[0m22:38:56.663488 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_sources
[0m22:38:56.663997 [debug] [Thread-1 (]: Began running node model.elementary.job_run_results
[0m22:38:56.664783 [info ] [Thread-1 (]: 21 of 32 START sql view model de_data_warehouse.job_run_results ................ [RUN]
[0m22:38:56.665588 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.job_run_results'
[0m22:38:56.665873 [debug] [Thread-1 (]: Began compiling node model.elementary.job_run_results
[0m22:38:56.680046 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.job_run_results"
[0m22:38:56.681226 [debug] [Thread-1 (]: Timing info for model.elementary.job_run_results (compile): 2023-04-20 22:38:56.666145 => 2023-04-20 22:38:56.681051
[0m22:38:56.681588 [debug] [Thread-1 (]: Began executing node model.elementary.job_run_results
[0m22:38:56.686590 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.job_run_results"
[0m22:38:56.687419 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:56.695751 [debug] [Thread-2 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.monitors_runs"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`monitors_runs`
  OPTIONS()
  as 

with data_monitoring_metrics as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`

),

max_bucket_end as (

    select full_table_name,
           column_name,
           metric_name,
           metric_properties,
           max(bucket_end) as last_bucket_end,
           min(bucket_end) as first_bucket_end
    from data_monitoring_metrics
    group by 1,2,3,4

)

select * from max_bucket_end;


[0m22:38:56.736401 [debug] [Thread-1 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.job_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`job_run_results`
  OPTIONS()
  as 





with jobs as (
  select
    job_name,
    job_id,
    job_run_id,
    
min(cast(run_started_at as TIMESTAMP))
 as job_run_started_at,
    
max(cast(run_completed_at as TIMESTAMP))
 as job_run_completed_at,
    
    timestamp_diff(
max(cast(run_completed_at as TIMESTAMP))
, 
min(cast(run_started_at as TIMESTAMP))
, second)
 as job_run_execution_time
  from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
  where job_id is not null
  group by job_name, job_id, job_run_id
)

select
  job_name as name,
  job_id as id,
  job_run_id as run_id,
  job_run_started_at as run_started_at,
  job_run_completed_at as run_completed_at,
  job_run_execution_time as run_execution_time
from jobs;


[0m22:38:56.901288 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e68330e0-2ddf-4efd-a925-8b392079ad4f&page=queryresults
[0m22:38:56.904282 [debug] [Thread-3 (]: Timing info for model.elementary.schema_columns_snapshot (execute): 2023-04-20 22:38:54.529270 => 2023-04-20 22:38:56.904203
[0m22:38:56.905290 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c86fbd0>]}
[0m22:38:56.905922 [info ] [Thread-3 (]: 17 of 32 OK created sql incremental model de_data_warehouse.schema_columns_snapshot  [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 2.39s]
[0m22:38:56.906502 [debug] [Thread-3 (]: Finished running node model.elementary.schema_columns_snapshot
[0m22:38:56.906966 [debug] [Thread-3 (]: Began running node model.elementary.model_run_results
[0m22:38:56.907513 [info ] [Thread-3 (]: 22 of 32 START sql view model de_data_warehouse.model_run_results .............. [RUN]
[0m22:38:56.908377 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.model_run_results'
[0m22:38:56.908728 [debug] [Thread-3 (]: Began compiling node model.elementary.model_run_results
[0m22:38:56.927679 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.model_run_results"
[0m22:38:56.928347 [debug] [Thread-3 (]: Timing info for model.elementary.model_run_results (compile): 2023-04-20 22:38:56.908947 => 2023-04-20 22:38:56.928268
[0m22:38:56.928600 [debug] [Thread-3 (]: Began executing node model.elementary.model_run_results
[0m22:38:56.935161 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.model_run_results"
[0m22:38:56.935968 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:38:56.986799 [debug] [Thread-3 (]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.model_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`model_run_results`
  OPTIONS()
  as 

with dbt_run_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
),

dbt_models as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.thread_id,
    models.database_name,
    models.schema_name,
    models.materialization,
    models.tags,
    models.package_name,
    models.path,
    models.original_path,
    models.owner,
    models.alias,
    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,
    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY 
    timestamp_trunc(cast(run_results.generated_at as timestamp), day)
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_first_invocation_of_the_day,
    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY 
    timestamp_trunc(cast(run_results.generated_at as timestamp), day)
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_last_invocation_of_the_day
    
FROM dbt_run_results run_results
JOIN dbt_models models ON run_results.unique_id = models.unique_id;


[0m22:38:57.674701 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:f3b867d3-775e-4694-9b24-aa1543e9e6a2&page=queryresults
[0m22:38:57.678360 [debug] [Thread-2 (]: Timing info for model.elementary.monitors_runs (execute): 2023-04-20 22:38:56.631647 => 2023-04-20 22:38:57.678281
[0m22:38:57.679873 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cc583d0>]}
[0m22:38:57.680661 [info ] [Thread-2 (]: 20 of 32 OK created sql view model de_data_warehouse.monitors_runs ............. [[32mCREATE VIEW (0 processed)[0m in 1.06s]
[0m22:38:57.681340 [debug] [Thread-2 (]: Finished running node model.elementary.monitors_runs
[0m22:38:57.681878 [debug] [Thread-2 (]: Began running node model.elementary.snapshot_run_results
[0m22:38:57.682526 [info ] [Thread-2 (]: 23 of 32 START sql view model de_data_warehouse.snapshot_run_results ........... [RUN]
[0m22:38:57.683996 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.snapshot_run_results'
[0m22:38:57.684910 [debug] [Thread-2 (]: Began compiling node model.elementary.snapshot_run_results
[0m22:38:57.694085 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.snapshot_run_results"
[0m22:38:57.694893 [debug] [Thread-2 (]: Timing info for model.elementary.snapshot_run_results (compile): 2023-04-20 22:38:57.685473 => 2023-04-20 22:38:57.694809
[0m22:38:57.695206 [debug] [Thread-2 (]: Began executing node model.elementary.snapshot_run_results
[0m22:38:57.700339 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.snapshot_run_results"
[0m22:38:57.702730 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:38:57.754136 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.snapshot_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`
  OPTIONS()
  as 

with dbt_run_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
),

dbt_snapshots as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.thread_id,
    snapshots.database_name,
    snapshots.schema_name,
    snapshots.materialization,
    snapshots.tags,
    snapshots.package_name,
    snapshots.path,
    snapshots.original_path,
    snapshots.owner,
    snapshots.alias
FROM dbt_run_results run_results
JOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id;


[0m22:38:57.793543 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:70c4d01f-b598-4e64-bba3-03c8dc5886a0&page=queryresults
[0m22:38:57.796406 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_tests (execute): 2023-04-20 22:38:50.684297 => 2023-04-20 22:38:57.796351
[0m22:38:57.798265 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cb72c10>]}
[0m22:38:57.800785 [info ] [Thread-4 (]: 12 of 32 OK created sql incremental model de_data_warehouse.dbt_tests .......... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 7.19s]
[0m22:38:57.801744 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_tests
[0m22:38:57.802163 [debug] [Thread-4 (]: Began running node model.elementary.alerts_anomaly_detection
[0m22:38:57.802609 [info ] [Thread-4 (]: 24 of 32 START sql view model de_data_warehouse.alerts_anomaly_detection ....... [RUN]
[0m22:38:57.803245 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.alerts_anomaly_detection'
[0m22:38:57.803529 [debug] [Thread-4 (]: Began compiling node model.elementary.alerts_anomaly_detection
[0m22:38:57.812431 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.alerts_anomaly_detection"
[0m22:38:57.813260 [debug] [Thread-4 (]: Timing info for model.elementary.alerts_anomaly_detection (compile): 2023-04-20 22:38:57.803867 => 2023-04-20 22:38:57.813109
[0m22:38:57.813691 [debug] [Thread-4 (]: Began executing node model.elementary.alerts_anomaly_detection
[0m22:38:57.820005 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.alerts_anomaly_detection"
[0m22:38:57.821595 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:38:57.876782 [debug] [Thread-4 (]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_anomaly_detection"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_anomaly_detection`
  OPTIONS()
  as 

with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_anomaly_detection as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'anomaly_detection'
)

select * from alerts_anomaly_detection;


[0m22:38:58.023438 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:f780c682-db0a-45dd-bf22-130a1652fa5a&page=queryresults
[0m22:38:58.026033 [debug] [Thread-3 (]: Timing info for model.elementary.model_run_results (execute): 2023-04-20 22:38:56.928750 => 2023-04-20 22:38:58.025939
[0m22:38:58.027475 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c5a7890>]}
[0m22:38:58.028695 [info ] [Thread-3 (]: 22 of 32 OK created sql view model de_data_warehouse.model_run_results ......... [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m22:38:58.029422 [debug] [Thread-3 (]: Finished running node model.elementary.model_run_results
[0m22:38:58.030246 [debug] [Thread-3 (]: Began running node model.elementary.alerts_dbt_tests
[0m22:38:58.030883 [info ] [Thread-3 (]: 25 of 32 START sql view model de_data_warehouse.alerts_dbt_tests ............... [RUN]
[0m22:38:58.031632 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_tests'
[0m22:38:58.032008 [debug] [Thread-3 (]: Began compiling node model.elementary.alerts_dbt_tests
[0m22:38:58.047948 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.alerts_dbt_tests"
[0m22:38:58.049356 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:418bc64f-0fad-4b17-8800-8f58c63a77fc&page=queryresults
[0m22:38:58.052187 [debug] [Thread-1 (]: Timing info for model.elementary.job_run_results (execute): 2023-04-20 22:38:56.681896 => 2023-04-20 22:38:58.052114
[0m22:38:58.052849 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_dbt_tests (compile): 2023-04-20 22:38:58.032268 => 2023-04-20 22:38:58.052736
[0m22:38:58.054249 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c9a3b90>]}
[0m22:38:58.055674 [debug] [Thread-3 (]: Began executing node model.elementary.alerts_dbt_tests
[0m22:38:58.056933 [info ] [Thread-1 (]: 21 of 32 OK created sql view model de_data_warehouse.job_run_results ........... [[32mCREATE VIEW (0 processed)[0m in 1.39s]
[0m22:38:58.064499 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.alerts_dbt_tests"
[0m22:38:58.065058 [debug] [Thread-1 (]: Finished running node model.elementary.job_run_results
[0m22:38:58.066081 [debug] [Thread-1 (]: Began running node model.elementary.alerts_schema_changes
[0m22:38:58.067007 [info ] [Thread-1 (]: 26 of 32 START sql view model de_data_warehouse.alerts_schema_changes .......... [RUN]
[0m22:38:58.068021 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.alerts_schema_changes'
[0m22:38:58.068348 [debug] [Thread-1 (]: Began compiling node model.elementary.alerts_schema_changes
[0m22:38:58.075320 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:38:58.082854 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.alerts_schema_changes"
[0m22:38:58.086039 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_schema_changes (compile): 2023-04-20 22:38:58.068743 => 2023-04-20 22:38:58.085862
[0m22:38:58.086577 [debug] [Thread-1 (]: Began executing node model.elementary.alerts_schema_changes
[0m22:38:58.094758 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.alerts_schema_changes"
[0m22:38:58.096424 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:38:58.151711 [debug] [Thread-3 (]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_tests"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_tests`
  OPTIONS()
  as 

with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_dbt_tests as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'dbt_test'
)

select * from alerts_dbt_tests;


[0m22:38:58.153052 [debug] [Thread-1 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_schema_changes"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_schema_changes`
  OPTIONS()
  as 


with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_schema_changes as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'schema_change'
)

select * from alerts_schema_changes;


[0m22:38:58.635790 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:117131e2-b577-4a81-9332-b3afee89fde7&page=queryresults
[0m22:38:58.638604 [debug] [Thread-4 (]: Timing info for model.elementary.alerts_anomaly_detection (execute): 2023-04-20 22:38:57.813860 => 2023-04-20 22:38:58.638536
[0m22:38:58.640412 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cdb5c50>]}
[0m22:38:58.641554 [info ] [Thread-4 (]: 24 of 32 OK created sql view model de_data_warehouse.alerts_anomaly_detection .. [[32mCREATE VIEW (0 processed)[0m in 0.84s]
[0m22:38:58.643001 [debug] [Thread-4 (]: Finished running node model.elementary.alerts_anomaly_detection
[0m22:38:58.643914 [debug] [Thread-4 (]: Began running node model.elementary.test_result_rows
[0m22:38:58.644809 [info ] [Thread-4 (]: 27 of 32 START sql incremental model de_data_warehouse.test_result_rows ........ [RUN]
[0m22:38:58.645848 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.test_result_rows'
[0m22:38:58.646199 [debug] [Thread-4 (]: Began compiling node model.elementary.test_result_rows
[0m22:38:58.661070 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.test_result_rows"
[0m22:38:58.662247 [debug] [Thread-4 (]: Timing info for model.elementary.test_result_rows (compile): 2023-04-20 22:38:58.646428 => 2023-04-20 22:38:58.662169
[0m22:38:58.662580 [debug] [Thread-4 (]: Began executing node model.elementary.test_result_rows
[0m22:38:58.667333 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.test_result_rows"
[0m22:38:58.668116 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:38:58.729416 [debug] [Thread-4 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.test_result_rows"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`test_result_rows`
    
    
    OPTIONS()
    as (
      

-- depends_on: `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as elementary_test_results_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as result_row

,
                cast('2091-02-17' as TIMESTAMP) as detected_at


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:38:58.732298 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8c8b124f-cd0c-46f5-a439-42f17364cd7d&page=queryresults
[0m22:38:58.734264 [debug] [Thread-2 (]: Timing info for model.elementary.snapshot_run_results (execute): 2023-04-20 22:38:57.695410 => 2023-04-20 22:38:58.734206
[0m22:38:58.736321 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c640210>]}
[0m22:38:58.736831 [info ] [Thread-2 (]: 23 of 32 OK created sql view model de_data_warehouse.snapshot_run_results ...... [[32mCREATE VIEW (0 processed)[0m in 1.05s]
[0m22:38:58.737865 [debug] [Thread-2 (]: Finished running node model.elementary.snapshot_run_results
[0m22:38:58.738572 [debug] [Thread-2 (]: Began running node model.de_project.final_land_and_property
[0m22:38:58.740167 [info ] [Thread-2 (]: 28 of 32 SKIP relation de_data_warehouse.final_land_and_property ............... [[33mSKIP[0m]
[0m22:38:58.741253 [debug] [Thread-2 (]: Finished running node model.de_project.final_land_and_property
[0m22:38:58.741719 [debug] [Thread-2 (]: Began running node model.elementary.anomaly_threshold_sensitivity
[0m22:38:58.742211 [info ] [Thread-2 (]: 29 of 32 START sql view model de_data_warehouse.anomaly_threshold_sensitivity .. [RUN]
[0m22:38:58.743198 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.anomaly_threshold_sensitivity'
[0m22:38:58.744069 [debug] [Thread-2 (]: Began compiling node model.elementary.anomaly_threshold_sensitivity
[0m22:38:58.760587 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.anomaly_threshold_sensitivity"
[0m22:38:58.761556 [debug] [Thread-2 (]: Timing info for model.elementary.anomaly_threshold_sensitivity (compile): 2023-04-20 22:38:58.744479 => 2023-04-20 22:38:58.761383
[0m22:38:58.762204 [debug] [Thread-2 (]: Began executing node model.elementary.anomaly_threshold_sensitivity
[0m22:38:58.768607 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.anomaly_threshold_sensitivity"
[0m22:38:58.769379 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:38:58.824025 [debug] [Thread-2 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`anomaly_threshold_sensitivity`
  OPTIONS()
  as 

with metrics_anomaly_score as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`

),

score_sensitivity as (

    select
        full_table_name,
        column_name,
        metric_name,
        latest_metric_value,
        training_avg as metric_avg,
        training_stddev as metric_stddev,
        anomaly_score,
        case when abs(anomaly_score) >= 1.5 then true else false end as `is_anomaly_1_5`,
        case when abs(anomaly_score) >= 2 then true else false end as `is_anomaly_2`,
        case when abs(anomaly_score) >= 2.5 then true else false end as `is_anomaly_2_5`,
        case when abs(anomaly_score) >= 3 then true else false end as `is_anomaly_3`,
        case when abs(anomaly_score) >= 3.5 then true else false end as `is_anomaly_3_5`,
        case when abs(anomaly_score) >= 4 then true else false end as `is_anomaly_4`,
        case when abs(anomaly_score) >= 4.5 then true else false end as `is_anomaly_4_5`
    from metrics_anomaly_score
    where abs(anomaly_score) >= 1.5

)

select * from score_sensitivity;


[0m22:38:59.222027 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5b1c0b7d-88af-4474-b1e6-3ae3f7675e1c&page=queryresults
[0m22:38:59.227274 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_dbt_tests (execute): 2023-04-20 22:38:58.057679 => 2023-04-20 22:38:59.227143
[0m22:38:59.228697 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cde55d0>]}
[0m22:38:59.494197 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:d623b1ff-964f-478d-9cd4-396a90009845&page=queryresults
[0m22:38:59.496350 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_schema_changes (execute): 2023-04-20 22:38:58.087062 => 2023-04-20 22:38:59.496305
[0m22:38:59.496979 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ca0fad0>]}
[0m22:38:59.901365 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:35546300-ada2-40df-adf7-85280bcbeb69&page=queryresults
[0m22:38:59.903297 [debug] [Thread-2 (]: Timing info for model.elementary.anomaly_threshold_sensitivity (execute): 2023-04-20 22:38:58.762584 => 2023-04-20 22:38:59.903253
[0m22:38:59.903903 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c57d490>]}
[0m22:39:00.543192 [info ] [Thread-3 (]: 25 of 32 OK created sql view model de_data_warehouse.alerts_dbt_tests .......... [[32mCREATE VIEW (0 processed)[0m in 1.20s]
[0m22:39:00.543851 [info ] [Thread-1 (]: 26 of 32 OK created sql view model de_data_warehouse.alerts_schema_changes ..... [[32mCREATE VIEW (0 processed)[0m in 1.43s]
[0m22:39:00.544418 [info ] [Thread-2 (]: 29 of 32 OK created sql view model de_data_warehouse.anomaly_threshold_sensitivity  [[32mCREATE VIEW (0 processed)[0m in 1.16s]
[0m22:39:00.545014 [debug] [Thread-3 (]: Finished running node model.elementary.alerts_dbt_tests
[0m22:39:00.545380 [debug] [Thread-1 (]: Finished running node model.elementary.alerts_schema_changes
[0m22:39:00.545735 [debug] [Thread-2 (]: Finished running node model.elementary.anomaly_threshold_sensitivity
[0m22:39:00.546111 [debug] [Thread-3 (]: Began running node model.elementary.alerts_dbt_source_freshness
[0m22:39:00.546596 [debug] [Thread-1 (]: Began running node model.elementary.dbt_artifacts_hashes
[0m22:39:00.547095 [debug] [Thread-2 (]: Began running node model.elementary.alerts_dbt_models
[0m22:39:00.547578 [info ] [Thread-3 (]: 30 of 32 START sql view model de_data_warehouse.alerts_dbt_source_freshness .... [RUN]
[0m22:39:00.548130 [info ] [Thread-1 (]: 31 of 32 START sql view model de_data_warehouse.dbt_artifacts_hashes ........... [RUN]
[0m22:39:00.548721 [info ] [Thread-2 (]: 32 of 32 START sql view model de_data_warehouse.alerts_dbt_models .............. [RUN]
[0m22:39:00.549543 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_source_freshness'
[0m22:39:00.550221 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_artifacts_hashes'
[0m22:39:00.551028 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_models'
[0m22:39:00.551733 [debug] [Thread-3 (]: Began compiling node model.elementary.alerts_dbt_source_freshness
[0m22:39:00.552149 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_artifacts_hashes
[0m22:39:00.552615 [debug] [Thread-2 (]: Began compiling node model.elementary.alerts_dbt_models
[0m22:39:00.559498 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.alerts_dbt_source_freshness"
[0m22:39:00.564615 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_artifacts_hashes"
[0m22:39:00.574936 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.alerts_dbt_models"
[0m22:39:00.576090 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_dbt_source_freshness (compile): 2023-04-20 22:39:00.552920 => 2023-04-20 22:39:00.575933
[0m22:39:00.576693 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_artifacts_hashes (compile): 2023-04-20 22:39:00.559826 => 2023-04-20 22:39:00.576591
[0m22:39:00.577076 [debug] [Thread-3 (]: Began executing node model.elementary.alerts_dbt_source_freshness
[0m22:39:00.577622 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_dbt_models (compile): 2023-04-20 22:39:00.564908 => 2023-04-20 22:39:00.577484
[0m22:39:00.578070 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_artifacts_hashes
[0m22:39:00.583815 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.alerts_dbt_source_freshness"
[0m22:39:00.584434 [debug] [Thread-2 (]: Began executing node model.elementary.alerts_dbt_models
[0m22:39:00.594287 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_artifacts_hashes"
[0m22:39:00.600806 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.alerts_dbt_models"
[0m22:39:00.601167 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:39:00.602351 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:39:00.602964 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:39:00.653929 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_models"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_models`
  OPTIONS()
  as 

with error_models as (
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias 
    from `dtc-de-383113`.`de_data_warehouse`.`model_run_results`
  
    union all
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias  
  from `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`
)


select model_execution_id as alert_id,
       unique_id,
       generated_at as detected_at,
       database_name,
       materialization,
       path,
       original_path,
       schema_name,
       message,
       owner as owners,
       tags,
       alias,
       status,
       full_refresh
from error_models
where True and lower(status) != 'success'and lower(status) != 'skipped';


[0m22:39:00.655500 [debug] [Thread-1 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_artifacts_hashes"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`dbt_artifacts_hashes`
  OPTIONS()
  as 




select
  'dbt_models' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
 union all 

select
  'dbt_tests' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
 union all 

select
  'dbt_sources' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
 union all 

select
  'dbt_snapshots' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
 union all 

select
  'dbt_metrics' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
 union all 

select
  'dbt_exposures' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
 union all 

select
  'dbt_seeds' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`


order by metadata_hash;


[0m22:39:00.655833 [debug] [Thread-3 (]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_source_freshness"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_source_freshness`
  OPTIONS()
  as 

with results as (
  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`
),

sources as (
  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
)

select
  results.source_freshness_execution_id as alert_id,
  results.max_loaded_at,
  results.snapshotted_at,
  results.generated_at as detected_at,
  results.max_loaded_at_time_ago_in_s,
  results.status,
  results.error,
  sources.unique_id,
  sources.database_name,
  sources.schema_name,
  sources.source_name,
  sources.identifier,
  sources.freshness_error_after,
  sources.freshness_warn_after,
  sources.freshness_filter,
  sources.tags,
  sources.meta,
  sources.owner,
  sources.package_name,
  sources.path
from results
join sources on results.unique_id = sources.unique_id
where True and lower(status) != 'pass';


[0m22:39:01.258216 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:9cbd79a4-1f73-4d37-abfc-35dcad0d5754&page=queryresults
[0m22:39:01.807124 [debug] [Thread-4 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.test_result_rows"} */

    
        select
        id,
        detected_at,
        result_rows
        from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
        where 
        timestamp_diff(current_timestamp, cast(detected_at as TIMESTAMP), day)
 < 14
        and result_rows is not null
    
  
[0m22:39:02.228994 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:360515f5-9096-4c13-b249-d61bbe538824&page=queryresults
[0m22:39:02.233297 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c2b17d8a-74d5-476c-bdb6-3ff6842db331&page=queryresults
[0m22:39:02.236982 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_dbt_source_freshness (execute): 2023-04-20 22:39:00.578521 => 2023-04-20 22:39:02.236844
[0m22:39:02.240683 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_artifacts_hashes (execute): 2023-04-20 22:39:00.584712 => 2023-04-20 22:39:02.240614
[0m22:39:02.242094 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:1dea2054-9a2b-45d2-9982-aad9fca486bf&page=queryresults
[0m22:39:02.243115 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8ba450>]}
[0m22:39:02.243913 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ca6db10>]}
[0m22:39:02.246985 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_dbt_models (execute): 2023-04-20 22:39:00.594620 => 2023-04-20 22:39:02.246912
[0m22:39:02.247718 [info ] [Thread-3 (]: 30 of 32 OK created sql view model de_data_warehouse.alerts_dbt_source_freshness  [[32mCREATE VIEW (0 processed)[0m in 1.69s]
[0m22:39:02.248407 [info ] [Thread-1 (]: 31 of 32 OK created sql view model de_data_warehouse.dbt_artifacts_hashes ...... [[32mCREATE VIEW (0 processed)[0m in 1.69s]
[0m22:39:02.249435 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c8fbdd0>]}
[0m22:39:02.249803 [debug] [Thread-3 (]: Finished running node model.elementary.alerts_dbt_source_freshness
[0m22:39:02.250330 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_artifacts_hashes
[0m22:39:02.251122 [info ] [Thread-2 (]: 32 of 32 OK created sql view model de_data_warehouse.alerts_dbt_models ......... [[32mCREATE VIEW (0 processed)[0m in 1.70s]
[0m22:39:02.252342 [debug] [Thread-2 (]: Finished running node model.elementary.alerts_dbt_models
[0m22:39:05.130333 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:4af942a0-cab4-41d4-b3c6-942d50899a05&page=queryresults
[0m22:39:05.133151 [debug] [Thread-4 (]: Timing info for model.elementary.test_result_rows (execute): 2023-04-20 22:38:58.662771 => 2023-04-20 22:39:05.133097
[0m22:39:05.133840 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '3b2cdcc9-d2c2-4956-9b2b-722740ee324f', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c86e6d0>]}
[0m22:39:05.134270 [info ] [Thread-4 (]: 27 of 32 OK created sql incremental model de_data_warehouse.test_result_rows ... [[32mCREATE TABLE (0.0 rows, 0 processed)[0m in 6.49s]
[0m22:39:05.134798 [debug] [Thread-4 (]: Finished running node model.elementary.test_result_rows
[0m22:39:05.136911 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:39:05.137343 [info ] [MainThread]: 
[0m22:39:05.138006 [info ] [MainThread]: Running 1 on-run-end hook
[0m22:39:05.165670 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:39:05.218683 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from `dtc-de-383113`.`de_data_warehouse`.`dbt_artifacts_hashes`
    order by metadata_hash
    
  
[0m22:39:06.964669 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:21c7ade7-1dd8-4822-83c1-2f4a609f87c5&page=queryresults
[0m22:39:06.968422 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:39:06.979819 [debug] [MainThread]: Elementary: [dbt_models] Artifacts already ran.
[0m22:39:06.983621 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts already ran.
[0m22:39:06.986384 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts already ran.
[0m22:39:06.989232 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts already ran.
[0m22:39:06.992234 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts already ran.
[0m22:39:06.993715 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts already ran.
[0m22:39:06.995536 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts already ran.
[0m22:39:07.002081 [debug] [MainThread]: Elementary: Uploading run results.
[0m22:39:07.005151 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m22:39:07.170497 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 32 artifacts.
[0m22:39:07.357683 [debug] [MainThread]: Elementary: Inserting 32 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
[0m22:39:07.916237 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:39:07.919109 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
         (model_execution_id,unique_id,invocation_id,generated_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id) values
    ('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.de_project.land_and_property_optimized_raw','model.de_project.land_and_property_optimized_raw','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','land_and_property_optimized_raw','Runtime Error in model land_and_property_optimized_raw (models/raw/land_and_property_optimized_raw.sql)\n  404 Not found: Dataset dtc-de-383113:project_dwh was not found in location europe-west6\n  \n  Location: europe-west6\n  Job ID: 6bb899ab-6b50-4354-9049-ecccfa078226\n  ','error','model',1.285677194595337,NULL,NULL,NULL,NULL,NULL,False,'with source as (\n      select * from `dtc-de-383113`.`project_dwh`.`land_and_property_optimized`\n)\nselect * from source',NULL,NULL,'Thread-1 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.data_monitoring_metrics','model.elementary.data_monitoring_metrics','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','data_monitoring_metrics','CREATE TABLE (0.0 rows, 0 processed)','success','model',3.3893208503723145,'2023-04-20T22:38:38.546595Z','2023-04-20T22:38:41.701061Z','2023-04-20T22:38:38.327605Z','2023-04-20T22:38:38.456574Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as id\n\n,\n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as metric_name\n\n,\n                \n        cast(123456789.99 as FLOAT64) as metric_value\n\n,\n                \n        cast(\'dummy_string\' as string) as source_value\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as bucket_start\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as bucket_end\n\n,\n                \n        cast(123456789 as INT64) as bucket_duration_hours\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as updated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as dimension\n\n,\n                \n        cast(\'dummy_string\' as string) as dimension_value\n\n,\n                \n        cast(\'dummy_string\' as string) as metric_properties\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_invocations','model.elementary.dbt_invocations','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_invocations','CREATE TABLE (0.0 rows, 0 processed)','success','model',3.3863861560821533,'2023-04-20T22:38:38.465778Z','2023-04-20T22:38:41.703111Z','2023-04-20T22:38:38.358035Z','2023-04-20T22:38:38.424595Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as invocation_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_run_id\n\n,\n                \n        cast(\'dummy_string\' as string) as run_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as run_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as command\n\n,\n                \n        cast(\'dummy_string\' as string) as dbt_version\n\n,\n                \n        cast(\'dummy_string\' as string) as elementary_version\n\n,\n                \n        cast (True as BOOL) as full_refresh\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as invocation_vars\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as vars\n\n,\n                \n        cast(\'dummy_string\' as string) as target_name\n\n,\n                \n        cast(\'dummy_string\' as string) as target_database\n\n,\n                \n        cast(\'dummy_string\' as string) as target_schema\n\n,\n                \n        cast(\'dummy_string\' as string) as target_profile_name\n\n,\n                \n        cast(123456789 as INT64) as threads\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as selected\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as yaml_selector\n\n,\n                \n        cast(\'dummy_string\' as string) as project_id\n\n,\n                \n        cast(\'dummy_string\' as string) as project_name\n\n,\n                \n        cast(\'dummy_string\' as string) as env\n\n,\n                \n        cast(\'dummy_string\' as string) as env_id\n\n,\n                \n        cast(\'dummy_string\' as string) as cause_category\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as cause\n\n,\n                \n        cast(\'dummy_string\' as string) as pull_request_id\n\n,\n                \n        cast(\'dummy_string\' as string) as git_sha\n\n,\n                \n        cast(\'dummy_string\' as string) as orchestrator\n\n,\n                \n        cast(\'dummy_string\' as string) as dbt_user\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_run_results','model.elementary.dbt_run_results','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_run_results','CREATE TABLE (0.0 rows, 0 processed)','success','model',2.608203887939453,'2023-04-20T22:38:41.772582Z','2023-04-20T22:38:44.318251Z','2023-04-20T22:38:41.736365Z','2023-04-20T22:38:41.763276Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_execution_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as message\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(\'dummy_string\' as string) as resource_type\n\n,\n                \n        cast(123456789.99 as FLOAT64) as execution_time\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_completed_at\n\n,\n                \n        cast(31474836478 as bigint) as rows_affected\n\n,\n                \n        cast (True as BOOL) as full_refresh\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as compiled_code\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast(\'dummy_string\' as string) as query_id\n\n,\n                \n        cast(\'dummy_string\' as string) as thread_id\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_exposures','model.elementary.dbt_exposures','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_exposures','CREATE TABLE (0.0 rows, 0 processed)','success','model',6.893661975860596,'2023-04-20T22:38:38.512153Z','2023-04-20T22:38:45.208439Z','2023-04-20T22:38:38.334365Z','2023-04-20T22:38:38.424986Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as maturity\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'dummy_string\' as string) as owner_email\n\n,\n                \n        cast(\'dummy_string\' as string) as owner_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as url\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_metrics','model.elementary.dbt_metrics','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_metrics','CREATE TABLE (0.0 rows, 0 processed)','success','model',6.661636829376221,'2023-04-20T22:38:39.633789Z','2023-04-20T22:38:46.263015Z','2023-04-20T22:38:39.602850Z','2023-04-20T22:38:39.633220Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as label\n\n,\n                \n        cast(\'dummy_string\' as string) as model\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as sql\n\n,\n                \n        cast(\'dummy_string\' as string) as timestamp\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as filters\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as time_grains\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as dimensions\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-1 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_source_freshness_results','model.elementary.dbt_source_freshness_results','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_source_freshness_results','CREATE TABLE (0.0 rows, 0 processed)','success','model',2.7536089420318604,'2023-04-20T22:38:46.295446Z','2023-04-20T22:38:49.019800Z','2023-04-20T22:38:46.271759Z','2023-04-20T22:38:46.294943Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as source_freshness_execution_id\n\n,\n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as max_loaded_at\n\n,\n                \n        cast(\'dummy_string\' as string) as snapshotted_at\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(123456789.99 as FLOAT64) as max_loaded_at_time_ago_in_s\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(\'dummy_string\' as string) as error\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-1 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_seeds','model.elementary.dbt_seeds','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_seeds','CREATE TABLE (0.0 rows, 0 processed)','success','model',6.218338251113892,'2023-04-20T22:38:44.534485Z','2023-04-20T22:38:50.599773Z','2023-04-20T22:38:44.413888Z','2023-04-20T22:38:44.522832Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_models','model.elementary.dbt_models','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_models','CREATE TABLE (0.0 rows, 0 processed)','success','model',8.897088050842285,'2023-04-20T22:38:41.763473Z','2023-04-20T22:38:50.604907Z','2023-04-20T22:38:41.712396Z','2023-04-20T22:38:41.762545Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'dummy_string\' as string) as materialization\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_snapshots','model.elementary.dbt_snapshots','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_snapshots','CREATE TABLE (0.0 rows, 0 processed)','success','model',5.899921178817749,'2023-04-20T22:38:45.242945Z','2023-04-20T22:38:51.108941Z','2023-04-20T22:38:45.212983Z','2023-04-20T22:38:45.242260Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'dummy_string\' as string) as materialization\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.filtered_information_schema_columns','model.elementary.filtered_information_schema_columns','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','filtered_information_schema_columns','CREATE VIEW (0 processed)','success','model',2.1114327907562256,'2023-04-20T22:38:51.154397Z','2023-04-20T22:38:53.226778Z','2023-04-20T22:38:51.118575Z','2023-04-20T22:38:51.134038Z',NULL,False,'\n\n\n\nwith filtered_information_schema_columns as (\n        with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as data_type\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n\n)\n\nselect *\nfrom filtered_information_schema_columns\nwhere full_table_name is not null',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.elementary_test_results','model.elementary.elementary_test_results','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','elementary_test_results','CREATE TABLE (0.0 rows, 0 processed)','success','model',2.7495970726013184,'2023-04-20T22:38:50.691360Z','2023-04-20T22:38:53.362328Z','2023-04-20T22:38:50.649235Z','2023-04-20T22:38:50.690525Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as id\n\n,\n                \n        cast(\'dummy_string\' as string) as data_issue_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_execution_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_unique_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as test_type\n\n,\n                \n        cast(\'dummy_string\' as string) as test_sub_type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_results_description\n\n,\n                \n        cast(\'dummy_string\' as string) as owners\n\n,\n                \n        cast(\'dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_results_query\n\n,\n                \n        cast(\'dummy_string\' as string) as other\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_params\n\n,\n                \n        cast(\'dummy_string\' as string) as severity\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast(\'dummy_string\' as string) as test_short_name\n\n,\n                \n        cast(\'dummy_string\' as string) as test_alias\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as result_rows\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.filtered_information_schema_tables','model.elementary.filtered_information_schema_tables','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','filtered_information_schema_tables','CREATE VIEW (0 processed)','success','model',1.2744698524475098,'2023-04-20T22:38:53.247868Z','2023-04-20T22:38:54.507498Z','2023-04-20T22:38:53.234679Z','2023-04-20T22:38:53.247284Z',NULL,False,'\n\n\n\nwith filtered_information_schema_tables as (\n        with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as full_schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n\n)\n\nselect *\nfrom filtered_information_schema_tables\nwhere schema_name is not null',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.metadata','model.elementary.metadata','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','metadata','CREATE TABLE (1.0 rows, 0 processed)','success','model',2.1492390632629395,'2023-04-20T22:38:53.392921Z','2023-04-20T22:38:55.533034Z','2023-04-20T22:38:53.385948Z','2023-04-20T22:38:53.391494Z',1,False,'\n\nSELECT\n    \'0.7.5\' as dbt_pkg_version',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.de_project.land_and_property_transform','model.de_project.land_and_property_transform','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','land_and_property_transform',NULL,'skipped','model',0.0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.metrics_anomaly_score','model.elementary.metrics_anomaly_score','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','metrics_anomaly_score','CREATE VIEW (0 processed)','success','model',1.0764949321746826,'2023-04-20T22:38:55.556849Z','2023-04-20T22:38:56.612868Z','2023-04-20T22:38:55.538919Z','2023-04-20T22:38:55.556252Z',NULL,False,'\n\nwith data_monitoring_metrics as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`\n\n),\n\ntime_window_aggregation as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        metric_value,\n        source_value,\n        bucket_start,\n        bucket_end,\n        bucket_duration_hours,\n        updated_at,\n        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,\n        stddev(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,\n        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,\n        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,\n        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start\n    from data_monitoring_metrics\n    group by 1,2,3,4,5,6,7,8,9,10,11,12\n),\n\nmetrics_anomaly_score as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        case\n            when training_stddev is null then null\n            when training_stddev = 0 then 0\n            else (metric_value - training_avg) / (training_stddev)\n        end as anomaly_score,\n        metric_value as latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        max(updated_at) as updated_at\n    from time_window_aggregation\n        where\n            metric_value is not null\n            and training_avg is not null\n            and training_set_size >= 14\n            and bucket_end >= \n       timestamp_add(cast(\n    timestamp_trunc(cast(current_timestamp as timestamp), day)\n as TIMESTAMP), INTERVAL cast(-7 as INT64) day)\n\n    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\n    order by bucket_end desc\n\n\n),\n\nfinal as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        anomaly_score,\n        latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        updated_at,\n        case\n            when abs(anomaly_score) > 3 then true\n            else false end\n        as is_anomaly\n    from metrics_anomaly_score\n)\n\nselect * from final',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_sources','model.elementary.dbt_sources','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_sources','CREATE TABLE (0.0 rows, 0 processed)','success','model',7.633256912231445,'2023-04-20T22:38:49.063179Z','2023-04-20T22:38:56.660848Z','2023-04-20T22:38:49.029561Z','2023-04-20T22:38:49.062479Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as source_name\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as identifier\n\n,\n                \n        cast(\'dummy_string\' as string) as loaded_at_field\n\n,\n                \n        cast(\'dummy_string\' as string) as freshness_warn_after\n\n,\n                \n        cast(\'dummy_string\' as string) as freshness_error_after\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as freshness_filter\n\n,\n                \n        cast(\'dummy_string\' as string) as relation_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as source_description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-1 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.schema_columns_snapshot','model.elementary.schema_columns_snapshot','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','schema_columns_snapshot','CREATE TABLE (0.0 rows, 0 processed)','success','model',2.394911050796509,'2023-04-20T22:38:54.529270Z','2023-04-20T22:38:56.904203Z','2023-04-20T22:38:54.511164Z','2023-04-20T22:38:54.528690Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as column_state_id\n\n,\n                \n        cast(\'dummy_string\' as string) as full_column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as data_type\n\n,\n                \n        cast (True as BOOL) as is_new\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.monitors_runs','model.elementary.monitors_runs','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','monitors_runs','CREATE VIEW (0 processed)','success','model',1.0609562397003174,'2023-04-20T22:38:56.631647Z','2023-04-20T22:38:57.678281Z','2023-04-20T22:38:56.621280Z','2023-04-20T22:38:56.630959Z',NULL,False,'\n\nwith data_monitoring_metrics as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`\n\n),\n\nmax_bucket_end as (\n\n    select full_table_name,\n           column_name,\n           metric_name,\n           metric_properties,\n           max(bucket_end) as last_bucket_end,\n           min(bucket_end) as first_bucket_end\n    from data_monitoring_metrics\n    group by 1,2,3,4\n\n)\n\nselect * from max_bucket_end',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_tests','model.elementary.dbt_tests','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_tests','CREATE TABLE (0.0 rows, 0 processed)','success','model',7.186043977737427,'2023-04-20T22:38:50.684297Z','2023-04-20T22:38:57.796351Z','2023-04-20T22:38:50.614478Z','2023-04-20T22:38:50.683581Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as short_name\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as test_column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as severity\n\n,\n                \n        cast(\'dummy_string\' as string) as warn_if\n\n,\n                \n        cast(\'dummy_string\' as string) as error_if\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_params\n\n,\n                \n        cast(\'dummy_string\' as string) as test_namespace\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_owners\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'dummy_string\' as string) as parent_model_unique_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.model_run_results','model.elementary.model_run_results','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','model_run_results','CREATE VIEW (0 processed)','success','model',1.1192717552185059,'2023-04-20T22:38:56.928750Z','2023-04-20T22:38:58.025939Z','2023-04-20T22:38:56.908947Z','2023-04-20T22:38:56.928268Z',NULL,False,'\n\nwith dbt_run_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`\n),\n\ndbt_models as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.thread_id,\n    models.database_name,\n    models.schema_name,\n    models.materialization,\n    models.tags,\n    models.package_name,\n    models.path,\n    models.original_path,\n    models.owner,\n    models.alias,\n    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,\n    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY \n    timestamp_trunc(cast(run_results.generated_at as timestamp), day)\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_first_invocation_of_the_day,\n    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY \n    timestamp_trunc(cast(run_results.generated_at as timestamp), day)\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_last_invocation_of_the_day\n    \nFROM dbt_run_results run_results\nJOIN dbt_models models ON run_results.unique_id = models.unique_id',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.job_run_results','model.elementary.job_run_results','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','job_run_results','CREATE VIEW (0 processed)','success','model',1.3887157440185547,'2023-04-20T22:38:56.681896Z','2023-04-20T22:38:58.052114Z','2023-04-20T22:38:56.666145Z','2023-04-20T22:38:56.681051Z',NULL,False,'\n\n\n\n\n\nwith jobs as (\n  select\n    job_name,\n    job_id,\n    job_run_id,\n    \nmin(cast(run_started_at as TIMESTAMP))\n as job_run_started_at,\n    \nmax(cast(run_completed_at as TIMESTAMP))\n as job_run_completed_at,\n    \n    timestamp_diff(\nmax(cast(run_completed_at as TIMESTAMP))\n, \nmin(cast(run_started_at as TIMESTAMP))\n, second)\n as job_run_execution_time\n  from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`\n  where job_id is not null\n  group by job_name, job_id, job_run_id\n)\n\nselect\n  job_name as name,\n  job_id as id,\n  job_run_id as run_id,\n  job_run_started_at as run_started_at,\n  job_run_completed_at as run_completed_at,\n  job_run_execution_time as run_execution_time\nfrom jobs',NULL,NULL,'Thread-1 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.alerts_anomaly_detection','model.elementary.alerts_anomaly_detection','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','alerts_anomaly_detection','CREATE VIEW (0 processed)','success','model',0.8373708724975586,'2023-04-20T22:38:57.813860Z','2023-04-20T22:38:58.638536Z','2023-04-20T22:38:57.803867Z','2023-04-20T22:38:57.813109Z',NULL,False,'\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_anomaly_detection as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'anomaly_detection\'\n)\n\nselect * from alerts_anomaly_detection',NULL,NULL,'Thread-4 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.snapshot_run_results','model.elementary.snapshot_run_results','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','snapshot_run_results','CREATE VIEW (0 processed)','success','model',1.0530869960784912,'2023-04-20T22:38:57.695410Z','2023-04-20T22:38:58.734206Z','2023-04-20T22:38:57.685473Z','2023-04-20T22:38:57.694809Z',NULL,False,'\n\nwith dbt_run_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`\n),\n\ndbt_snapshots as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.thread_id,\n    snapshots.database_name,\n    snapshots.schema_name,\n    snapshots.materialization,\n    snapshots.tags,\n    snapshots.package_name,\n    snapshots.path,\n    snapshots.original_path,\n    snapshots.owner,\n    snapshots.alias\nFROM dbt_run_results run_results\nJOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.de_project.final_land_and_property','model.de_project.final_land_and_property','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','final_land_and_property',NULL,'skipped','model',0.0,NULL,NULL,NULL,NULL,NULL,False,NULL,NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.alerts_dbt_tests','model.elementary.alerts_dbt_tests','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','alerts_dbt_tests','CREATE VIEW (0 processed)','success','model',1.197314977645874,'2023-04-20T22:38:58.057679Z','2023-04-20T22:38:59.227143Z','2023-04-20T22:38:58.032268Z','2023-04-20T22:38:58.052736Z',NULL,False,'\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_dbt_tests as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'dbt_test\'\n)\n\nselect * from alerts_dbt_tests',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.alerts_schema_changes','model.elementary.alerts_schema_changes','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','alerts_schema_changes','CREATE VIEW (0 processed)','success','model',1.4292259216308594,'2023-04-20T22:38:58.087062Z','2023-04-20T22:38:59.496305Z','2023-04-20T22:38:58.068743Z','2023-04-20T22:38:58.085862Z',NULL,False,'\n\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_schema_changes as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'schema_change\'\n)\n\nselect * from alerts_schema_changes',NULL,NULL,'Thread-1 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.anomaly_threshold_sensitivity','model.elementary.anomaly_threshold_sensitivity','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','anomaly_threshold_sensitivity','CREATE VIEW (0 processed)','success','model',1.1611130237579346,'2023-04-20T22:38:58.762584Z','2023-04-20T22:38:59.903253Z','2023-04-20T22:38:58.744479Z','2023-04-20T22:38:58.761383Z',NULL,False,'\n\nwith metrics_anomaly_score as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`\n\n),\n\nscore_sensitivity as (\n\n    select\n        full_table_name,\n        column_name,\n        metric_name,\n        latest_metric_value,\n        training_avg as metric_avg,\n        training_stddev as metric_stddev,\n        anomaly_score,\n        case when abs(anomaly_score) >= 1.5 then true else false end as `is_anomaly_1_5`,\n        case when abs(anomaly_score) >= 2 then true else false end as `is_anomaly_2`,\n        case when abs(anomaly_score) >= 2.5 then true else false end as `is_anomaly_2_5`,\n        case when abs(anomaly_score) >= 3 then true else false end as `is_anomaly_3`,\n        case when abs(anomaly_score) >= 3.5 then true else false end as `is_anomaly_3_5`,\n        case when abs(anomaly_score) >= 4 then true else false end as `is_anomaly_4`,\n        case when abs(anomaly_score) >= 4.5 then true else false end as `is_anomaly_4_5`\n    from metrics_anomaly_score\n    where abs(anomaly_score) >= 1.5\n\n)\n\nselect * from score_sensitivity',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.alerts_dbt_source_freshness','model.elementary.alerts_dbt_source_freshness','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','alerts_dbt_source_freshness','CREATE VIEW (0 processed)','success','model',1.6938350200653076,'2023-04-20T22:39:00.578521Z','2023-04-20T22:39:02.236844Z','2023-04-20T22:39:00.552920Z','2023-04-20T22:39:00.575933Z',NULL,False,'\n\nwith results as (\n  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`\n),\n\nsources as (\n  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`\n)\n\nselect\n  results.source_freshness_execution_id as alert_id,\n  results.max_loaded_at,\n  results.snapshotted_at,\n  results.generated_at as detected_at,\n  results.max_loaded_at_time_ago_in_s,\n  results.status,\n  results.error,\n  sources.unique_id,\n  sources.database_name,\n  sources.schema_name,\n  sources.source_name,\n  sources.identifier,\n  sources.freshness_error_after,\n  sources.freshness_warn_after,\n  sources.freshness_filter,\n  sources.tags,\n  sources.meta,\n  sources.owner,\n  sources.package_name,\n  sources.path\nfrom results\njoin sources on results.unique_id = sources.unique_id\nwhere True and lower(status) != \'pass\'',NULL,NULL,'Thread-3 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.dbt_artifacts_hashes','model.elementary.dbt_artifacts_hashes','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','dbt_artifacts_hashes','CREATE VIEW (0 processed)','success','model',1.6939761638641357,'2023-04-20T22:39:00.584712Z','2023-04-20T22:39:02.240614Z','2023-04-20T22:39:00.559826Z','2023-04-20T22:39:00.576591Z',NULL,False,'\n\n\n\n\nselect\n  \'dbt_models\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_models`\n union all \n\nselect\n  \'dbt_tests\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`\n union all \n\nselect\n  \'dbt_sources\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`\n union all \n\nselect\n  \'dbt_snapshots\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`\n union all \n\nselect\n  \'dbt_metrics\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`\n union all \n\nselect\n  \'dbt_exposures\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`\n union all \n\nselect\n  \'dbt_seeds\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`\n\n\norder by metadata_hash',NULL,NULL,'Thread-1 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.alerts_dbt_models','model.elementary.alerts_dbt_models','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','alerts_dbt_models','CREATE VIEW (0 processed)','success','model',1.6988179683685303,'2023-04-20T22:39:00.594620Z','2023-04-20T22:39:02.246912Z','2023-04-20T22:39:00.564908Z','2023-04-20T22:39:00.577484Z',NULL,False,'\n\nwith error_models as (\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias \n    from `dtc-de-383113`.`de_data_warehouse`.`model_run_results`\n  \n    union all\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias  \n  from `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`\n)\n\n\nselect model_execution_id as alert_id,\n       unique_id,\n       generated_at as detected_at,\n       database_name,\n       materialization,\n       path,\n       original_path,\n       schema_name,\n       message,\n       owner as owners,\n       tags,\n       alias,\n       status,\n       full_refresh\nfrom error_models\nwhere True and lower(status) != \'success\'and lower(status) != \'skipped\'',NULL,NULL,'Thread-2 (worker)'),('3b2cdcc9-d2c2-4956-9b2b-722740ee324f.model.elementary.test_result_rows','model.elementary.test_result_rows','3b2cdcc9-d2c2-4956-9b2b-722740ee324f','2023-04-20 22:39:07','test_result_rows','CREATE TABLE (0.0 rows, 0 processed)','success','model',6.488354921340942,'2023-04-20T22:38:58.662771Z','2023-04-20T22:39:05.133097Z','2023-04-20T22:38:58.646428Z','2023-04-20T22:38:58.662169Z',0,False,'\n\n-- depends_on: `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as elementary_test_results_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as result_row\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)')
  
[0m22:39:09.578934 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b45627b5-35ac-4f44-bcee-53a09d846b7a&page=queryresults
[0m22:39:09.579797 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m22:39:09.596565 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m22:39:09.979242 [debug] [MainThread]: Elementary: Inserting 1 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
[0m22:39:10.016292 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:39:10.018391 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user) values
    ('3b2cdcc9-d2c2-4956-9b2b-722740ee324f',NULL,NULL,NULL,'2023-04-20 22:38:31','2023-04-20 22:39:09','2023-04-20 22:39:09','run','1.4.5','0.7.5',False,'{}','{}','dev','dtc-de-383113','de_data_warehouse','de_project',4,'[]','[]',NULL,'de_project',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL)
  
[0m22:39:11.550614 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:521b764d-15eb-4b23-8617-5b69199a9d6e&page=queryresults
[0m22:39:11.552411 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m22:39:11.556421 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m22:39:11.558045 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m22:39:11.559153 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.00s]
[0m22:39:11.559753 [info ] [MainThread]: 
[0m22:39:11.561007 [debug] [MainThread]: Connection 'master' was properly closed.
[0m22:39:11.561465 [debug] [MainThread]: Connection 'model.elementary.dbt_artifacts_hashes' was properly closed.
[0m22:39:11.561883 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_models' was properly closed.
[0m22:39:11.562228 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_source_freshness' was properly closed.
[0m22:39:11.562512 [debug] [MainThread]: Connection 'model.elementary.test_result_rows' was properly closed.
[0m22:39:11.562990 [info ] [MainThread]: 
[0m22:39:11.563506 [info ] [MainThread]: Finished running 17 view models, 14 incremental models, 1 table model, 2 hooks in 0 hours 0 minutes and 34.99 seconds (34.99s).
[0m22:39:11.565813 [debug] [MainThread]: Command end result
[0m22:39:11.804386 [info ] [MainThread]: 
[0m22:39:11.804876 [info ] [MainThread]: [31mCompleted with 1 error and 0 warnings:[0m
[0m22:39:11.805371 [info ] [MainThread]: 
[0m22:39:11.805804 [error] [MainThread]: [33mRuntime Error in model land_and_property_optimized_raw (models/raw/land_and_property_optimized_raw.sql)[0m
[0m22:39:11.806128 [error] [MainThread]:   404 Not found: Dataset dtc-de-383113:project_dwh was not found in location europe-west6
[0m22:39:11.806564 [error] [MainThread]:   
[0m22:39:11.807000 [error] [MainThread]:   Location: europe-west6
[0m22:39:11.807440 [error] [MainThread]:   Job ID: 6bb899ab-6b50-4354-9049-ecccfa078226
[0m22:39:11.808065 [error] [MainThread]:   
[0m22:39:11.808655 [info ] [MainThread]: 
[0m22:39:11.808995 [info ] [MainThread]: Done. PASS=29 WARN=0 ERROR=1 SKIP=2 TOTAL=32
[0m22:39:11.809506 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ce3f010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ce3efd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ce3f1d0>]}
[0m22:39:11.809848 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:40:19.510053 | c7d07b1d-f23a-4b3d-9578-df8b26413800 ==============================
[0m22:40:19.510053 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:40:19.514694 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:40:19.515280 [debug] [MainThread]: Tracking: tracking
[0m22:40:19.556785 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x106c2f250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d0f7fd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d0f7b10>]}
[0m22:40:19.618676 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:40:19.778110 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:40:19.779739 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:40:19.799956 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:40:19.817069 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1b4550>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1b4810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1b55d0>]}
[0m22:40:19.817542 [debug] [MainThread]: Flushing usage events
[0m22:40:20.760452 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_project.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_data_warehouse.land_and_property_optimized' which was not found


============================== 2023-04-20 22:41:24.675873 | b7732fdb-a746-4829-9194-68561c341d40 ==============================
[0m22:41:24.675873 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:41:24.678864 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m22:41:24.679196 [debug] [MainThread]: Tracking: tracking
[0m22:41:24.737683 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108ed9650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e75e90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10918a850>]}
[0m22:41:24.739922 [debug] [MainThread]: Set downloads directory='/var/folders/b0/5sk7vs2s2zj10lhp65p3qrh40000gn/T/dbt-downloads-ifw4gr6s'
[0m22:41:24.740811 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:41:26.526200 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:41:26.526821 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:41:26.886386 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:41:26.894442 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m22:41:27.085602 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m22:41:27.087426 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m22:41:27.478419 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m22:41:27.505538 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:41:28.595645 [info ] [MainThread]:   Installed from version 1.0.0
[0m22:41:28.596264 [info ] [MainThread]:   Up to date!
[0m22:41:28.596939 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b7732fdb-a746-4829-9194-68561c341d40', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091f2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e02910>]}
[0m22:41:28.597329 [info ] [MainThread]: Installing dbt-labs/codegen
[0m22:41:29.163811 [info ] [MainThread]:   Installed from version 0.9.0
[0m22:41:29.164440 [info ] [MainThread]:   Up to date!
[0m22:41:29.164954 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b7732fdb-a746-4829-9194-68561c341d40', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e02910>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091f2b50>]}
[0m22:41:29.165454 [info ] [MainThread]: Installing elementary-data/elementary
[0m22:41:30.223290 [info ] [MainThread]:   Installed from version 0.7.5
[0m22:41:30.224553 [info ] [MainThread]:   Up to date!
[0m22:41:30.225577 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': 'b7732fdb-a746-4829-9194-68561c341d40', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1091f2b50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x108e02910>]}
[0m22:41:30.227400 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10918a710>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1094b71d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1090f7850>]}
[0m22:41:30.227992 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:41:41.345432 | 999af602-72bd-417c-9fba-eac7cfe89314 ==============================
[0m22:41:41.345432 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:41:41.349953 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:41:41.350731 [debug] [MainThread]: Tracking: tracking
[0m22:41:41.400083 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c5ce190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c5cf090>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c60ca10>]}
[0m22:41:41.462231 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:41:41.671362 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:41:41.672842 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:41:41.702138 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:41:41.722413 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c6c2110>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c6c11d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c6c1690>]}
[0m22:41:41.723141 [debug] [MainThread]: Flushing usage events
[0m22:41:42.693570 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_project.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_data_warehouse.land_and_property_optimized' which was not found


============================== 2023-04-20 22:42:37.512181 | 44886cf9-de3a-49bf-a13c-3ee00b2bae0b ==============================
[0m22:42:37.512181 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:42:37.514973 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:42:37.515345 [debug] [MainThread]: Tracking: tracking
[0m22:42:37.557332 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126f9b810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126fa4450>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x126fa4a90>]}
[0m22:42:37.609890 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:42:37.811796 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:42:37.812928 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:42:37.836928 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:42:37.855292 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12704dd10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x127075050>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11b38f650>]}
[0m22:42:37.855802 [debug] [MainThread]: Flushing usage events
[0m22:42:38.649921 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_project.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_data_warehouse.land_and_property_optimized' which was not found


============================== 2023-04-20 22:43:45.390332 | 47c3531b-773d-4a3e-9006-09d87796ceee ==============================
[0m22:43:45.390332 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:43:45.393993 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:43:45.394328 [debug] [MainThread]: Tracking: tracking
[0m22:43:45.422670 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c376310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c394290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11c3948d0>]}
[0m22:43:45.472027 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:43:45.652588 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:43:45.653235 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:43:45.670962 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:43:45.685360 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271d27d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271d2350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1271d2410>]}
[0m22:43:45.685741 [debug] [MainThread]: Flushing usage events
[0m22:43:47.225237 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_project.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_data_warehouse.land_and_property_optimized' which was not found


============================== 2023-04-20 22:49:42.963519 | be366476-5a56-40f7-bc01-e60aa48d51be ==============================
[0m22:49:42.963519 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:49:42.967540 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:49:42.967892 [debug] [MainThread]: Tracking: tracking
[0m22:49:42.987611 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12200e850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x122018e10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12204f8d0>]}
[0m22:49:43.045693 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:49:43.076958 [info ] [MainThread]: Unable to do partial parsing because a project dependency has been added
[0m22:49:43.077793 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'partial_parser', 'label': 'be366476-5a56-40f7-bc01-e60aa48d51be', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1222fce50>]}
[0m22:49:45.693219 [debug] [MainThread]: 1699: static parser successfully parsed core/final_land_and_property.sql
[0m22:49:45.708153 [debug] [MainThread]: 1603: static parser failed on transform/land_and_property_transform.sql
[0m22:49:45.717364 [debug] [MainThread]: 1602: parser fallback to jinja rendering on transform/land_and_property_transform.sql
[0m22:49:45.719027 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:49:45.756569 [debug] [MainThread]: 1699: static parser successfully parsed edr/run_results/snapshot_run_results.sql
[0m22:49:45.760268 [debug] [MainThread]: 1603: static parser failed on edr/run_results/job_run_results.sql
[0m22:49:45.779031 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/job_run_results.sql
[0m22:49:45.780854 [debug] [MainThread]: 1603: static parser failed on edr/run_results/model_run_results.sql
[0m22:49:45.790019 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/model_run_results.sql
[0m22:49:45.791679 [debug] [MainThread]: 1603: static parser failed on edr/run_results/test_result_rows.sql
[0m22:49:45.849324 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/test_result_rows.sql
[0m22:49:45.850993 [debug] [MainThread]: 1603: static parser failed on edr/run_results/elementary_test_results.sql
[0m22:49:45.889367 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/elementary_test_results.sql
[0m22:49:45.890851 [debug] [MainThread]: 1603: static parser failed on edr/run_results/dbt_source_freshness_results.sql
[0m22:49:45.918980 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/run_results/dbt_source_freshness_results.sql
[0m22:49:45.920577 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_tests.sql
[0m22:49:45.935093 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_tests.sql
[0m22:49:45.937841 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_schema_changes.sql
[0m22:49:45.952821 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_schema_changes.sql
[0m22:49:45.954669 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_source_freshness.sql
[0m22:49:45.963895 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_source_freshness.sql
[0m22:49:45.967098 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_anomaly_detection.sql
[0m22:49:45.980694 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_anomaly_detection.sql
[0m22:49:45.982606 [debug] [MainThread]: 1603: static parser failed on edr/alerts/alerts_dbt_models.sql
[0m22:49:45.993633 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/alerts/alerts_dbt_models.sql
[0m22:49:45.997035 [debug] [MainThread]: 1699: static parser successfully parsed edr/system/monitors_runs.sql
[0m22:49:46.001025 [debug] [MainThread]: 1603: static parser failed on edr/system/metadata.sql
[0m22:49:46.010678 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/system/metadata.sql
[0m22:49:46.013477 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_tests.sql
[0m22:49:46.081822 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_tests.sql
[0m22:49:46.083390 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_models.sql
[0m22:49:46.120061 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_models.sql
[0m22:49:46.121606 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_sources.sql
[0m22:49:46.161545 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_sources.sql
[0m22:49:46.163859 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_snapshots.sql
[0m22:49:46.194046 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_snapshots.sql
[0m22:49:46.196744 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_invocations.sql
[0m22:49:46.246584 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_invocations.sql
[0m22:49:46.248637 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_metrics.sql
[0m22:49:46.287581 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_metrics.sql
[0m22:49:46.289700 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_seeds.sql
[0m22:49:46.322508 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_seeds.sql
[0m22:49:46.324389 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_artifacts_hashes.sql
[0m22:49:46.334295 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_artifacts_hashes.sql
[0m22:49:46.335934 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_run_results.sql
[0m22:49:46.368679 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_run_results.sql
[0m22:49:46.370437 [debug] [MainThread]: 1603: static parser failed on edr/dbt_artifacts/dbt_exposures.sql
[0m22:49:46.404929 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/dbt_artifacts/dbt_exposures.sql
[0m22:49:46.407082 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql
[0m22:49:46.440348 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql
[0m22:49:46.442624 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql
[0m22:49:46.452934 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql
[0m22:49:46.454545 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/schema_changes/schema_columns_snapshot.sql
[0m22:49:46.472391 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/schema_changes/schema_columns_snapshot.sql
[0m22:49:46.474389 [debug] [MainThread]: 1603: static parser failed on edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql
[0m22:49:46.494910 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql
[0m22:49:46.496866 [debug] [MainThread]: 1603: static parser failed on edr/metadata_store/filtered_information_schema_columns.sql
[0m22:49:46.518728 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/metadata_store/filtered_information_schema_columns.sql
[0m22:49:46.520406 [debug] [MainThread]: 1603: static parser failed on edr/metadata_store/filtered_information_schema_tables.sql
[0m22:49:46.533889 [debug] [MainThread]: 1602: parser fallback to jinja rendering on edr/metadata_store/filtered_information_schema_tables.sql
[0m22:49:46.736109 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1224bc350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1220cfbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1223d87d0>]}
[0m22:49:46.736580 [debug] [MainThread]: Flushing usage events
[0m22:49:47.695216 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_data_warehouse.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_data_warehouse.land_and_property_optimized' which was not found


============================== 2023-04-20 22:51:59.550654 | 07557614-2b35-4904-b102-a9f79acabbe3 ==============================
[0m22:51:59.550654 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:51:59.558945 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:51:59.559531 [debug] [MainThread]: Tracking: tracking
[0m22:51:59.610985 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128bf77d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c00390>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c009d0>]}
[0m22:51:59.662576 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:51:59.840294 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:51:59.840959 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:51:59.858167 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:51:59.874430 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128cc29d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128cb5310>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128cb4f10>]}
[0m22:51:59.874883 [debug] [MainThread]: Flushing usage events
[0m22:52:01.451220 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_project.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_project.land_and_property_optimized' which was not found


============================== 2023-04-20 22:54:13.295731 | 96c6f904-d46e-4104-8eb5-980a37c036a7 ==============================
[0m22:54:13.295731 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:54:13.301876 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'deps', 'rpc_method': 'deps', 'indirect_selection': 'eager'}
[0m22:54:13.302330 [debug] [MainThread]: Tracking: tracking
[0m22:54:13.356247 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fac290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111377990>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11164ddd0>]}
[0m22:54:13.370195 [debug] [MainThread]: Set downloads directory='/var/folders/b0/5sk7vs2s2zj10lhp65p3qrh40000gn/T/dbt-downloads-5_1f0vdm'
[0m22:54:13.371220 [debug] [MainThread]: Making package index registry request: GET https://hub.getdbt.com/api/v1/index.json
[0m22:54:13.908553 [debug] [MainThread]: Response from registry index: GET https://hub.getdbt.com/api/v1/index.json 200
[0m22:54:13.909467 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json
[0m22:54:14.155625 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/dbt_utils.json 200
[0m22:54:14.164659 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json
[0m22:54:14.487597 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/dbt-labs/codegen.json 200
[0m22:54:14.489772 [debug] [MainThread]: Making package registry request: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json
[0m22:54:14.684776 [debug] [MainThread]: Response from registry: GET https://hub.getdbt.com/api/v1/elementary-data/elementary.json 200
[0m22:54:14.702113 [info ] [MainThread]: Installing dbt-labs/dbt_utils
[0m22:54:15.781467 [info ] [MainThread]:   Installed from version 1.0.0
[0m22:54:15.782505 [info ] [MainThread]:   Up to date!
[0m22:54:15.783572 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '96c6f904-d46e-4104-8eb5-980a37c036a7', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fc6510>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11160dcd0>]}
[0m22:54:15.784198 [info ] [MainThread]: Installing dbt-labs/codegen
[0m22:54:17.144562 [info ] [MainThread]:   Installed from version 0.9.0
[0m22:54:17.145134 [info ] [MainThread]:   Up to date!
[0m22:54:17.145767 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '96c6f904-d46e-4104-8eb5-980a37c036a7', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111645250>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x110fc6510>]}
[0m22:54:17.146340 [info ] [MainThread]: Installing elementary-data/elementary
[0m22:54:18.608144 [info ] [MainThread]:   Installed from version 0.7.5
[0m22:54:18.614605 [info ] [MainThread]:   Up to date!
[0m22:54:18.615769 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'package', 'label': '96c6f904-d46e-4104-8eb5-980a37c036a7', 'property_': 'install', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112a5d90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x111638650>]}
[0m22:54:18.619170 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1116445d0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11107cbd0>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1112a5d90>]}
[0m22:54:18.619827 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 22:54:29.765696 | cc12a479-1412-4d78-94ed-1cba04e696a6 ==============================
[0m22:54:29.765696 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:54:29.769699 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:54:29.770202 [debug] [MainThread]: Tracking: tracking
[0m22:54:29.825316 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12451c350>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x124550190>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245507d0>]}
[0m22:54:29.889047 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:54:30.073953 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 1 files changed.
[0m22:54:30.074751 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:54:30.095643 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:54:30.127753 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245fa010>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245fa690>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1245fa490>]}
[0m22:54:30.128252 [debug] [MainThread]: Flushing usage events
[0m22:54:30.819328 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_project.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_project.land_and_property_optimized' which was not found


============================== 2023-04-20 22:58:55.826913 | 4e135628-8352-4375-bec3-9b53c3738c4b ==============================
[0m22:58:55.826913 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:58:55.829369 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:58:55.829771 [debug] [MainThread]: Tracking: tracking
[0m22:58:55.851714 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab87a50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab90810>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ab90e50>]}
[0m22:58:55.897737 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:58:56.010728 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m22:58:56.011658 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/sources.yml
[0m22:58:56.012135 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:58:56.032159 [debug] [MainThread]: 1699: static parser successfully parsed core/final_land_and_property.sql
[0m22:58:56.050848 [debug] [MainThread]: 1603: static parser failed on transform/land_and_property_transform.sql
[0m22:58:56.061088 [debug] [MainThread]: 1602: parser fallback to jinja rendering on transform/land_and_property_transform.sql
[0m22:58:56.064430 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:58:56.081168 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ac35d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afc4d50>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11afc4b50>]}
[0m22:58:56.081580 [debug] [MainThread]: Flushing usage events
[0m22:58:57.036176 [error] [MainThread]: Encountered an error:
Compilation Error
  Model 'model.de_project.land_and_property_optimized_raw' (models/raw/land_and_property_optimized_raw.sql) depends on a source named 'de_project.land_and_property_optimized' which was not found


============================== 2023-04-20 22:59:23.462690 | 9f3fc660-72f8-4b44-97ce-7042bae015c7 ==============================
[0m22:59:23.462690 [info ] [MainThread]: Running with dbt=1.4.5
[0m22:59:23.465433 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m22:59:23.465813 [debug] [MainThread]: Tracking: tracking
[0m22:59:23.486659 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128bf6c90>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c40850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c40e50>]}
[0m22:59:23.533088 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m22:59:23.633661 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 2 files changed.
[0m22:59:23.634484 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/sources.yml
[0m22:59:23.634787 [debug] [MainThread]: Partial parsing: updated file: de_project://models/raw/land_and_property_optimized_raw.sql
[0m22:59:23.652269 [debug] [MainThread]: 1699: static parser successfully parsed core/final_land_and_property.sql
[0m22:59:23.668959 [debug] [MainThread]: 1603: static parser failed on transform/land_and_property_transform.sql
[0m22:59:23.678500 [debug] [MainThread]: 1602: parser fallback to jinja rendering on transform/land_and_property_transform.sql
[0m22:59:23.680043 [debug] [MainThread]: 1699: static parser successfully parsed raw/land_and_property_optimized_raw.sql
[0m22:59:23.804672 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128d48bd0>]}
[0m22:59:23.827407 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1290784d0>]}
[0m22:59:23.828147 [info ] [MainThread]: Found 32 models, 0 tests, 0 snapshots, 0 analyses, 880 macros, 2 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m22:59:23.828598 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x112d5f9d0>]}
[0m22:59:23.831872 [info ] [MainThread]: 
[0m22:59:23.834265 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:59:23.836970 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dtc-de-383113'
[0m22:59:23.837535 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m22:59:24.968298 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dtc-de-383113_de_data_warehouse'
[0m22:59:24.968834 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m22:59:25.741103 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1280792d0>]}
[0m22:59:25.741622 [info ] [MainThread]: 
[0m22:59:25.742851 [info ] [MainThread]: Running 1 on-run-start hook
[0m22:59:25.781421 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m22:59:25.783694 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m22:59:25.784433 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.00s]
[0m22:59:25.784912 [info ] [MainThread]: 
[0m22:59:25.785879 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m22:59:25.786426 [info ] [MainThread]: 
[0m22:59:25.795690 [debug] [Thread-1 (]: Began running node model.de_project.land_and_property_optimized_raw
[0m22:59:25.796266 [debug] [Thread-2 (]: Began running node model.elementary.data_monitoring_metrics
[0m22:59:25.796737 [debug] [Thread-3 (]: Began running node model.elementary.dbt_exposures
[0m22:59:25.797303 [debug] [Thread-4 (]: Began running node model.elementary.dbt_invocations
[0m22:59:25.797998 [info ] [Thread-1 (]: 1 of 32 START sql view model de_data_warehouse.land_and_property_optimized_raw . [RUN]
[0m22:59:25.798738 [info ] [Thread-2 (]: 2 of 32 START sql incremental model de_data_warehouse.data_monitoring_metrics .. [RUN]
[0m22:59:25.799470 [info ] [Thread-3 (]: 3 of 32 START sql incremental model de_data_warehouse.dbt_exposures ............ [RUN]
[0m22:59:25.800115 [info ] [Thread-4 (]: 4 of 32 START sql incremental model de_data_warehouse.dbt_invocations .......... [RUN]
[0m22:59:25.801685 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.de_project.land_and_property_optimized_raw'
[0m22:59:25.802440 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.data_monitoring_metrics'
[0m22:59:25.803097 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_exposures'
[0m22:59:25.804132 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_invocations'
[0m22:59:25.804857 [debug] [Thread-1 (]: Began compiling node model.de_project.land_and_property_optimized_raw
[0m22:59:25.805410 [debug] [Thread-2 (]: Began compiling node model.elementary.data_monitoring_metrics
[0m22:59:25.805864 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_exposures
[0m22:59:25.806559 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_invocations
[0m22:59:25.811434 [debug] [Thread-1 (]: Writing injected SQL for node "model.de_project.land_and_property_optimized_raw"
[0m22:59:25.923829 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_exposures"
[0m22:59:25.954274 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_optimized_raw (compile): 2023-04-20 22:59:25.807284 => 2023-04-20 22:59:25.944314
[0m22:59:26.008387 [debug] [Thread-1 (]: Began executing node model.de_project.land_and_property_optimized_raw
[0m22:59:26.007260 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_exposures (compile): 2023-04-20 22:59:25.845821 => 2023-04-20 22:59:26.007031
[0m22:59:26.013623 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_invocations"
[0m22:59:25.964698 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.data_monitoring_metrics"
[0m22:59:26.052231 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_exposures
[0m22:59:26.073965 [debug] [Thread-1 (]: Writing runtime sql for node "model.de_project.land_and_property_optimized_raw"
[0m22:59:26.102993 [debug] [Thread-2 (]: Timing info for model.elementary.data_monitoring_metrics (compile): 2023-04-20 22:59:25.811767 => 2023-04-20 22:59:26.102865
[0m22:59:26.103492 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_invocations (compile): 2023-04-20 22:59:25.867541 => 2023-04-20 22:59:26.103409
[0m22:59:26.122691 [debug] [Thread-2 (]: Began executing node model.elementary.data_monitoring_metrics
[0m22:59:26.123384 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:26.140373 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_invocations
[0m22:59:26.237673 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m22:59:26.255874 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m22:59:26.257342 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m22:59:26.279545 [debug] [Thread-1 (]: On model.de_project.land_and_property_optimized_raw: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.land_and_property_optimized_raw"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`
  OPTIONS()
  as with source as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized`
)
select * from source;


[0m22:59:26.331968 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as maturity

,
                
        cast('dummy_string' as string) as type

,
                
        cast('dummy_string' as string) as owner_email

,
                
        cast('dummy_string' as string) as owner_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as url

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:26.334617 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.data_monitoring_metrics"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as id

,
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as metric_name

,
                
        cast(123456789.99 as FLOAT64) as metric_value

,
                
        cast('dummy_string' as string) as source_value

,
                cast('2091-02-17' as TIMESTAMP) as bucket_start

,
                cast('2091-02-17' as TIMESTAMP) as bucket_end

,
                
        cast(123456789 as INT64) as bucket_duration_hours

,
                cast('2091-02-17' as TIMESTAMP) as updated_at

,
                
        cast('dummy_string' as string) as dimension

,
                
        cast('dummy_string' as string) as dimension_value

,
                
        cast('dummy_string' as string) as metric_properties


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m22:59:26.338921 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_invocations"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as invocation_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_run_id

,
                
        cast('dummy_string' as string) as run_started_at

,
                
        cast('dummy_string' as string) as run_completed_at

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as command

,
                
        cast('dummy_string' as string) as dbt_version

,
                
        cast('dummy_string' as string) as elementary_version

,
                
        cast (True as BOOL) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as string) as invocation_vars

,
                
        cast('this_is_just_a_long_dummy_string' as string) as vars

,
                
        cast('dummy_string' as string) as target_name

,
                
        cast('dummy_string' as string) as target_database

,
                
        cast('dummy_string' as string) as target_schema

,
                
        cast('dummy_string' as string) as target_profile_name

,
                
        cast(123456789 as INT64) as threads

,
                
        cast('this_is_just_a_long_dummy_string' as string) as selected

,
                
        cast('this_is_just_a_long_dummy_string' as string) as yaml_selector

,
                
        cast('dummy_string' as string) as project_id

,
                
        cast('dummy_string' as string) as project_name

,
                
        cast('dummy_string' as string) as env

,
                
        cast('dummy_string' as string) as env_id

,
                
        cast('dummy_string' as string) as cause_category

,
                
        cast('this_is_just_a_long_dummy_string' as string) as cause

,
                
        cast('dummy_string' as string) as pull_request_id

,
                
        cast('dummy_string' as string) as git_sha

,
                
        cast('dummy_string' as string) as orchestrator

,
                
        cast('dummy_string' as string) as dbt_user


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:28.092008 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8190170a-071b-44ca-8c9c-6b1bdaa14123&page=queryresults
[0m22:59:28.110446 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_optimized_raw (execute): 2023-04-20 22:59:26.013985 => 2023-04-20 22:59:28.110339
[0m22:59:28.111721 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1290fd050>]}
[0m22:59:28.112640 [info ] [Thread-1 (]: 1 of 32 OK created sql view model de_data_warehouse.land_and_property_optimized_raw  [[32mCREATE VIEW (0 processed)[0m in 2.31s]
[0m22:59:28.116353 [debug] [Thread-1 (]: Finished running node model.de_project.land_and_property_optimized_raw
[0m22:59:28.117121 [debug] [Thread-1 (]: Began running node model.elementary.dbt_metrics
[0m22:59:28.118002 [info ] [Thread-1 (]: 5 of 32 START sql incremental model de_data_warehouse.dbt_metrics .............. [RUN]
[0m22:59:28.118855 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_metrics'
[0m22:59:28.119187 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_metrics
[0m22:59:28.160018 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_metrics"
[0m22:59:28.161043 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_metrics (compile): 2023-04-20 22:59:28.119355 => 2023-04-20 22:59:28.160819
[0m22:59:28.161927 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_metrics
[0m22:59:28.175517 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:28.228260 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as label

,
                
        cast('dummy_string' as string) as model

,
                
        cast('dummy_string' as string) as type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as sql

,
                
        cast('dummy_string' as string) as timestamp

,
                
        cast('this_is_just_a_long_dummy_string' as string) as filters

,
                
        cast('this_is_just_a_long_dummy_string' as string) as time_grains

,
                
        cast('this_is_just_a_long_dummy_string' as string) as dimensions

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:28.759718 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:640e70d1-e3f2-42f6-8dea-bbf9211053e5&page=queryresults
[0m22:59:28.774593 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:0c1d4210-33c4-4ec0-a885-91e8558d51b2&page=queryresults
[0m22:59:28.778336 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:151009e7-386c-4d37-bfbd-6a4b3289bb06&page=queryresults
[0m22:59:29.040804 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:29.066407 [debug] [Thread-3 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:29.075670 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_invocations"
[0m22:59:29.077454 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_exposures"
[0m22:59:29.078222 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_invocations"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.invocation_id = DBT_INTERNAL_DEST.invocation_id
            )

    
    when matched then update set
        `invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`,`job_id` = DBT_INTERNAL_SOURCE.`job_id`,`job_name` = DBT_INTERNAL_SOURCE.`job_name`,`job_run_id` = DBT_INTERNAL_SOURCE.`job_run_id`,`run_started_at` = DBT_INTERNAL_SOURCE.`run_started_at`,`run_completed_at` = DBT_INTERNAL_SOURCE.`run_completed_at`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`command` = DBT_INTERNAL_SOURCE.`command`,`dbt_version` = DBT_INTERNAL_SOURCE.`dbt_version`,`elementary_version` = DBT_INTERNAL_SOURCE.`elementary_version`,`full_refresh` = DBT_INTERNAL_SOURCE.`full_refresh`,`invocation_vars` = DBT_INTERNAL_SOURCE.`invocation_vars`,`vars` = DBT_INTERNAL_SOURCE.`vars`,`target_name` = DBT_INTERNAL_SOURCE.`target_name`,`target_database` = DBT_INTERNAL_SOURCE.`target_database`,`target_schema` = DBT_INTERNAL_SOURCE.`target_schema`,`target_profile_name` = DBT_INTERNAL_SOURCE.`target_profile_name`,`threads` = DBT_INTERNAL_SOURCE.`threads`,`selected` = DBT_INTERNAL_SOURCE.`selected`,`yaml_selector` = DBT_INTERNAL_SOURCE.`yaml_selector`,`project_id` = DBT_INTERNAL_SOURCE.`project_id`,`project_name` = DBT_INTERNAL_SOURCE.`project_name`,`env` = DBT_INTERNAL_SOURCE.`env`,`env_id` = DBT_INTERNAL_SOURCE.`env_id`,`cause_category` = DBT_INTERNAL_SOURCE.`cause_category`,`cause` = DBT_INTERNAL_SOURCE.`cause`,`pull_request_id` = DBT_INTERNAL_SOURCE.`pull_request_id`,`git_sha` = DBT_INTERNAL_SOURCE.`git_sha`,`orchestrator` = DBT_INTERNAL_SOURCE.`orchestrator`,`dbt_user` = DBT_INTERNAL_SOURCE.`dbt_user`
    

    when not matched then insert
        (`invocation_id`, `job_id`, `job_name`, `job_run_id`, `run_started_at`, `run_completed_at`, `generated_at`, `command`, `dbt_version`, `elementary_version`, `full_refresh`, `invocation_vars`, `vars`, `target_name`, `target_database`, `target_schema`, `target_profile_name`, `threads`, `selected`, `yaml_selector`, `project_id`, `project_name`, `env`, `env_id`, `cause_category`, `cause`, `pull_request_id`, `git_sha`, `orchestrator`, `dbt_user`)
    values
        (`invocation_id`, `job_id`, `job_name`, `job_run_id`, `run_started_at`, `run_completed_at`, `generated_at`, `command`, `dbt_version`, `elementary_version`, `full_refresh`, `invocation_vars`, `vars`, `target_name`, `target_database`, `target_schema`, `target_profile_name`, `threads`, `selected`, `yaml_selector`, `project_id`, `project_name`, `env`, `env_id`, `cause_category`, `cause`, `pull_request_id`, `git_sha`, `orchestrator`, `dbt_user`)


    
[0m22:59:29.078478 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`maturity` = DBT_INTERNAL_SOURCE.`maturity`,`type` = DBT_INTERNAL_SOURCE.`type`,`owner_email` = DBT_INTERNAL_SOURCE.`owner_email`,`owner_name` = DBT_INTERNAL_SOURCE.`owner_name`,`url` = DBT_INTERNAL_SOURCE.`url`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `name`, `maturity`, `type`, `owner_email`, `owner_name`, `url`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `name`, `maturity`, `type`, `owner_email`, `owner_name`, `url`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m22:59:29.165973 [debug] [Thread-2 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:29.170552 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.data_monitoring_metrics"
[0m22:59:29.174294 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.data_monitoring_metrics"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
            )

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`full_table_name` = DBT_INTERNAL_SOURCE.`full_table_name`,`column_name` = DBT_INTERNAL_SOURCE.`column_name`,`metric_name` = DBT_INTERNAL_SOURCE.`metric_name`,`metric_value` = DBT_INTERNAL_SOURCE.`metric_value`,`source_value` = DBT_INTERNAL_SOURCE.`source_value`,`bucket_start` = DBT_INTERNAL_SOURCE.`bucket_start`,`bucket_end` = DBT_INTERNAL_SOURCE.`bucket_end`,`bucket_duration_hours` = DBT_INTERNAL_SOURCE.`bucket_duration_hours`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`,`dimension` = DBT_INTERNAL_SOURCE.`dimension`,`dimension_value` = DBT_INTERNAL_SOURCE.`dimension_value`,`metric_properties` = DBT_INTERNAL_SOURCE.`metric_properties`
    

    when not matched then insert
        (`id`, `full_table_name`, `column_name`, `metric_name`, `metric_value`, `source_value`, `bucket_start`, `bucket_end`, `bucket_duration_hours`, `updated_at`, `dimension`, `dimension_value`, `metric_properties`)
    values
        (`id`, `full_table_name`, `column_name`, `metric_name`, `metric_value`, `source_value`, `bucket_start`, `bucket_end`, `bucket_duration_hours`, `updated_at`, `dimension`, `dimension_value`, `metric_properties`)


    
[0m22:59:30.702468 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:3c233f76-d073-4287-a841-ebe8e6b8e207&page=queryresults
[0m22:59:30.706372 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_invocations (execute): 2023-04-20 22:59:26.243706 => 2023-04-20 22:59:30.706260
[0m22:59:30.707581 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1291c65d0>]}
[0m22:59:30.708153 [info ] [Thread-4 (]: 4 of 32 OK created sql incremental model de_data_warehouse.dbt_invocations ..... [[32mMERGE (0.0 rows, 208.0 Bytes processed)[0m in 4.90s]
[0m22:59:30.708847 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_invocations
[0m22:59:30.709486 [debug] [Thread-4 (]: Began running node model.elementary.dbt_models
[0m22:59:30.710317 [info ] [Thread-4 (]: 6 of 32 START sql incremental model de_data_warehouse.dbt_models ............... [RUN]
[0m22:59:30.711770 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_models'
[0m22:59:30.712147 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_models
[0m22:59:30.752735 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_models"
[0m22:59:30.754059 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_models (compile): 2023-04-20 22:59:30.712365 => 2023-04-20 22:59:30.753867
[0m22:59:30.754615 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_models
[0m22:59:30.764968 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:59:30.784984 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:90e87690-93d4-40f3-bc72-08b3901fc77c&page=queryresults
[0m22:59:30.828417 [debug] [Thread-3 (]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m22:59:30.828947 [debug] [Thread-4 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('dummy_string' as string) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:30.829910 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e49db5c3-e883-4dbc-932b-c041501d3c24&page=queryresults
[0m22:59:30.834863 [debug] [Thread-3 (]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m22:59:30.881010 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__tmp_20230420225930857420`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
        WHERE 1 = 0
    
    );
  
  
[0m22:59:30.889108 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ac397500-877c-471d-824f-1e4a3c365032&page=queryresults
[0m22:59:30.891025 [debug] [Thread-2 (]: Timing info for model.elementary.data_monitoring_metrics (execute): 2023-04-20 22:59:26.170407 => 2023-04-20 22:59:30.890971
[0m22:59:30.891700 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1291565d0>]}
[0m22:59:30.892370 [info ] [Thread-2 (]: 2 of 32 OK created sql incremental model de_data_warehouse.data_monitoring_metrics  [[32mMERGE (0.0 rows, 0 processed)[0m in 5.09s]
[0m22:59:30.892979 [debug] [Thread-2 (]: Finished running node model.elementary.data_monitoring_metrics
[0m22:59:30.893674 [debug] [Thread-2 (]: Began running node model.elementary.dbt_run_results
[0m22:59:30.894932 [info ] [Thread-2 (]: 7 of 32 START sql incremental model de_data_warehouse.dbt_run_results .......... [RUN]
[0m22:59:30.896114 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.dbt_run_results'
[0m22:59:30.896558 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_run_results
[0m22:59:30.940391 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_run_results"
[0m22:59:30.941108 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_run_results (compile): 2023-04-20 22:59:30.896801 => 2023-04-20 22:59:30.941016
[0m22:59:30.941439 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_run_results
[0m22:59:30.952597 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:31.010110 [debug] [Thread-2 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_run_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as model_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as invocation_id

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('this_is_just_a_long_dummy_string' as string) as name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as message

,
                
        cast('dummy_string' as string) as status

,
                
        cast('dummy_string' as string) as resource_type

,
                
        cast(123456789.99 as FLOAT64) as execution_time

,
                
        cast('dummy_string' as string) as execute_started_at

,
                
        cast('dummy_string' as string) as execute_completed_at

,
                
        cast('dummy_string' as string) as compile_started_at

,
                
        cast('dummy_string' as string) as compile_completed_at

,
                
        cast(31474836478 as bigint) as rows_affected

,
                
        cast (True as BOOL) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as string) as compiled_code

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as string) as query_id

,
                
        cast('dummy_string' as string) as thread_id


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:31.242959 [debug] [Thread-1 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:31.244893 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_metrics"
[0m22:59:31.245808 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`label` = DBT_INTERNAL_SOURCE.`label`,`model` = DBT_INTERNAL_SOURCE.`model`,`type` = DBT_INTERNAL_SOURCE.`type`,`sql` = DBT_INTERNAL_SOURCE.`sql`,`timestamp` = DBT_INTERNAL_SOURCE.`timestamp`,`filters` = DBT_INTERNAL_SOURCE.`filters`,`time_grains` = DBT_INTERNAL_SOURCE.`time_grains`,`dimensions` = DBT_INTERNAL_SOURCE.`dimensions`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `name`, `label`, `model`, `type`, `sql`, `timestamp`, `filters`, `time_grains`, `dimensions`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `name`, `label`, `model`, `type`, `sql`, `timestamp`, `filters`, `time_grains`, `dimensions`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m22:59:32.814965 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:69a59c52-1dd5-463f-9459-73d681b0d372&page=queryresults
[0m22:59:32.836931 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__tmp_20230420225930857420`
    );
  
  
[0m22:59:33.074860 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:97cb03f9-5433-4749-a6a9-7fbb600257f2&page=queryresults
[0m22:59:33.210047 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:25b05963-bd5a-41ac-b9cb-df2e70ae09a1&page=queryresults
[0m22:59:33.217840 [debug] [Thread-1 (]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m22:59:33.220996 [debug] [Thread-1 (]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m22:59:33.228151 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__tmp_20230420225933224002`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
        WHERE 1 = 0
    
    );
  
  
[0m22:59:33.371242 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_models`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:33.374848 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_models"
[0m22:59:33.375696 [debug] [Thread-4 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_models` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`checksum` = DBT_INTERNAL_SOURCE.`checksum`,`materialization` = DBT_INTERNAL_SOURCE.`materialization`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`name` = DBT_INTERNAL_SOURCE.`name`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m22:59:33.733217 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c1021161-eff9-4936-bdf9-183d8e550c6d&page=queryresults
[0m22:59:34.016299 [debug] [Thread-2 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:34.020173 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_run_results"
[0m22:59:34.021094 [debug] [Thread-2 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_run_results"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.model_execution_id = DBT_INTERNAL_DEST.model_execution_id
            )

    
    when matched then update set
        `model_execution_id` = DBT_INTERNAL_SOURCE.`model_execution_id`,`unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`name` = DBT_INTERNAL_SOURCE.`name`,`message` = DBT_INTERNAL_SOURCE.`message`,`status` = DBT_INTERNAL_SOURCE.`status`,`resource_type` = DBT_INTERNAL_SOURCE.`resource_type`,`execution_time` = DBT_INTERNAL_SOURCE.`execution_time`,`execute_started_at` = DBT_INTERNAL_SOURCE.`execute_started_at`,`execute_completed_at` = DBT_INTERNAL_SOURCE.`execute_completed_at`,`compile_started_at` = DBT_INTERNAL_SOURCE.`compile_started_at`,`compile_completed_at` = DBT_INTERNAL_SOURCE.`compile_completed_at`,`rows_affected` = DBT_INTERNAL_SOURCE.`rows_affected`,`full_refresh` = DBT_INTERNAL_SOURCE.`full_refresh`,`compiled_code` = DBT_INTERNAL_SOURCE.`compiled_code`,`failures` = DBT_INTERNAL_SOURCE.`failures`,`query_id` = DBT_INTERNAL_SOURCE.`query_id`,`thread_id` = DBT_INTERNAL_SOURCE.`thread_id`
    

    when not matched then insert
        (`model_execution_id`, `unique_id`, `invocation_id`, `generated_at`, `name`, `message`, `status`, `resource_type`, `execution_time`, `execute_started_at`, `execute_completed_at`, `compile_started_at`, `compile_completed_at`, `rows_affected`, `full_refresh`, `compiled_code`, `failures`, `query_id`, `thread_id`)
    values
        (`model_execution_id`, `unique_id`, `invocation_id`, `generated_at`, `name`, `message`, `status`, `resource_type`, `execution_time`, `execute_started_at`, `execute_completed_at`, `compile_started_at`, `compile_completed_at`, `rows_affected`, `full_refresh`, `compiled_code`, `failures`, `query_id`, `thread_id`)


    
[0m22:59:34.482636 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ee6d40ab-adbd-40cc-b6cb-6d951a3ae839&page=queryresults
[0m22:59:34.486031 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_exposures (execute): 2023-04-20 22:59:26.074695 => 2023-04-20 22:59:34.485954
[0m22:59:34.487012 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128e1a890>]}
[0m22:59:34.487782 [info ] [Thread-3 (]: 3 of 32 OK created sql incremental model de_data_warehouse.dbt_exposures ....... [[32mMERGE (0.0 rows, 0 processed)[0m in 8.68s]
[0m22:59:34.488519 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_exposures
[0m22:59:34.489137 [debug] [Thread-3 (]: Began running node model.elementary.dbt_seeds
[0m22:59:34.489639 [info ] [Thread-3 (]: 8 of 32 START sql incremental model de_data_warehouse.dbt_seeds ................ [RUN]
[0m22:59:34.490476 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_seeds'
[0m22:59:34.490805 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_seeds
[0m22:59:34.516679 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_seeds"
[0m22:59:34.517312 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_seeds (compile): 2023-04-20 22:59:34.491022 => 2023-04-20 22:59:34.517240
[0m22:59:34.517566 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_seeds
[0m22:59:34.525063 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:59:34.555181 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:dd0c0fd6-f294-4f4f-8bba-50da3b5165a8&page=queryresults
[0m22:59:34.558816 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__tmp_20230420225933224002`
    );
  
  
[0m22:59:34.574413 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:35.036906 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:f70ccd64-d62b-48d5-9267-5759285ba8d0&page=queryresults
[0m22:59:35.047376 [debug] [Thread-4 (]: Elementary: [dbt_models] Flattening the artifacts.
[0m22:59:35.179535 [debug] [Thread-4 (]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m22:59:35.183699 [debug] [Thread-4 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420225935181046`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
        WHERE 1 = 0
    
    );
  
  
[0m22:59:35.561335 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:35ab227f-1b09-4962-b76a-d73df4f42b31&page=queryresults
[0m22:59:35.564220 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_run_results (execute): 2023-04-20 22:59:30.942067 => 2023-04-20 22:59:35.564055
[0m22:59:35.565558 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1290b4f10>]}
[0m22:59:35.566251 [info ] [Thread-2 (]: 7 of 32 OK created sql incremental model de_data_warehouse.dbt_run_results ..... [[32mMERGE (0.0 rows, 48.6 KB processed)[0m in 4.67s]
[0m22:59:35.566923 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_run_results
[0m22:59:35.567334 [debug] [Thread-2 (]: Began running node model.elementary.dbt_snapshots
[0m22:59:35.567773 [info ] [Thread-2 (]: 9 of 32 START sql incremental model de_data_warehouse.dbt_snapshots ............ [RUN]
[0m22:59:35.568763 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.dbt_snapshots'
[0m22:59:35.569317 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_snapshots
[0m22:59:35.595633 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_snapshots"
[0m22:59:35.596542 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_snapshots (compile): 2023-04-20 22:59:35.569683 => 2023-04-20 22:59:35.596442
[0m22:59:35.596915 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_snapshots
[0m22:59:35.603647 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:35.654295 [debug] [Thread-2 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('dummy_string' as string) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:37.017523 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e1eeb998-788d-434a-b442-ddd4ed8f6ab8&page=queryresults
[0m22:59:37.024400 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_metrics (execute): 2023-04-20 22:59:28.162445 => 2023-04-20 22:59:37.024328
[0m22:59:37.025465 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128c90bd0>]}
[0m22:59:37.027423 [info ] [Thread-1 (]: 5 of 32 OK created sql incremental model de_data_warehouse.dbt_metrics ......... [[32mMERGE (0.0 rows, 0 processed)[0m in 8.91s]
[0m22:59:37.028590 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_metrics
[0m22:59:37.029067 [debug] [Thread-1 (]: Began running node model.elementary.dbt_source_freshness_results
[0m22:59:37.029474 [info ] [Thread-1 (]: 10 of 32 START sql incremental model de_data_warehouse.dbt_source_freshness_results  [RUN]
[0m22:59:37.030452 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_source_freshness_results'
[0m22:59:37.030806 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_source_freshness_results
[0m22:59:37.050108 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_source_freshness_results"
[0m22:59:37.050787 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_source_freshness_results (compile): 2023-04-20 22:59:37.031014 => 2023-04-20 22:59:37.050707
[0m22:59:37.051115 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_source_freshness_results
[0m22:59:37.057281 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:37.106933 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_source_freshness_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as source_freshness_execution_id

,
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as max_loaded_at

,
                
        cast('dummy_string' as string) as snapshotted_at

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast(123456789.99 as FLOAT64) as max_loaded_at_time_ago_in_s

,
                
        cast('dummy_string' as string) as status

,
                
        cast('dummy_string' as string) as error

,
                
        cast('dummy_string' as string) as compile_started_at

,
                
        cast('dummy_string' as string) as compile_completed_at

,
                
        cast('dummy_string' as string) as execute_started_at

,
                
        cast('dummy_string' as string) as execute_completed_at

,
                
        cast('dummy_string' as string) as invocation_id


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m22:59:37.133898 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:39fa5b3c-c670-4643-91f9-a07015b33b81&page=queryresults
[0m22:59:37.271222 [debug] [Thread-4 (]: Elementary: Inserting 32 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420225935181046`
[0m22:59:37.278018 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:fdadbca3-db4b-4716-8010-f6d094f37d45&page=queryresults
[0m22:59:37.956626 [debug] [Thread-3 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:37.978018 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_seeds"
[0m22:59:38.028404 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`checksum` = DBT_INTERNAL_SOURCE.`checksum`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`description` = DBT_INTERNAL_SOURCE.`description`,`name` = DBT_INTERNAL_SOURCE.`name`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `alias`, `checksum`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `alias`, `checksum`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m22:59:38.039312 [debug] [Thread-4 (]: Elementary: [1/1] Running insert query.
[0m22:59:38.042304 [debug] [Thread-4 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420225935181046`
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,generated_at,metadata_hash) values
    ('model.elementary.snapshot_run_results','snapshot_run_results','25bf33e62e7405e06cff77de7ee9e748c7d9c6f28889e88eeb2975cdec933457','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.dbt_run_results", "model.elementary.dbt_snapshots"]','Run results of dbt snapshots, enriched with snapshots metadata. Each row is the result of a single snapshot. This is a view that joins data from `dbt_run_results` and `dbt_snapshots`.\n','snapshot_run_results','elementary','models/edr/run_results/snapshot_run_results.sql','edr/run_results/snapshot_run_results.sql','2023-04-20 22:59:35','b2e8ee2ee6429401a1749565ce18bbb8'),('model.elementary.job_run_results','job_run_results','4f77bef7722550578b36f29135d6c77fc2f0985e3e9362881f857f2bdf99ccdf','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.timediff"]','["model.elementary.dbt_invocations"]','Run results of dbt invocations, enriched with jobs metadata. Each row is the result of a single job. This is a view on `dbt_invocations`.','job_run_results','elementary','models/edr/run_results/job_run_results.sql','edr/run_results/job_run_results.sql','2023-04-20 22:59:35','cfe6d470f7287227f3b9d941e5ed6763'),('model.elementary.model_run_results','model_run_results','b13f8a6604ca22e1f7b968c6383ca9333cf443c852cc677e4b25985a5750d42c','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_time_trunc"]','["model.elementary.dbt_models", "model.elementary.dbt_run_results"]','Run results of dbt models, enriched with models metadata. Each row is the result of a single model. This is a view that joins data from `dbt_run_results` and `dbt_models`.\n','model_run_results','elementary','models/edr/run_results/model_run_results.sql','edr/run_results/model_run_results.sql','2023-04-20 22:59:35','b1b27b2c855f8f443b7a29ad7caf349f'),('model.elementary.test_result_rows','test_result_rows','f882d86b0cf618b35fd6f0825316eacf1be69fe55009f74551898a5be31962fc','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.backfill_result_rows", "macro.elementary.empty_table", "macro.elementary.get_config_var"]','["model.elementary.elementary_test_results", "model.elementary.elementary_test_results", "model.elementary.elementary_test_results"]','','test_result_rows','elementary','models/edr/run_results/test_result_rows.sql','edr/run_results/test_result_rows.sql','2023-04-20 22:59:35','aa11986de0436f139683e212b22e9e9b'),('model.elementary.elementary_test_results','elementary_test_results','7b92ed7eb8aa32dd1af920bc70ab408480f469992371aaa6e2fa9722927beb08','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_elementary_test_results", "macro.elementary.get_config_var"]','[]','Run results of all dbt tests, with fields and metadata needed to produce the Elementary report UI. Each row is the result of a single test, including native dbt tests, packages tests and elementary tests. New data is loaded to this model on an on-run-end hook named `elementary.handle_tests_results`.\n','elementary_test_results','elementary','models/edr/run_results/elementary_test_results.sql','edr/run_results/elementary_test_results.sql','2023-04-20 22:59:35','a24cdc13f2a59ca31fce11149bf64905'),('model.elementary.dbt_source_freshness_results','dbt_source_freshness_results','400e5c6af2b56ab6dc10bb33edfecb74988b768bf1091087e13795a5a32a0cdf','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_dbt_source_freshness_results", "macro.elementary.get_config_var"]','[]','','dbt_source_freshness_results','elementary','models/edr/run_results/dbt_source_freshness_results.sql','edr/run_results/dbt_source_freshness_results.sql','2023-04-20 22:59:35','1168a7a7f029edabcf6dc34051f5ca37'),('model.elementary.alerts_dbt_tests','alerts_dbt_tests','644e6360ece0829a8d77509903a110b8fca81b1dedf34b8cb8b5bdcc75f83922','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate dbt tests alerts, including all the fields the alert will include such as owner, tags, error message, etc. This view includes data about all dbt tests except elementary tests. It filters alerts according to configuration.\n','alerts_dbt_tests','elementary','models/edr/alerts/alerts_dbt_tests.sql','edr/alerts/alerts_dbt_tests.sql','2023-04-20 22:59:35','277e4a40cf57ab225729f6aa6a27be08'),('model.elementary.alerts_schema_changes','alerts_schema_changes','96c9a42ca06d726bff66c903a314b13c6beb1641347aba54d93710161d2391e1','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on schema changes detected using elementary tests. The view filters alerts according to configuration.','alerts_schema_changes','elementary','models/edr/alerts/alerts_schema_changes.sql','edr/alerts/alerts_schema_changes.sql','2023-04-20 22:59:35','257b4ac15bd154e52b832da313def902'),('model.elementary.alerts_dbt_source_freshness','alerts_dbt_source_freshness','ec03b412a62d28d45853ddb68502724c9bee8ae8bf16d203391711546f5904b0','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.dbt_source_freshness_results", "model.elementary.dbt_sources"]','','alerts_dbt_source_freshness','elementary','models/edr/alerts/alerts_dbt_source_freshness.sql','edr/alerts/alerts_dbt_source_freshness.sql','2023-04-20 22:59:35','f8d27490eeb21de3c129459fedd42899'),('model.elementary.alerts_anomaly_detection','alerts_anomaly_detection','0d2bb9c33ded81e6501643abeeacde1b21695f406b861f748923e4bd9ce0c4c8','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on data anomalies detected using the elementary anomaly detection tests. The view filters alerts according to configuration.\n','alerts_anomaly_detection','elementary','models/edr/alerts/alerts_anomaly_detection.sql','edr/alerts/alerts_anomaly_detection.sql','2023-04-20 22:59:35','abc8859218c6d0216fac24f1207f1bd9'),('model.elementary.alerts_dbt_models','alerts_dbt_models','aad00742146b5339efa4fbb9e8f475745116c1a6603d7a0999a2ba5d9e4392c6','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.model_run_results", "model.elementary.snapshot_run_results"]','A view that is used by the Elementary CLI to generate models alerts, including all the fields the alert will include such as owner, tags, error message, etc. It joins data about models and snapshots run results, and filters alerts according to configuration.\n','alerts_dbt_models','elementary','models/edr/alerts/alerts_dbt_models.sql','edr/alerts/alerts_dbt_models.sql','2023-04-20 22:59:35','853e5956cb3d5201c1f6ab18a3194491'),('model.elementary.monitors_runs','monitors_runs','3720e206635d4f2f95c193835727b0d533ec1a5fa56e5dec79331418d07e934f','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that is used to determine when a specific anomaly detection test was last executed. Each anomaly detection test queries this view to decide on a start time for collecting metrics.\n','monitors_runs','elementary','models/edr/system/monitors_runs.sql','edr/system/monitors_runs.sql','2023-04-20 22:59:35','fc5b979579f0fd4a9060a6f588a30220'),('model.elementary.metadata','metadata','08d0f5a6af1433ddf3b0077d85b594442a49901cd430729fd050c0417c48b5a2','table','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_elementary_package_version"]','[]','','metadata','elementary','models/edr/system/metadata.sql','edr/system/metadata.sql','2023-04-20 22:59:35','2d7e3e5b23a516456a352ca0fbc1603f'),('model.elementary.dbt_tests','dbt_tests','741409041141e4601052d37da988d545419809fd0c630fa7cfee31d75e66a5c2','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_tests_empty_table_query", "macro.elementary.upload_dbt_tests"]','[]','Metadata about tests in the project, including configuration and properties from the dbt graph. Each row contains information about a single test. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_tests','elementary','models/edr/dbt_artifacts/dbt_tests.sql','edr/dbt_artifacts/dbt_tests.sql','2023-04-20 22:59:35','582352ecff6170098dc8b5fd9c6b2de4'),('model.elementary.dbt_models','dbt_models','593b000e1d5ce7b219e4de4086c067491fb0333274ab375e793ccb2fb9fd3759','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.upload_dbt_models"]','[]','Metadata about models in the project, including configuration and properties from the dbt graph. Each row contains information about a single model. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_models','elementary','models/edr/dbt_artifacts/dbt_models.sql','edr/dbt_artifacts/dbt_models.sql','2023-04-20 22:59:35','45a6667f857b50814c08963227979fb7'),('model.elementary.dbt_sources','dbt_sources','d8a8439c596b52172075bc5b4106ba6c38d6dbfddbb83677b08815ea400bc712','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_sources_empty_table_query", "macro.elementary.upload_dbt_sources"]','[]','Metadata about sources in the project, including configuration and properties from the dbt graph. Each row contains information about a single source. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_sources','elementary','models/edr/dbt_artifacts/dbt_sources.sql','edr/dbt_artifacts/dbt_sources.sql','2023-04-20 22:59:35','4f5a6af3fc8463f8cba80ff847ac92e9'),('model.elementary.dbt_snapshots','dbt_snapshots','e9a4dd4bf0b0a9ec362d517a263768f9c09d319b49297618b0e68201241db006','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.upload_dbt_snapshots"]','[]','Metadata about snapshots in the project, including configuration and properties from the dbt graph. Each row contains information about a single snapshot. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_snapshots','elementary','models/edr/dbt_artifacts/dbt_snapshots.sql','edr/dbt_artifacts/dbt_snapshots.sql','2023-04-20 22:59:35','1fad44195b8c7d17da299adf691e5839'),('model.elementary.dbt_invocations','dbt_invocations','eb905380b5a7d9d7a1daab283bae14bea8800fff22a3a6d25f5d44fea739717f','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_invocations_empty_table_query"]','[]','Attributes associated with each dbt invocation. Inserted at the end of each invocation.\n','dbt_invocations','elementary','models/edr/dbt_artifacts/dbt_invocations.sql','edr/dbt_artifacts/dbt_invocations.sql','2023-04-20 22:59:35','21c91fb0fa00307fdb36d4ccfc5d13f5'),('model.elementary.dbt_metrics','dbt_metrics','346d0ae98ddf568e9102387d30aa7d9ee4c8c3c3ea58cd254e5e57fcb800f7e9','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_metrics_empty_table_query", "macro.elementary.upload_dbt_metrics"]','[]','Metadata about metics in the project, including configuration and properties from the dbt graph. Each row contains information about a single metric. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_metrics','elementary','models/edr/dbt_artifacts/dbt_metrics.sql','edr/dbt_artifacts/dbt_metrics.sql','2023-04-20 22:59:35','3996cb4cd74bfefd0fd9a88f5b170024'),('model.elementary.dbt_seeds','dbt_seeds','8daecb4cb68c55a0ad53ba73468d4537965acf2ccdc5c4343b9e1f4e3ae6f197','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_seeds_empty_table_query", "macro.elementary.upload_dbt_seeds"]','[]','','dbt_seeds','elementary','models/edr/dbt_artifacts/dbt_seeds.sql','edr/dbt_artifacts/dbt_seeds.sql','2023-04-20 22:59:35','f1d124eda9e29d0b21e9c31e6cf99aee'),('model.elementary.dbt_artifacts_hashes','dbt_artifacts_hashes','a493a63069e8e18354eb9fe4d6e0cd21f83f7efb7c9ffc1ff5cece8943b74f85','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.dbt_exposures", "model.elementary.dbt_metrics", "model.elementary.dbt_models", "model.elementary.dbt_seeds", "model.elementary.dbt_snapshots", "model.elementary.dbt_sources", "model.elementary.dbt_tests"]','','dbt_artifacts_hashes','elementary','models/edr/dbt_artifacts/dbt_artifacts_hashes.sql','edr/dbt_artifacts/dbt_artifacts_hashes.sql','2023-04-20 22:59:35','c11fe71d307067d4412509b15de1ed21'),('model.elementary.dbt_run_results','dbt_run_results','ecee798e20623bd3fe0d1822356a14c63f8a99e251ccf1aff743b0b3759c548d','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_run_results_empty_table_query"]','[]','Run results of dbt invocations, inserted at the end of each invocation. Each row is the invocation result of a single resource (model, test, snapshot, etc). New data is loaded to this model on an on-run-end hook named \'elementary.upload_run_results\' from each invocation that produces a result object. This is an incremental model.\n','dbt_run_results','elementary','models/edr/dbt_artifacts/dbt_run_results.sql','edr/dbt_artifacts/dbt_run_results.sql','2023-04-20 22:59:35','2bff3e8c2c1d0e9f67b04bb75ea7007e'),('model.elementary.dbt_exposures','dbt_exposures','8a682af36a6af01c41098c007da5b2fbe040cc282350e2817269b1b20b0f0e36','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_exposures_empty_table_query", "macro.elementary.upload_dbt_exposures"]','[]','Metadata about exposures in the project, including configuration and properties from the dbt graph. Each row contains information about a single exposure. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_exposures','elementary','models/edr/dbt_artifacts/dbt_exposures.sql','edr/dbt_artifacts/dbt_exposures.sql','2023-04-20 22:59:35','3db9239b91b8669ccd9a93cdc10b8901'),('model.elementary.metrics_anomaly_score','metrics_anomaly_score','abfd27ad29f3a4da67885dfd0c82ed98c043958f705c4258175db6c306d0795e','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.dbt_utils.group_by", "macro.elementary.edr_current_timestamp", "macro.elementary.edr_date_trunc", "macro.elementary.edr_timeadd", "macro.elementary.get_config_var"]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that runs the same query the anomaly detection tests run to calculate anomaly scores. The purpose of this view is to provide visibility to the results of anomaly detection tests.\n','metrics_anomaly_score','elementary','models/edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','2023-04-20 22:59:35','40815ab8a31b1886c8776436d0eeb6be'),('model.elementary.anomaly_threshold_sensitivity','anomaly_threshold_sensitivity','193ea3f501e775b7e3865e489edfff8936fed64d1f9063393292082e8a69d005','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_quote_column"]','["model.elementary.metrics_anomaly_score"]','This is a view on `metrics_anomaly_score` that calculates if values of metrics from latest runs would have been considered anomalies in different anomaly scores. This can help you decide if there is a need to adjust the `anomaly_score_threshold`.\n','anomaly_threshold_sensitivity','elementary','models/edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','2023-04-20 22:59:35','19252671a087e268e34e867f994c44ba'),('model.elementary.schema_columns_snapshot','schema_columns_snapshot','4026dd4e8a55d4d5811bdb27cd4214398607ed24bc5b3940ee40dbb4b42a4f2f','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_schema_columns_snapshot", "macro.elementary.get_config_var"]','[]','Stores the schema details for tables that are monitored with elementary schema changes test. In order to compare current schema to previous state, we must store the previous state. The data is from a view that queries the data warehouse information schema. This is an incremental table.\n','schema_columns_snapshot','elementary','models/edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','2023-04-20 22:59:35','85e17bc2cee1e746f638449c1f9c0dce'),('model.elementary.data_monitoring_metrics','data_monitoring_metrics','4654d1519d81eca2b622d05e7fd6a0c85fea9126025078173a6b99ff3418bbd2','incremental','[]','{"timestamp_column": "updated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_data_monitoring_metrics", "macro.elementary.get_config_var"]','[]','Elementary anomaly detection tests monitor metrics such as volume, freshness and data quality metrics. This incremental table is used to store the metrics over time. On each anomaly detection test, the test queries this table for historical metrics, and compares to the latest values. The table is updated with new metrics on the on-run-end named handle_test_results that is executed at the end of dbt test invocations.\n','data_monitoring_metrics','elementary','models/edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','2023-04-20 22:59:35','f04d74fc1abcf2f5ccce035084f09076'),('model.elementary.filtered_information_schema_columns','filtered_information_schema_columns','8b0602cbf990730afd02271c018d6843414aaff35c5d6e191c8711e570178d7b','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_table", "macro.elementary.get_configured_schemas_from_graph"]','[]','Queries the columns view from the information schema of the schemas in the project. This view is generated using an adapter specific macro, as information schema is different between platforms. This is a view to make the work with the information schema more convinient.\n','filtered_information_schema_columns','elementary','models/edr/metadata_store/filtered_information_schema_columns.sql','edr/metadata_store/filtered_information_schema_columns.sql','2023-04-20 22:59:35','7770ea68471155c6ad930fa2c688dcd7'),('model.elementary.filtered_information_schema_tables','filtered_information_schema_tables','89284ddd42994a960605b4f4de200adbdfc7e467e4bebb7d1debefbe8718839d','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_table", "macro.elementary.get_configured_schemas_from_graph"]','[]','Queries the tables and schemas views from the information schema of the schemas in the project. This view is generated using an adapter specific macro, as information schema is different between platforms. This is a view to make the work with the information schema more convinient.','filtered_information_schema_tables','elementary','models/edr/metadata_store/filtered_information_schema_tables.sql','edr/metadata_store/filtered_information_schema_tables.sql','2023-04-20 22:59:35','2d8307a460561db81f97c4a08828ee9f'),('model.de_project.final_land_and_property','final_land_and_property','630617aeffb59ffe66475bed6ccc49f56b5c1b14ad0d98b3bf06fdf56b9beeef','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.de_project.land_and_property_transform"]','','final_land_and_property','de_project','models/core/final_land_and_property.sql','core/final_land_and_property.sql','2023-04-20 22:59:35','e00a803282655eab912faaa4afa92cf4'),('model.de_project.land_and_property_transform','land_and_property_transform','705aa5a5fe5a0d2d7e54e62b9cad3c679e12969b56a45015a64b4fe8d843ed80','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.de_project.land_and_property_optimized_raw"]','','land_and_property_transform','de_project','models/transform/land_and_property_transform.sql','transform/land_and_property_transform.sql','2023-04-20 22:59:35','77f3e269736e203f5c332cf385ce803b'),('model.de_project.land_and_property_optimized_raw','land_and_property_optimized_raw','0b0a8a2e95020e232cd3ed84bf2551afc5ebdfb1efc67917e581e4eaeec65128','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["source.de_project.de_data_warehouse.land_and_property_optimized"]','','land_and_property_optimized_raw','de_project','models/raw/land_and_property_optimized_raw.sql','raw/land_and_property_optimized_raw.sql','2023-04-20 22:59:35','51c344cfd702e3e2a83eb973b1a324b4')
  
[0m22:59:38.323738 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:d2a1a52d-fd86-4d71-9ced-fdf4f64504c5&page=queryresults
[0m22:59:38.606641 [debug] [Thread-2 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:38.611236 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_snapshots"
[0m22:59:38.612310 [debug] [Thread-2 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`checksum` = DBT_INTERNAL_SOURCE.`checksum`,`materialization` = DBT_INTERNAL_SOURCE.`materialization`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`name` = DBT_INTERNAL_SOURCE.`name`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m22:59:39.500114 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e38aa4fe-a46d-44c6-a4ec-331c830fccdb&page=queryresults
[0m22:59:39.587433 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5ad5aac6-4d4d-412b-b93a-a50e81a6c212&page=queryresults
[0m22:59:39.595263 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m22:59:39.597000 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m22:59:39.604580 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__tmp_20230420225939599493`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`
        WHERE 1 = 0
    
    );
  
  
[0m22:59:39.612908 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8009dc5f-74dd-4acc-9405-b61f37a61e3a&page=queryresults
[0m22:59:39.615669 [debug] [Thread-4 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420225935181046`
    );
  
  
[0m22:59:40.165687 [debug] [Thread-1 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:40.169389 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_source_freshness_results"
[0m22:59:40.170281 [debug] [Thread-1 (]: On model.elementary.dbt_source_freshness_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_source_freshness_results"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.source_freshness_execution_id = DBT_INTERNAL_DEST.source_freshness_execution_id
            )

    
    when matched then update set
        `source_freshness_execution_id` = DBT_INTERNAL_SOURCE.`source_freshness_execution_id`,`unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`max_loaded_at` = DBT_INTERNAL_SOURCE.`max_loaded_at`,`snapshotted_at` = DBT_INTERNAL_SOURCE.`snapshotted_at`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`max_loaded_at_time_ago_in_s` = DBT_INTERNAL_SOURCE.`max_loaded_at_time_ago_in_s`,`status` = DBT_INTERNAL_SOURCE.`status`,`error` = DBT_INTERNAL_SOURCE.`error`,`compile_started_at` = DBT_INTERNAL_SOURCE.`compile_started_at`,`compile_completed_at` = DBT_INTERNAL_SOURCE.`compile_completed_at`,`execute_started_at` = DBT_INTERNAL_SOURCE.`execute_started_at`,`execute_completed_at` = DBT_INTERNAL_SOURCE.`execute_completed_at`,`invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`
    

    when not matched then insert
        (`source_freshness_execution_id`, `unique_id`, `max_loaded_at`, `snapshotted_at`, `generated_at`, `max_loaded_at_time_ago_in_s`, `status`, `error`, `compile_started_at`, `compile_completed_at`, `execute_started_at`, `execute_completed_at`, `invocation_id`)
    values
        (`source_freshness_execution_id`, `unique_id`, `max_loaded_at`, `snapshotted_at`, `generated_at`, `max_loaded_at_time_ago_in_s`, `status`, `error`, `compile_started_at`, `compile_completed_at`, `execute_started_at`, `execute_completed_at`, `invocation_id`)


    
[0m22:59:40.270470 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:04d7c224-0e0e-4c03-9f97-6f2226312bda&page=queryresults
[0m22:59:40.277874 [debug] [Thread-2 (]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m22:59:40.280139 [debug] [Thread-2 (]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m22:59:40.285912 [debug] [Thread-2 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__tmp_20230420225940282124`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
        WHERE 1 = 0
    
    );
  
  
[0m22:59:41.292843 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5c8cf074-afbf-4fb0-8492-1313803e77e7&page=queryresults
[0m22:59:41.295963 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__tmp_20230420225939599493`
    );
  
  
[0m22:59:41.299044 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e4a772d9-53e2-4315-986e-4ae95d4ff030&page=queryresults
[0m22:59:41.301338 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_models (execute): 2023-04-20 22:59:30.754901 => 2023-04-20 22:59:41.301286
[0m22:59:41.302342 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128def910>]}
[0m22:59:41.303020 [info ] [Thread-4 (]: 6 of 32 OK created sql incremental model de_data_warehouse.dbt_models .......... [[32mMERGE (0.0 rows, 20.7 KB processed)[0m in 10.59s]
[0m22:59:41.304210 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_models
[0m22:59:41.304620 [debug] [Thread-4 (]: Began running node model.elementary.dbt_sources
[0m22:59:41.305038 [info ] [Thread-4 (]: 11 of 32 START sql incremental model de_data_warehouse.dbt_sources ............. [RUN]
[0m22:59:41.306250 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_sources'
[0m22:59:41.306587 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_sources
[0m22:59:41.342477 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_sources"
[0m22:59:41.343259 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_sources (compile): 2023-04-20 22:59:41.306753 => 2023-04-20 22:59:41.343139
[0m22:59:41.343635 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_sources
[0m22:59:41.353240 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:59:41.404133 [debug] [Thread-4 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as source_name

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as identifier

,
                
        cast('dummy_string' as string) as loaded_at_field

,
                
        cast('dummy_string' as string) as freshness_warn_after

,
                
        cast('dummy_string' as string) as freshness_error_after

,
                
        cast('this_is_just_a_long_dummy_string' as string) as freshness_filter

,
                
        cast('dummy_string' as string) as relation_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('this_is_just_a_long_dummy_string' as string) as source_description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:41.744733 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:199fbaaa-7cd2-4708-ba0a-a8989e9929a9&page=queryresults
[0m22:59:41.747028 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_source_freshness_results (execute): 2023-04-20 22:59:37.051317 => 2023-04-20 22:59:41.746965
[0m22:59:41.748198 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128d23490>]}
[0m22:59:41.748851 [info ] [Thread-1 (]: 10 of 32 OK created sql incremental model de_data_warehouse.dbt_source_freshness_results  [[32mMERGE (0.0 rows, 0 processed)[0m in 4.72s]
[0m22:59:41.749448 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_source_freshness_results
[0m22:59:41.750060 [debug] [Thread-1 (]: Began running node model.elementary.dbt_tests
[0m22:59:41.750689 [info ] [Thread-1 (]: 12 of 32 START sql incremental model de_data_warehouse.dbt_tests ............... [RUN]
[0m22:59:41.751365 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_tests'
[0m22:59:41.751791 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_tests
[0m22:59:41.829955 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_tests"
[0m22:59:41.831041 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_tests (compile): 2023-04-20 22:59:41.752047 => 2023-04-20 22:59:41.830923
[0m22:59:41.831790 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_tests
[0m22:59:41.849508 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:41.910400 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as short_name

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as test_column_name

,
                
        cast('dummy_string' as string) as severity

,
                
        cast('dummy_string' as string) as warn_if

,
                
        cast('dummy_string' as string) as error_if

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_params

,
                
        cast('dummy_string' as string) as test_namespace

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_owners

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('dummy_string' as string) as parent_model_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('dummy_string' as string) as type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:42.118325 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:d9c55162-636c-46ea-a31c-e0087ecf7a73&page=queryresults
[0m22:59:42.121274 [debug] [Thread-2 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__tmp_20230420225940282124`
    );
  
  
[0m22:59:43.167540 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:2154f53f-9d04-4da1-ba35-23ec14d08c3e&page=queryresults
[0m22:59:43.170397 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_seeds (execute): 2023-04-20 22:59:34.517736 => 2023-04-20 22:59:43.170321
[0m22:59:43.171382 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128d498d0>]}
[0m22:59:43.172002 [info ] [Thread-3 (]: 8 of 32 OK created sql incremental model de_data_warehouse.dbt_seeds ........... [[32mMERGE (0.0 rows, 0 processed)[0m in 8.68s]
[0m22:59:43.173221 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_seeds
[0m22:59:43.173833 [debug] [Thread-3 (]: Began running node model.elementary.elementary_test_results
[0m22:59:43.174465 [info ] [Thread-3 (]: 13 of 32 START sql incremental model de_data_warehouse.elementary_test_results . [RUN]
[0m22:59:43.175375 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.elementary_test_results'
[0m22:59:43.175751 [debug] [Thread-3 (]: Began compiling node model.elementary.elementary_test_results
[0m22:59:43.213275 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.elementary_test_results"
[0m22:59:43.214034 [debug] [Thread-3 (]: Timing info for model.elementary.elementary_test_results (compile): 2023-04-20 22:59:43.175981 => 2023-04-20 22:59:43.213926
[0m22:59:43.214540 [debug] [Thread-3 (]: Began executing node model.elementary.elementary_test_results
[0m22:59:43.222097 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:59:43.269626 [debug] [Thread-3 (]: On model.elementary.elementary_test_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.elementary_test_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      


    with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as id

,
                
        cast('dummy_string' as string) as data_issue_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_unique_id

,
                
        cast('dummy_string' as string) as invocation_id

,
                cast('2091-02-17' as TIMESTAMP) as detected_at

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as test_type

,
                
        cast('dummy_string' as string) as test_sub_type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_results_description

,
                
        cast('dummy_string' as string) as owners

,
                
        cast('dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_results_query

,
                
        cast('dummy_string' as string) as other

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_params

,
                
        cast('dummy_string' as string) as severity

,
                
        cast('dummy_string' as string) as status

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as string) as test_short_name

,
                
        cast('dummy_string' as string) as test_alias

,
                
        cast('this_is_just_a_long_dummy_string' as string) as result_rows


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m22:59:43.838956 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:75917f3a-1f19-49d1-9384-f1745ef8f351&page=queryresults
[0m22:59:43.843934 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5adfaa7e-507c-4e4a-87d3-7ec899a5e82e&page=queryresults
[0m22:59:43.849160 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_snapshots (execute): 2023-04-20 22:59:35.597172 => 2023-04-20 22:59:43.849039
[0m22:59:43.850259 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128e66190>]}
[0m22:59:43.851641 [info ] [Thread-2 (]: 9 of 32 OK created sql incremental model de_data_warehouse.dbt_snapshots ....... [[32mMERGE (0.0 rows, 0 processed)[0m in 8.28s]
[0m22:59:43.852387 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_snapshots
[0m22:59:43.853052 [debug] [Thread-2 (]: Began running node model.elementary.filtered_information_schema_columns
[0m22:59:43.853806 [info ] [Thread-2 (]: 14 of 32 START sql view model de_data_warehouse.filtered_information_schema_columns  [RUN]
[0m22:59:43.855100 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.filtered_information_schema_columns'
[0m22:59:43.855501 [debug] [Thread-2 (]: Began compiling node model.elementary.filtered_information_schema_columns
[0m22:59:43.880020 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.filtered_information_schema_columns"
[0m22:59:43.880720 [debug] [Thread-2 (]: Timing info for model.elementary.filtered_information_schema_columns (compile): 2023-04-20 22:59:43.855754 => 2023-04-20 22:59:43.880631
[0m22:59:43.881374 [debug] [Thread-2 (]: Began executing node model.elementary.filtered_information_schema_columns
[0m22:59:43.888220 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.filtered_information_schema_columns"
[0m22:59:43.888982 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:43.938165 [debug] [Thread-2 (]: On model.elementary.filtered_information_schema_columns: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.filtered_information_schema_columns"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`filtered_information_schema_columns`
  OPTIONS()
  as 



with filtered_information_schema_columns as (
        with empty_table as (
            select
            
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as data_type


            )
        select * from empty_table
        where 1 = 0

)

select *
from filtered_information_schema_columns
where full_table_name is not null;


[0m22:59:44.228436 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:44.234898 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_sources"
[0m22:59:44.237824 [debug] [Thread-4 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_sources` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`source_name` = DBT_INTERNAL_SOURCE.`source_name`,`name` = DBT_INTERNAL_SOURCE.`name`,`identifier` = DBT_INTERNAL_SOURCE.`identifier`,`loaded_at_field` = DBT_INTERNAL_SOURCE.`loaded_at_field`,`freshness_warn_after` = DBT_INTERNAL_SOURCE.`freshness_warn_after`,`freshness_error_after` = DBT_INTERNAL_SOURCE.`freshness_error_after`,`freshness_filter` = DBT_INTERNAL_SOURCE.`freshness_filter`,`relation_name` = DBT_INTERNAL_SOURCE.`relation_name`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`source_description` = DBT_INTERNAL_SOURCE.`source_description`,`description` = DBT_INTERNAL_SOURCE.`description`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `database_name`, `schema_name`, `source_name`, `name`, `identifier`, `loaded_at_field`, `freshness_warn_after`, `freshness_error_after`, `freshness_filter`, `relation_name`, `tags`, `meta`, `owner`, `package_name`, `original_path`, `path`, `source_description`, `description`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `database_name`, `schema_name`, `source_name`, `name`, `identifier`, `loaded_at_field`, `freshness_warn_after`, `freshness_error_after`, `freshness_filter`, `relation_name`, `tags`, `meta`, `owner`, `package_name`, `original_path`, `path`, `source_description`, `description`, `generated_at`, `metadata_hash`)


    
[0m22:59:44.496259 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:53f8fae1-cd68-4eb3-97dc-eec129615e42&page=queryresults
[0m22:59:44.753759 [debug] [Thread-1 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:44.759039 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_tests"
[0m22:59:44.759981 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_tests` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`name` = DBT_INTERNAL_SOURCE.`name`,`short_name` = DBT_INTERNAL_SOURCE.`short_name`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`test_column_name` = DBT_INTERNAL_SOURCE.`test_column_name`,`severity` = DBT_INTERNAL_SOURCE.`severity`,`warn_if` = DBT_INTERNAL_SOURCE.`warn_if`,`error_if` = DBT_INTERNAL_SOURCE.`error_if`,`test_params` = DBT_INTERNAL_SOURCE.`test_params`,`test_namespace` = DBT_INTERNAL_SOURCE.`test_namespace`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`model_tags` = DBT_INTERNAL_SOURCE.`model_tags`,`model_owners` = DBT_INTERNAL_SOURCE.`model_owners`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`parent_model_unique_id` = DBT_INTERNAL_SOURCE.`parent_model_unique_id`,`description` = DBT_INTERNAL_SOURCE.`description`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`type` = DBT_INTERNAL_SOURCE.`type`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `database_name`, `schema_name`, `name`, `short_name`, `alias`, `test_column_name`, `severity`, `warn_if`, `error_if`, `test_params`, `test_namespace`, `tags`, `model_tags`, `model_owners`, `meta`, `depends_on_macros`, `depends_on_nodes`, `parent_model_unique_id`, `description`, `package_name`, `type`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `database_name`, `schema_name`, `name`, `short_name`, `alias`, `test_column_name`, `severity`, `warn_if`, `error_if`, `test_params`, `test_namespace`, `tags`, `model_tags`, `model_owners`, `meta`, `depends_on_macros`, `depends_on_nodes`, `parent_model_unique_id`, `description`, `package_name`, `type`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m22:59:45.002584 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ebc920ef-3484-4d35-9bc8-1174ec91b36e&page=queryresults
[0m22:59:45.010082 [debug] [Thread-2 (]: Timing info for model.elementary.filtered_information_schema_columns (execute): 2023-04-20 22:59:43.881720 => 2023-04-20 22:59:45.009898
[0m22:59:45.011247 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12930e390>]}
[0m22:59:45.011806 [info ] [Thread-2 (]: 14 of 32 OK created sql view model de_data_warehouse.filtered_information_schema_columns  [[32mCREATE VIEW (0 processed)[0m in 1.16s]
[0m22:59:45.012352 [debug] [Thread-2 (]: Finished running node model.elementary.filtered_information_schema_columns
[0m22:59:45.012895 [debug] [Thread-2 (]: Began running node model.elementary.filtered_information_schema_tables
[0m22:59:45.013522 [info ] [Thread-2 (]: 15 of 32 START sql view model de_data_warehouse.filtered_information_schema_tables  [RUN]
[0m22:59:45.014431 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.filtered_information_schema_tables'
[0m22:59:45.014915 [debug] [Thread-2 (]: Began compiling node model.elementary.filtered_information_schema_tables
[0m22:59:45.027452 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.filtered_information_schema_tables"
[0m22:59:45.028505 [debug] [Thread-2 (]: Timing info for model.elementary.filtered_information_schema_tables (compile): 2023-04-20 22:59:45.015146 => 2023-04-20 22:59:45.028333
[0m22:59:45.030594 [debug] [Thread-2 (]: Began executing node model.elementary.filtered_information_schema_tables
[0m22:59:45.038893 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.filtered_information_schema_tables"
[0m22:59:45.039539 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:45.091458 [debug] [Thread-2 (]: On model.elementary.filtered_information_schema_tables: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.filtered_information_schema_tables"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`filtered_information_schema_tables`
  OPTIONS()
  as 



with filtered_information_schema_tables as (
        with empty_table as (
            select
            
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as full_schema_name

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name


            )
        select * from empty_table
        where 1 = 0

)

select *
from filtered_information_schema_tables
where schema_name is not null;


[0m22:59:46.076286 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c0c6cfe5-0f64-45e5-9f10-dab48f68f9ce&page=queryresults
[0m22:59:46.087611 [debug] [Thread-4 (]: Elementary: [dbt_sources] Flattening the artifacts.
[0m22:59:46.125166 [debug] [Thread-4 (]: Elementary: [dbt_sources] Flattened 1 artifacts.
[0m22:59:46.135222 [debug] [Thread-4 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420225946130882`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
        WHERE 1 = 0
    
    );
  
  
[0m22:59:46.317038 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:690cfe15-bb38-441e-b649-ef6bf0c614fd&page=queryresults
[0m22:59:46.458502 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:3a71b470-ab02-479b-8fd1-6b5d6778b3ae&page=queryresults
[0m22:59:46.469694 [debug] [Thread-1 (]: Elementary: [dbt_tests] Flattening the artifacts.
[0m22:59:46.472941 [debug] [Thread-1 (]: Elementary: [dbt_tests] Flattened 0 artifacts.
[0m22:59:46.480500 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__tmp_20230420225946474446`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
        WHERE 1 = 0
    
    );
  
  
[0m22:59:46.570978 [debug] [Thread-3 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:46.573252 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.elementary_test_results"
[0m22:59:46.573932 [debug] [Thread-3 (]: On model.elementary.elementary_test_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.elementary_test_results"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
            )

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`data_issue_id` = DBT_INTERNAL_SOURCE.`data_issue_id`,`test_execution_id` = DBT_INTERNAL_SOURCE.`test_execution_id`,`test_unique_id` = DBT_INTERNAL_SOURCE.`test_unique_id`,`model_unique_id` = DBT_INTERNAL_SOURCE.`model_unique_id`,`invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`,`detected_at` = DBT_INTERNAL_SOURCE.`detected_at`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`table_name` = DBT_INTERNAL_SOURCE.`table_name`,`column_name` = DBT_INTERNAL_SOURCE.`column_name`,`test_type` = DBT_INTERNAL_SOURCE.`test_type`,`test_sub_type` = DBT_INTERNAL_SOURCE.`test_sub_type`,`test_results_description` = DBT_INTERNAL_SOURCE.`test_results_description`,`owners` = DBT_INTERNAL_SOURCE.`owners`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`test_results_query` = DBT_INTERNAL_SOURCE.`test_results_query`,`other` = DBT_INTERNAL_SOURCE.`other`,`test_name` = DBT_INTERNAL_SOURCE.`test_name`,`test_params` = DBT_INTERNAL_SOURCE.`test_params`,`severity` = DBT_INTERNAL_SOURCE.`severity`,`status` = DBT_INTERNAL_SOURCE.`status`,`failures` = DBT_INTERNAL_SOURCE.`failures`,`test_short_name` = DBT_INTERNAL_SOURCE.`test_short_name`,`test_alias` = DBT_INTERNAL_SOURCE.`test_alias`,`result_rows` = DBT_INTERNAL_SOURCE.`result_rows`
    

    when not matched then insert
        (`id`, `data_issue_id`, `test_execution_id`, `test_unique_id`, `model_unique_id`, `invocation_id`, `detected_at`, `database_name`, `schema_name`, `table_name`, `column_name`, `test_type`, `test_sub_type`, `test_results_description`, `owners`, `tags`, `test_results_query`, `other`, `test_name`, `test_params`, `severity`, `status`, `failures`, `test_short_name`, `test_alias`, `result_rows`)
    values
        (`id`, `data_issue_id`, `test_execution_id`, `test_unique_id`, `model_unique_id`, `invocation_id`, `detected_at`, `database_name`, `schema_name`, `table_name`, `column_name`, `test_type`, `test_sub_type`, `test_results_description`, `owners`, `tags`, `test_results_query`, `other`, `test_name`, `test_params`, `severity`, `status`, `failures`, `test_short_name`, `test_alias`, `result_rows`)


    
[0m22:59:46.964678 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:3b8fc715-d0ed-4fe8-8c7c-a99f2cbef291&page=queryresults
[0m22:59:46.966805 [debug] [Thread-2 (]: Timing info for model.elementary.filtered_information_schema_tables (execute): 2023-04-20 22:59:45.031989 => 2023-04-20 22:59:46.966750
[0m22:59:46.967506 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128e66190>]}
[0m22:59:46.967925 [info ] [Thread-2 (]: 15 of 32 OK created sql view model de_data_warehouse.filtered_information_schema_tables  [[32mCREATE VIEW (0 processed)[0m in 1.95s]
[0m22:59:46.968275 [debug] [Thread-2 (]: Finished running node model.elementary.filtered_information_schema_tables
[0m22:59:46.968693 [debug] [Thread-2 (]: Began running node model.elementary.metadata
[0m22:59:46.969379 [info ] [Thread-2 (]: 16 of 32 START sql table model de_data_warehouse.metadata ...................... [RUN]
[0m22:59:46.970195 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.metadata'
[0m22:59:46.970567 [debug] [Thread-2 (]: Began compiling node model.elementary.metadata
[0m22:59:46.988947 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.metadata"
[0m22:59:46.989837 [debug] [Thread-2 (]: Timing info for model.elementary.metadata (compile): 2023-04-20 22:59:46.970776 => 2023-04-20 22:59:46.989718
[0m22:59:46.990149 [debug] [Thread-2 (]: Began executing node model.elementary.metadata
[0m22:59:47.009046 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:47.894670 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.metadata"
[0m22:59:47.899318 [debug] [Thread-2 (]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.metadata"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`metadata`
    
    
    OPTIONS()
    as (
      

SELECT
    '0.7.5' as dbt_pkg_version
    );
  
[0m22:59:48.031652 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:49a90f79-4c9c-46fc-9109-faafcfba0bc3&page=queryresults
[0m22:59:48.116139 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:a4d4d152-7243-4b4d-8bbe-ad53921c94ef&page=queryresults
[0m22:59:48.122282 [debug] [Thread-1 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__tmp_20230420225946474446`
    );
  
  
[0m22:59:48.168056 [debug] [Thread-4 (]: Elementary: Inserting 1 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420225946130882`
[0m22:59:48.201888 [debug] [Thread-4 (]: Elementary: [1/1] Running insert query.
[0m22:59:48.203696 [debug] [Thread-4 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420225946130882`
         (unique_id,database_name,schema_name,source_name,name,identifier,loaded_at_field,freshness_warn_after,freshness_error_after,freshness_filter,relation_name,tags,meta,owner,package_name,original_path,path,source_description,description,generated_at,metadata_hash) values
    ('source.de_project.de_data_warehouse.land_and_property_optimized','dtc-de-383113','de_data_warehouse','de_data_warehouse','land_and_property_optimized','land_and_property_optimized',NULL,'{"count": null, "period": null}','{"count": null, "period": null}',NULL,'`dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized`','[]','{}',NULL,'de_project','models/raw/sources.yml','models/raw/sources.yml','','','2023-04-20 22:59:46','fc4865e15760a1575b8bb1dab7c24692')
  
[0m22:59:48.531488 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c31ec834-4144-44e4-bb86-1138617a3600&page=queryresults
[0m22:59:48.534962 [debug] [Thread-3 (]: Timing info for model.elementary.elementary_test_results (execute): 2023-04-20 22:59:43.215143 => 2023-04-20 22:59:48.534880
[0m22:59:48.535997 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129284f10>]}
[0m22:59:48.536630 [info ] [Thread-3 (]: 13 of 32 OK created sql incremental model de_data_warehouse.elementary_test_results  [[32mMERGE (0.0 rows, 0 processed)[0m in 5.36s]
[0m22:59:48.537229 [debug] [Thread-3 (]: Finished running node model.elementary.elementary_test_results
[0m22:59:48.537763 [debug] [Thread-3 (]: Began running node model.elementary.schema_columns_snapshot
[0m22:59:48.538636 [info ] [Thread-3 (]: 17 of 32 START sql incremental model de_data_warehouse.schema_columns_snapshot . [RUN]
[0m22:59:48.539965 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.schema_columns_snapshot'
[0m22:59:48.540798 [debug] [Thread-3 (]: Began compiling node model.elementary.schema_columns_snapshot
[0m22:59:48.565008 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.schema_columns_snapshot"
[0m22:59:48.565722 [debug] [Thread-3 (]: Timing info for model.elementary.schema_columns_snapshot (compile): 2023-04-20 22:59:48.541609 => 2023-04-20 22:59:48.565645
[0m22:59:48.566064 [debug] [Thread-3 (]: Began executing node model.elementary.schema_columns_snapshot
[0m22:59:48.570612 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:59:49.231819 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.schema_columns_snapshot"
[0m22:59:49.233130 [debug] [Thread-3 (]: On model.elementary.schema_columns_snapshot: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.schema_columns_snapshot"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`schema_columns_snapshot` as DBT_INTERNAL_DEST
        using (


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as column_state_id

,
                
        cast('dummy_string' as string) as full_column_name

,
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as data_type

,
                
        cast (True as BOOL) as is_new

,
                cast('2091-02-17' as TIMESTAMP) as detected_at


            )
        select * from empty_table
        where 1 = 0

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.column_state_id = DBT_INTERNAL_DEST.column_state_id
            )

    
    when matched then update set
        `column_state_id` = DBT_INTERNAL_SOURCE.`column_state_id`,`full_column_name` = DBT_INTERNAL_SOURCE.`full_column_name`,`full_table_name` = DBT_INTERNAL_SOURCE.`full_table_name`,`column_name` = DBT_INTERNAL_SOURCE.`column_name`,`data_type` = DBT_INTERNAL_SOURCE.`data_type`,`is_new` = DBT_INTERNAL_SOURCE.`is_new`,`detected_at` = DBT_INTERNAL_SOURCE.`detected_at`
    

    when not matched then insert
        (`column_state_id`, `full_column_name`, `full_table_name`, `column_name`, `data_type`, `is_new`, `detected_at`)
    values
        (`column_state_id`, `full_column_name`, `full_table_name`, `column_name`, `data_type`, `is_new`, `detected_at`)


    
[0m22:59:49.686783 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:140d3515-0f97-4318-9c8c-f8d29d9f8a0d&page=queryresults
[0m22:59:49.691470 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_tests (execute): 2023-04-20 22:59:41.832251 => 2023-04-20 22:59:49.691372
[0m22:59:49.693772 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128db68d0>]}
[0m22:59:49.696833 [info ] [Thread-1 (]: 12 of 32 OK created sql incremental model de_data_warehouse.dbt_tests .......... [[32mMERGE (0.0 rows, 0 processed)[0m in 7.94s]
[0m22:59:49.697988 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_tests
[0m22:59:49.698929 [debug] [Thread-1 (]: Began running node model.de_project.land_and_property_transform
[0m22:59:49.701881 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:79dd3550-6b67-47e8-ac67-9a4bb8aa3d2d&page=queryresults
[0m22:59:49.702456 [info ] [Thread-1 (]: 18 of 32 START sql view model de_data_warehouse.land_and_property_transform .... [RUN]
[0m22:59:49.706300 [debug] [Thread-2 (]: Timing info for model.elementary.metadata (execute): 2023-04-20 22:59:46.990309 => 2023-04-20 22:59:49.706231
[0m22:59:49.707704 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.de_project.land_and_property_transform'
[0m22:59:49.711054 [debug] [Thread-1 (]: Began compiling node model.de_project.land_and_property_transform
[0m22:59:49.709312 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128db56d0>]}
[0m22:59:49.721507 [debug] [Thread-1 (]: Writing injected SQL for node "model.de_project.land_and_property_transform"
[0m22:59:49.722349 [info ] [Thread-2 (]: 16 of 32 OK created sql table model de_data_warehouse.metadata ................. [[32mCREATE TABLE (1.0 rows, 0 processed)[0m in 2.74s]
[0m22:59:49.723088 [debug] [Thread-2 (]: Finished running node model.elementary.metadata
[0m22:59:49.723944 [debug] [Thread-2 (]: Began running node model.elementary.job_run_results
[0m22:59:49.724865 [info ] [Thread-2 (]: 19 of 32 START sql view model de_data_warehouse.job_run_results ................ [RUN]
[0m22:59:49.726042 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.job_run_results'
[0m22:59:49.726545 [debug] [Thread-2 (]: Began compiling node model.elementary.job_run_results
[0m22:59:49.732702 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_transform (compile): 2023-04-20 22:59:49.711609 => 2023-04-20 22:59:49.732432
[0m22:59:49.740418 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.job_run_results"
[0m22:59:49.741254 [debug] [Thread-1 (]: Began executing node model.de_project.land_and_property_transform
[0m22:59:49.749156 [debug] [Thread-1 (]: Writing runtime sql for node "model.de_project.land_and_property_transform"
[0m22:59:49.750024 [debug] [Thread-2 (]: Timing info for model.elementary.job_run_results (compile): 2023-04-20 22:59:49.726946 => 2023-04-20 22:59:49.749895
[0m22:59:49.750568 [debug] [Thread-2 (]: Began executing node model.elementary.job_run_results
[0m22:59:49.754868 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.job_run_results"
[0m22:59:49.755584 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:49.760193 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:49.806768 [debug] [Thread-1 (]: On model.de_project.land_and_property_transform: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.land_and_property_transform"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`land_and_property_transform`
  OPTIONS()
  as with source AS (

    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`

),

renamed as (
    select
        `Account_Customer` AS customer,
        `FR`,
        `DFL`,
        `TP`,
        `DLG`,
        `OS_W_`,
        `OS_NPW_`,
        `OS_P_`,
        `OS_NPP_`,
        `SIMS`,
        `OC1`,
        `OC2`,
        `date_added`

    from source
)
select * from renamed;


[0m22:59:49.811000 [debug] [Thread-2 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.job_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`job_run_results`
  OPTIONS()
  as 





with jobs as (
  select
    job_name,
    job_id,
    job_run_id,
    
min(cast(run_started_at as TIMESTAMP))
 as job_run_started_at,
    
max(cast(run_completed_at as TIMESTAMP))
 as job_run_completed_at,
    
    timestamp_diff(
max(cast(run_completed_at as TIMESTAMP))
, 
min(cast(run_started_at as TIMESTAMP))
, second)
 as job_run_execution_time
  from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
  where job_id is not null
  group by job_name, job_id, job_run_id
)

select
  job_name as name,
  job_id as id,
  job_run_id as run_id,
  job_run_started_at as run_started_at,
  job_run_completed_at as run_completed_at,
  job_run_execution_time as run_execution_time
from jobs;


[0m22:59:49.988145 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e5db30d2-7cfe-45ad-9b06-d0daa7fd0e3f&page=queryresults
[0m22:59:49.991672 [debug] [Thread-4 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420225946130882`
    );
  
  
[0m22:59:50.777412 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ebe5683f-a463-49fe-bd18-15ca2583fef0&page=queryresults
[0m22:59:50.779440 [debug] [Thread-2 (]: Timing info for model.elementary.job_run_results (execute): 2023-04-20 22:59:49.750898 => 2023-04-20 22:59:50.779387
[0m22:59:50.780176 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129547510>]}
[0m22:59:50.780625 [info ] [Thread-2 (]: 19 of 32 OK created sql view model de_data_warehouse.job_run_results ........... [[32mCREATE VIEW (0 processed)[0m in 1.05s]
[0m22:59:50.781074 [debug] [Thread-2 (]: Finished running node model.elementary.job_run_results
[0m22:59:50.781660 [debug] [Thread-2 (]: Began running node model.elementary.metrics_anomaly_score
[0m22:59:50.782203 [info ] [Thread-2 (]: 20 of 32 START sql view model de_data_warehouse.metrics_anomaly_score .......... [RUN]
[0m22:59:50.783390 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.metrics_anomaly_score'
[0m22:59:50.784445 [debug] [Thread-2 (]: Began compiling node model.elementary.metrics_anomaly_score
[0m22:59:50.811961 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:67238d00-9e17-4415-ad9c-b068a9295c63&page=queryresults
[0m22:59:50.819871 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_transform (execute): 2023-04-20 22:59:49.742379 => 2023-04-20 22:59:50.819818
[0m22:59:50.830436 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.metrics_anomaly_score"
[0m22:59:50.831149 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x128db4790>]}
[0m22:59:50.832120 [info ] [Thread-1 (]: 18 of 32 OK created sql view model de_data_warehouse.land_and_property_transform  [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m22:59:50.832728 [debug] [Thread-1 (]: Finished running node model.de_project.land_and_property_transform
[0m22:59:50.833061 [debug] [Thread-2 (]: Timing info for model.elementary.metrics_anomaly_score (compile): 2023-04-20 22:59:50.784956 => 2023-04-20 22:59:50.832993
[0m22:59:50.833337 [debug] [Thread-1 (]: Began running node model.elementary.monitors_runs
[0m22:59:50.833739 [debug] [Thread-2 (]: Began executing node model.elementary.metrics_anomaly_score
[0m22:59:50.834126 [info ] [Thread-1 (]: 21 of 32 START sql view model de_data_warehouse.monitors_runs .................. [RUN]
[0m22:59:50.838087 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.monitors_runs'
[0m22:59:50.839450 [debug] [Thread-1 (]: Began compiling node model.elementary.monitors_runs
[0m22:59:50.855352 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.metrics_anomaly_score"
[0m22:59:50.856163 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.monitors_runs"
[0m22:59:50.862043 [debug] [Thread-1 (]: Timing info for model.elementary.monitors_runs (compile): 2023-04-20 22:59:50.846301 => 2023-04-20 22:59:50.861941
[0m22:59:50.862453 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:50.862757 [debug] [Thread-1 (]: Began executing node model.elementary.monitors_runs
[0m22:59:50.867754 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.monitors_runs"
[0m22:59:50.868696 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:50.919922 [debug] [Thread-2 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.metrics_anomaly_score"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`
  OPTIONS()
  as 

with data_monitoring_metrics as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`

),

time_window_aggregation as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        metric_value,
        source_value,
        bucket_start,
        bucket_end,
        bucket_duration_hours,
        updated_at,
        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,
        stddev(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,
        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,
        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,
        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start
    from data_monitoring_metrics
    group by 1,2,3,4,5,6,7,8,9,10,11,12
),

metrics_anomaly_score as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        case
            when training_stddev is null then null
            when training_stddev = 0 then 0
            else (metric_value - training_avg) / (training_stddev)
        end as anomaly_score,
        metric_value as latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        max(updated_at) as updated_at
    from time_window_aggregation
        where
            metric_value is not null
            and training_avg is not null
            and training_set_size >= 14
            and bucket_end >= 
       timestamp_add(cast(
    timestamp_trunc(cast(current_timestamp as timestamp), day)
 as TIMESTAMP), INTERVAL cast(-7 as INT64) day)

    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    order by bucket_end desc


),

final as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        anomaly_score,
        latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        updated_at,
        case
            when abs(anomaly_score) > 3 then true
            else false end
        as is_anomaly
    from metrics_anomaly_score
)

select * from final;


[0m22:59:50.920905 [debug] [Thread-1 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.monitors_runs"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`monitors_runs`
  OPTIONS()
  as 

with data_monitoring_metrics as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`

),

max_bucket_end as (

    select full_table_name,
           column_name,
           metric_name,
           metric_properties,
           max(bucket_end) as last_bucket_end,
           min(bucket_end) as first_bucket_end
    from data_monitoring_metrics
    group by 1,2,3,4

)

select * from max_bucket_end;


[0m22:59:51.035311 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c4fc4136-c8c8-495a-b16d-92e745aaef58&page=queryresults
[0m22:59:51.038021 [debug] [Thread-3 (]: Timing info for model.elementary.schema_columns_snapshot (execute): 2023-04-20 22:59:48.566251 => 2023-04-20 22:59:51.037922
[0m22:59:51.039004 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129227510>]}
[0m22:59:51.039486 [info ] [Thread-3 (]: 17 of 32 OK created sql incremental model de_data_warehouse.schema_columns_snapshot  [[32mMERGE (0.0 rows, 0 processed)[0m in 2.50s]
[0m22:59:51.039966 [debug] [Thread-3 (]: Finished running node model.elementary.schema_columns_snapshot
[0m22:59:51.040511 [debug] [Thread-3 (]: Began running node model.elementary.model_run_results
[0m22:59:51.041030 [info ] [Thread-3 (]: 22 of 32 START sql view model de_data_warehouse.model_run_results .............. [RUN]
[0m22:59:51.044449 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.model_run_results'
[0m22:59:51.045084 [debug] [Thread-3 (]: Began compiling node model.elementary.model_run_results
[0m22:59:51.060778 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.model_run_results"
[0m22:59:51.062289 [debug] [Thread-3 (]: Timing info for model.elementary.model_run_results (compile): 2023-04-20 22:59:51.045458 => 2023-04-20 22:59:51.062151
[0m22:59:51.062871 [debug] [Thread-3 (]: Began executing node model.elementary.model_run_results
[0m22:59:51.073648 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.model_run_results"
[0m22:59:51.076644 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:59:51.138314 [debug] [Thread-3 (]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.model_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`model_run_results`
  OPTIONS()
  as 

with dbt_run_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
),

dbt_models as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.thread_id,
    models.database_name,
    models.schema_name,
    models.materialization,
    models.tags,
    models.package_name,
    models.path,
    models.original_path,
    models.owner,
    models.alias,
    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,
    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY 
    timestamp_trunc(cast(run_results.generated_at as timestamp), day)
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_first_invocation_of_the_day,
    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY 
    timestamp_trunc(cast(run_results.generated_at as timestamp), day)
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_last_invocation_of_the_day
    
FROM dbt_run_results run_results
JOIN dbt_models models ON run_results.unique_id = models.unique_id;


[0m22:59:51.746871 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:662c66fe-c2d5-436a-bfe8-61f0fab91639&page=queryresults
[0m22:59:51.748884 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_sources (execute): 2023-04-20 22:59:41.343800 => 2023-04-20 22:59:51.748828
[0m22:59:51.749544 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129273510>]}
[0m22:59:51.750127 [info ] [Thread-4 (]: 11 of 32 OK created sql incremental model de_data_warehouse.dbt_sources ........ [[32mMERGE (0.0 rows, 412.0 Bytes processed)[0m in 10.44s]
[0m22:59:51.751024 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_sources
[0m22:59:51.751670 [debug] [Thread-4 (]: Began running node model.elementary.snapshot_run_results
[0m22:59:51.752328 [info ] [Thread-4 (]: 23 of 32 START sql view model de_data_warehouse.snapshot_run_results ........... [RUN]
[0m22:59:51.753113 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.snapshot_run_results'
[0m22:59:51.753492 [debug] [Thread-4 (]: Began compiling node model.elementary.snapshot_run_results
[0m22:59:51.762323 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.snapshot_run_results"
[0m22:59:51.764452 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8e1f5974-c37c-4d0e-9f7c-7dc82bf4dc75&page=queryresults
[0m22:59:51.764723 [debug] [Thread-4 (]: Timing info for model.elementary.snapshot_run_results (compile): 2023-04-20 22:59:51.753709 => 2023-04-20 22:59:51.764650
[0m22:59:51.767070 [debug] [Thread-1 (]: Timing info for model.elementary.monitors_runs (execute): 2023-04-20 22:59:50.863193 => 2023-04-20 22:59:51.766996
[0m22:59:51.767820 [debug] [Thread-4 (]: Began executing node model.elementary.snapshot_run_results
[0m22:59:51.769015 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1294f8cd0>]}
[0m22:59:51.778813 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.snapshot_run_results"
[0m22:59:51.780401 [info ] [Thread-1 (]: 21 of 32 OK created sql view model de_data_warehouse.monitors_runs ............. [[32mCREATE VIEW (0 processed)[0m in 0.93s]
[0m22:59:51.781837 [debug] [Thread-1 (]: Finished running node model.elementary.monitors_runs
[0m22:59:51.782364 [debug] [Thread-1 (]: Began running node model.elementary.alerts_anomaly_detection
[0m22:59:51.782752 [info ] [Thread-1 (]: 24 of 32 START sql view model de_data_warehouse.alerts_anomaly_detection ....... [RUN]
[0m22:59:51.783421 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.alerts_anomaly_detection'
[0m22:59:51.783884 [debug] [Thread-1 (]: Began compiling node model.elementary.alerts_anomaly_detection
[0m22:59:51.870686 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:59:51.874165 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b380079b-dd9e-4c65-91f8-413f858e8066&page=queryresults
[0m22:59:51.883131 [debug] [Thread-2 (]: Timing info for model.elementary.metrics_anomaly_score (execute): 2023-04-20 22:59:50.834535 => 2023-04-20 22:59:51.883081
[0m22:59:51.884116 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x12912d390>]}
[0m22:59:51.885912 [info ] [Thread-2 (]: 20 of 32 OK created sql view model de_data_warehouse.metrics_anomaly_score ..... [[32mCREATE VIEW (0 processed)[0m in 1.10s]
[0m22:59:51.888112 [debug] [Thread-2 (]: Finished running node model.elementary.metrics_anomaly_score
[0m22:59:51.888792 [debug] [Thread-2 (]: Began running node model.elementary.alerts_dbt_tests
[0m22:59:51.897185 [info ] [Thread-2 (]: 25 of 32 START sql view model de_data_warehouse.alerts_dbt_tests ............... [RUN]
[0m22:59:51.898411 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_tests'
[0m22:59:51.901861 [debug] [Thread-2 (]: Began compiling node model.elementary.alerts_dbt_tests
[0m22:59:51.913541 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.alerts_dbt_tests"
[0m22:59:51.921580 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_dbt_tests (compile): 2023-04-20 22:59:51.902357 => 2023-04-20 22:59:51.921499
[0m22:59:51.922002 [debug] [Thread-2 (]: Began executing node model.elementary.alerts_dbt_tests
[0m22:59:51.928414 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.alerts_dbt_tests"
[0m22:59:51.933885 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:51.939331 [debug] [Thread-4 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.snapshot_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`
  OPTIONS()
  as 

with dbt_run_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
),

dbt_snapshots as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.thread_id,
    snapshots.database_name,
    snapshots.schema_name,
    snapshots.materialization,
    snapshots.tags,
    snapshots.package_name,
    snapshots.path,
    snapshots.original_path,
    snapshots.owner,
    snapshots.alias
FROM dbt_run_results run_results
JOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id;


[0m22:59:52.012463 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.alerts_anomaly_detection"
[0m22:59:52.013808 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_tests"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_tests`
  OPTIONS()
  as 

with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_dbt_tests as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'dbt_test'
)

select * from alerts_dbt_tests;


[0m22:59:52.015521 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_anomaly_detection (compile): 2023-04-20 22:59:51.784231 => 2023-04-20 22:59:52.015404
[0m22:59:52.016551 [debug] [Thread-1 (]: Began executing node model.elementary.alerts_anomaly_detection
[0m22:59:52.021903 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.alerts_anomaly_detection"
[0m22:59:52.023182 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:52.071219 [debug] [Thread-1 (]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_anomaly_detection"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_anomaly_detection`
  OPTIONS()
  as 

with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_anomaly_detection as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'anomaly_detection'
)

select * from alerts_anomaly_detection;


[0m22:59:52.299176 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e05f4c93-51e1-49f5-85f7-a1bb7c68c676&page=queryresults
[0m22:59:52.301911 [debug] [Thread-3 (]: Timing info for model.elementary.model_run_results (execute): 2023-04-20 22:59:51.063330 => 2023-04-20 22:59:52.301838
[0m22:59:52.302608 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1295be2d0>]}
[0m22:59:52.303006 [info ] [Thread-3 (]: 22 of 32 OK created sql view model de_data_warehouse.model_run_results ......... [[32mCREATE VIEW (0 processed)[0m in 1.26s]
[0m22:59:52.303354 [debug] [Thread-3 (]: Finished running node model.elementary.model_run_results
[0m22:59:52.303939 [debug] [Thread-3 (]: Began running node model.elementary.alerts_schema_changes
[0m22:59:52.304389 [info ] [Thread-3 (]: 26 of 32 START sql view model de_data_warehouse.alerts_schema_changes .......... [RUN]
[0m22:59:52.305131 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.alerts_schema_changes'
[0m22:59:52.305508 [debug] [Thread-3 (]: Began compiling node model.elementary.alerts_schema_changes
[0m22:59:52.317999 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.alerts_schema_changes"
[0m22:59:52.319448 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_schema_changes (compile): 2023-04-20 22:59:52.305711 => 2023-04-20 22:59:52.319273
[0m22:59:52.319868 [debug] [Thread-3 (]: Began executing node model.elementary.alerts_schema_changes
[0m22:59:52.326924 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.alerts_schema_changes"
[0m22:59:52.328340 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:59:52.379666 [debug] [Thread-3 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_schema_changes"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_schema_changes`
  OPTIONS()
  as 


with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_schema_changes as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'schema_change'
)

select * from alerts_schema_changes;


[0m22:59:52.828840 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:dea6db39-ee46-49c7-acac-f2c2b32094fc&page=queryresults
[0m22:59:52.833081 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_dbt_tests (execute): 2023-04-20 22:59:51.922471 => 2023-04-20 22:59:52.832999
[0m22:59:52.835028 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129457b50>]}
[0m22:59:52.835755 [info ] [Thread-2 (]: 25 of 32 OK created sql view model de_data_warehouse.alerts_dbt_tests .......... [[32mCREATE VIEW (0 processed)[0m in 0.94s]
[0m22:59:52.836317 [debug] [Thread-2 (]: Finished running node model.elementary.alerts_dbt_tests
[0m22:59:52.836782 [debug] [Thread-2 (]: Began running node model.elementary.test_result_rows
[0m22:59:52.837397 [info ] [Thread-2 (]: 27 of 32 START sql incremental model de_data_warehouse.test_result_rows ........ [RUN]
[0m22:59:52.838412 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.test_result_rows'
[0m22:59:52.838888 [debug] [Thread-2 (]: Began compiling node model.elementary.test_result_rows
[0m22:59:52.854713 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.test_result_rows"
[0m22:59:52.855575 [debug] [Thread-2 (]: Timing info for model.elementary.test_result_rows (compile): 2023-04-20 22:59:52.839196 => 2023-04-20 22:59:52.855488
[0m22:59:52.855938 [debug] [Thread-2 (]: Began executing node model.elementary.test_result_rows
[0m22:59:52.869927 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m22:59:52.918433 [debug] [Thread-2 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.test_result_rows"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`test_result_rows__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

-- depends_on: `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as elementary_test_results_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as result_row

,
                cast('2091-02-17' as TIMESTAMP) as detected_at


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m22:59:53.133294 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:dcdafb52-2212-4e5e-87c6-7a2923540806&page=queryresults
[0m22:59:53.135738 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_anomaly_detection (execute): 2023-04-20 22:59:52.016951 => 2023-04-20 22:59:53.135686
[0m22:59:53.136397 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129654250>]}
[0m22:59:53.136816 [info ] [Thread-1 (]: 24 of 32 OK created sql view model de_data_warehouse.alerts_anomaly_detection .. [[32mCREATE VIEW (0 processed)[0m in 1.35s]
[0m22:59:53.137322 [debug] [Thread-1 (]: Finished running node model.elementary.alerts_anomaly_detection
[0m22:59:53.137731 [debug] [Thread-1 (]: Began running node model.de_project.final_land_and_property
[0m22:59:53.138172 [info ] [Thread-1 (]: 28 of 32 START sql view model de_data_warehouse.final_land_and_property ........ [RUN]
[0m22:59:53.138897 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.de_project.final_land_and_property'
[0m22:59:53.139219 [debug] [Thread-1 (]: Began compiling node model.de_project.final_land_and_property
[0m22:59:53.143572 [debug] [Thread-1 (]: Writing injected SQL for node "model.de_project.final_land_and_property"
[0m22:59:53.144284 [debug] [Thread-1 (]: Timing info for model.de_project.final_land_and_property (compile): 2023-04-20 22:59:53.139451 => 2023-04-20 22:59:53.144216
[0m22:59:53.144553 [debug] [Thread-1 (]: Began executing node model.de_project.final_land_and_property
[0m22:59:53.149546 [debug] [Thread-1 (]: Writing runtime sql for node "model.de_project.final_land_and_property"
[0m22:59:53.153035 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:53.203849 [debug] [Thread-1 (]: On model.de_project.final_land_and_property: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.final_land_and_property"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`final_land_and_property`
  OPTIONS()
  as with source as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_transform`

)
SELECT
*
FROM source;


[0m22:59:53.268719 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:a7e453b5-a750-47de-a370-828e716cca56&page=queryresults
[0m22:59:53.272923 [debug] [Thread-4 (]: Timing info for model.elementary.snapshot_run_results (execute): 2023-04-20 22:59:51.769303 => 2023-04-20 22:59:53.272769
[0m22:59:53.275364 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1295ad1d0>]}
[0m22:59:53.770738 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c68b916b-1e49-45dd-9cc2-cfbe3ce5fb5d&page=queryresults
[0m22:59:53.775560 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_schema_changes (execute): 2023-04-20 22:59:52.320820 => 2023-04-20 22:59:53.775489
[0m22:59:53.776502 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1294f3590>]}
[0m22:59:54.839920 [info ] [Thread-4 (]: 23 of 32 OK created sql view model de_data_warehouse.snapshot_run_results ...... [[32mCREATE VIEW (0 processed)[0m in 1.52s]
[0m22:59:54.840838 [info ] [Thread-3 (]: 26 of 32 OK created sql view model de_data_warehouse.alerts_schema_changes ..... [[32mCREATE VIEW (0 processed)[0m in 1.47s]
[0m22:59:54.843175 [debug] [Thread-4 (]: Finished running node model.elementary.snapshot_run_results
[0m22:59:54.844763 [debug] [Thread-3 (]: Finished running node model.elementary.alerts_schema_changes
[0m22:59:54.846115 [debug] [Thread-4 (]: Began running node model.elementary.alerts_dbt_source_freshness
[0m22:59:54.848110 [debug] [Thread-3 (]: Began running node model.elementary.dbt_artifacts_hashes
[0m22:59:54.849102 [info ] [Thread-4 (]: 29 of 32 START sql view model de_data_warehouse.alerts_dbt_source_freshness .... [RUN]
[0m22:59:54.850098 [info ] [Thread-3 (]: 30 of 32 START sql view model de_data_warehouse.dbt_artifacts_hashes ........... [RUN]
[0m22:59:54.851471 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_source_freshness'
[0m22:59:54.852719 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_artifacts_hashes'
[0m22:59:54.853277 [debug] [Thread-4 (]: Began compiling node model.elementary.alerts_dbt_source_freshness
[0m22:59:54.853897 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_artifacts_hashes
[0m22:59:54.864460 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.alerts_dbt_source_freshness"
[0m22:59:54.869900 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_artifacts_hashes"
[0m22:59:54.871410 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_artifacts_hashes (compile): 2023-04-20 22:59:54.864795 => 2023-04-20 22:59:54.871268
[0m22:59:54.872349 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_artifacts_hashes
[0m22:59:54.872690 [debug] [Thread-4 (]: Timing info for model.elementary.alerts_dbt_source_freshness (compile): 2023-04-20 22:59:54.854503 => 2023-04-20 22:59:54.872602
[0m22:59:54.879231 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_artifacts_hashes"
[0m22:59:54.881169 [debug] [Thread-4 (]: Began executing node model.elementary.alerts_dbt_source_freshness
[0m22:59:54.891475 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.alerts_dbt_source_freshness"
[0m22:59:54.891955 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:59:54.893620 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m22:59:54.943329 [debug] [Thread-3 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_artifacts_hashes"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`dbt_artifacts_hashes`
  OPTIONS()
  as 




select
  'dbt_models' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
 union all 

select
  'dbt_tests' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
 union all 

select
  'dbt_sources' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
 union all 

select
  'dbt_snapshots' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
 union all 

select
  'dbt_metrics' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
 union all 

select
  'dbt_exposures' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
 union all 

select
  'dbt_seeds' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`


order by metadata_hash;


[0m22:59:54.943763 [debug] [Thread-4 (]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_source_freshness"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_source_freshness`
  OPTIONS()
  as 

with results as (
  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`
),

sources as (
  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
)

select
  results.source_freshness_execution_id as alert_id,
  results.max_loaded_at,
  results.snapshotted_at,
  results.generated_at as detected_at,
  results.max_loaded_at_time_ago_in_s,
  results.status,
  results.error,
  sources.unique_id,
  sources.database_name,
  sources.schema_name,
  sources.source_name,
  sources.identifier,
  sources.freshness_error_after,
  sources.freshness_warn_after,
  sources.freshness_filter,
  sources.tags,
  sources.meta,
  sources.owner,
  sources.package_name,
  sources.path
from results
join sources on results.unique_id = sources.unique_id
where True and lower(status) != 'pass';


[0m22:59:54.985543 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:3385a3a6-22bd-4b76-ac9e-6d411c8f83e0&page=queryresults
[0m22:59:54.987337 [debug] [Thread-1 (]: Timing info for model.de_project.final_land_and_property (execute): 2023-04-20 22:59:53.144713 => 2023-04-20 22:59:54.987287
[0m22:59:54.987965 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1293ae510>]}
[0m22:59:54.988351 [info ] [Thread-1 (]: 28 of 32 OK created sql view model de_data_warehouse.final_land_and_property ... [[32mCREATE VIEW (0 processed)[0m in 1.85s]
[0m22:59:54.988692 [debug] [Thread-1 (]: Finished running node model.de_project.final_land_and_property
[0m22:59:54.989137 [debug] [Thread-1 (]: Began running node model.elementary.anomaly_threshold_sensitivity
[0m22:59:54.989818 [info ] [Thread-1 (]: 31 of 32 START sql view model de_data_warehouse.anomaly_threshold_sensitivity .. [RUN]
[0m22:59:54.990772 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.anomaly_threshold_sensitivity'
[0m22:59:54.991305 [debug] [Thread-1 (]: Began compiling node model.elementary.anomaly_threshold_sensitivity
[0m22:59:55.003012 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.anomaly_threshold_sensitivity"
[0m22:59:55.008801 [debug] [Thread-1 (]: Timing info for model.elementary.anomaly_threshold_sensitivity (compile): 2023-04-20 22:59:54.991563 => 2023-04-20 22:59:55.008588
[0m22:59:55.009476 [debug] [Thread-1 (]: Began executing node model.elementary.anomaly_threshold_sensitivity
[0m22:59:55.016379 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.anomaly_threshold_sensitivity"
[0m22:59:55.018032 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m22:59:55.064785 [debug] [Thread-1 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`anomaly_threshold_sensitivity`
  OPTIONS()
  as 

with metrics_anomaly_score as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`

),

score_sensitivity as (

    select
        full_table_name,
        column_name,
        metric_name,
        latest_metric_value,
        training_avg as metric_avg,
        training_stddev as metric_stddev,
        anomaly_score,
        case when abs(anomaly_score) >= 1.5 then true else false end as `is_anomaly_1_5`,
        case when abs(anomaly_score) >= 2 then true else false end as `is_anomaly_2`,
        case when abs(anomaly_score) >= 2.5 then true else false end as `is_anomaly_2_5`,
        case when abs(anomaly_score) >= 3 then true else false end as `is_anomaly_3`,
        case when abs(anomaly_score) >= 3.5 then true else false end as `is_anomaly_3_5`,
        case when abs(anomaly_score) >= 4 then true else false end as `is_anomaly_4`,
        case when abs(anomaly_score) >= 4.5 then true else false end as `is_anomaly_4_5`
    from metrics_anomaly_score
    where abs(anomaly_score) >= 1.5

)

select * from score_sensitivity;


[0m22:59:55.225742 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:0a55d785-543c-41f0-b230-575e27f47821&page=queryresults
[0m22:59:55.490525 [debug] [Thread-2 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`test_result_rows`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m22:59:55.495358 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.test_result_rows"
[0m22:59:55.497423 [debug] [Thread-2 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.test_result_rows"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`test_result_rows` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`test_result_rows__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.elementary_test_results_id = DBT_INTERNAL_DEST.elementary_test_results_id
            )

    
    when matched then update set
        `elementary_test_results_id` = DBT_INTERNAL_SOURCE.`elementary_test_results_id`,`result_row` = DBT_INTERNAL_SOURCE.`result_row`,`detected_at` = DBT_INTERNAL_SOURCE.`detected_at`
    

    when not matched then insert
        (`elementary_test_results_id`, `result_row`, `detected_at`)
    values
        (`elementary_test_results_id`, `result_row`, `detected_at`)


    
[0m22:59:55.967562 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:60c34e80-679f-491f-ae80-3119b82d256a&page=queryresults
[0m22:59:55.971074 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_artifacts_hashes (execute): 2023-04-20 22:59:54.872964 => 2023-04-20 22:59:55.970994
[0m22:59:55.971995 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129539350>]}
[0m22:59:55.972585 [info ] [Thread-3 (]: 30 of 32 OK created sql view model de_data_warehouse.dbt_artifacts_hashes ...... [[32mCREATE VIEW (0 processed)[0m in 1.12s]
[0m22:59:55.973411 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_artifacts_hashes
[0m22:59:55.974007 [debug] [Thread-3 (]: Began running node model.elementary.alerts_dbt_models
[0m22:59:55.974801 [info ] [Thread-3 (]: 32 of 32 START sql view model de_data_warehouse.alerts_dbt_models .............. [RUN]
[0m22:59:55.975982 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_models'
[0m22:59:55.976411 [debug] [Thread-3 (]: Began compiling node model.elementary.alerts_dbt_models
[0m22:59:55.989013 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.alerts_dbt_models"
[0m22:59:55.990316 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_dbt_models (compile): 2023-04-20 22:59:55.976712 => 2023-04-20 22:59:55.990137
[0m22:59:55.991283 [debug] [Thread-3 (]: Began executing node model.elementary.alerts_dbt_models
[0m22:59:55.997544 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.alerts_dbt_models"
[0m22:59:55.999128 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m22:59:56.015514 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:d403ad66-e893-4fe5-9ee0-ee715ccb1182&page=queryresults
[0m22:59:56.017704 [debug] [Thread-4 (]: Timing info for model.elementary.alerts_dbt_source_freshness (execute): 2023-04-20 22:59:54.881822 => 2023-04-20 22:59:56.017648
[0m22:59:56.018955 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129652710>]}
[0m22:59:56.019794 [info ] [Thread-4 (]: 29 of 32 OK created sql view model de_data_warehouse.alerts_dbt_source_freshness  [[32mCREATE VIEW (0 processed)[0m in 1.17s]
[0m22:59:56.020668 [debug] [Thread-4 (]: Finished running node model.elementary.alerts_dbt_source_freshness
[0m22:59:56.065165 [debug] [Thread-3 (]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_models"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_models`
  OPTIONS()
  as 

with error_models as (
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias 
    from `dtc-de-383113`.`de_data_warehouse`.`model_run_results`
  
    union all
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias  
  from `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`
)


select model_execution_id as alert_id,
       unique_id,
       generated_at as detected_at,
       database_name,
       materialization,
       path,
       original_path,
       schema_name,
       message,
       owner as owners,
       tags,
       alias,
       status,
       full_refresh
from error_models
where True and lower(status) != 'success'and lower(status) != 'skipped';


[0m22:59:56.142886 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:51872008-eb39-4cd4-ba26-5bf6f9198996&page=queryresults
[0m22:59:56.145487 [debug] [Thread-1 (]: Timing info for model.elementary.anomaly_threshold_sensitivity (execute): 2023-04-20 22:59:55.010112 => 2023-04-20 22:59:56.145255
[0m22:59:56.147007 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129436190>]}
[0m22:59:56.147837 [info ] [Thread-1 (]: 31 of 32 OK created sql view model de_data_warehouse.anomaly_threshold_sensitivity  [[32mCREATE VIEW (0 processed)[0m in 1.16s]
[0m22:59:56.148390 [debug] [Thread-1 (]: Finished running node model.elementary.anomaly_threshold_sensitivity
[0m22:59:57.043670 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ed6771ce-337c-4ee5-9d30-b5492f939629&page=queryresults
[0m22:59:57.046607 [debug] [Thread-3 (]: Timing info for model.elementary.alerts_dbt_models (execute): 2023-04-20 22:59:55.991831 => 2023-04-20 22:59:57.046552
[0m22:59:57.047349 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x129650510>]}
[0m22:59:57.047825 [info ] [Thread-3 (]: 32 of 32 OK created sql view model de_data_warehouse.alerts_dbt_models ......... [[32mCREATE VIEW (0 processed)[0m in 1.07s]
[0m22:59:57.048245 [debug] [Thread-3 (]: Finished running node model.elementary.alerts_dbt_models
[0m22:59:57.324712 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b019e094-5e0f-444e-a4f9-6e28051f83bf&page=queryresults
[0m22:59:57.344768 [debug] [Thread-2 (]: Timing info for model.elementary.test_result_rows (execute): 2023-04-20 22:59:52.856129 => 2023-04-20 22:59:57.344710
[0m22:59:57.345552 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '9f3fc660-72f8-4b44-97ce-7042bae015c7', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1294d6390>]}
[0m22:59:57.346275 [info ] [Thread-2 (]: 27 of 32 OK created sql incremental model de_data_warehouse.test_result_rows ... [[32mMERGE (0.0 rows, 0 processed)[0m in 4.51s]
[0m22:59:57.347032 [debug] [Thread-2 (]: Finished running node model.elementary.test_result_rows
[0m22:59:57.351361 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m22:59:57.351907 [info ] [MainThread]: 
[0m22:59:57.352499 [info ] [MainThread]: Running 1 on-run-end hook
[0m22:59:57.394897 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m22:59:57.446352 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from `dtc-de-383113`.`de_data_warehouse`.`dbt_artifacts_hashes`
    order by metadata_hash
    
  
[0m22:59:59.035494 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8a811231-c04e-44d2-afd9-519fbbaf3a2f&page=queryresults
[0m22:59:59.037977 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m22:59:59.047105 [debug] [MainThread]: Elementary: [dbt_models] Artifacts already ran.
[0m22:59:59.049741 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts already ran.
[0m22:59:59.052081 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts already ran.
[0m22:59:59.054661 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts already ran.
[0m22:59:59.056759 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts already ran.
[0m22:59:59.058547 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts already ran.
[0m22:59:59.060655 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts already ran.
[0m22:59:59.067281 [debug] [MainThread]: Elementary: Uploading run results.
[0m22:59:59.068688 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m22:59:59.199101 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 32 artifacts.
[0m22:59:59.423263 [debug] [MainThread]: Elementary: Inserting 32 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
[0m22:59:59.864242 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m22:59:59.865739 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
         (model_execution_id,unique_id,invocation_id,generated_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id) values
    ('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.de_project.land_and_property_optimized_raw','model.de_project.land_and_property_optimized_raw','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','land_and_property_optimized_raw','CREATE VIEW (0 processed)','success','model',2.310472011566162,'2023-04-20T22:59:26.013985Z','2023-04-20T22:59:28.110339Z','2023-04-20T22:59:25.807284Z','2023-04-20T22:59:25.944314Z',NULL,False,'with source as (\n      select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized`\n)\nselect * from source',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_invocations','model.elementary.dbt_invocations','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_invocations','MERGE (0.0 rows, 208.0 Bytes processed)','success','model',4.903811693191528,'2023-04-20T22:59:26.243706Z','2023-04-20T22:59:30.706260Z','2023-04-20T22:59:25.867541Z','2023-04-20T22:59:26.103409Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as invocation_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_run_id\n\n,\n                \n        cast(\'dummy_string\' as string) as run_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as run_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as command\n\n,\n                \n        cast(\'dummy_string\' as string) as dbt_version\n\n,\n                \n        cast(\'dummy_string\' as string) as elementary_version\n\n,\n                \n        cast (True as BOOL) as full_refresh\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as invocation_vars\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as vars\n\n,\n                \n        cast(\'dummy_string\' as string) as target_name\n\n,\n                \n        cast(\'dummy_string\' as string) as target_database\n\n,\n                \n        cast(\'dummy_string\' as string) as target_schema\n\n,\n                \n        cast(\'dummy_string\' as string) as target_profile_name\n\n,\n                \n        cast(123456789 as INT64) as threads\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as selected\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as yaml_selector\n\n,\n                \n        cast(\'dummy_string\' as string) as project_id\n\n,\n                \n        cast(\'dummy_string\' as string) as project_name\n\n,\n                \n        cast(\'dummy_string\' as string) as env\n\n,\n                \n        cast(\'dummy_string\' as string) as env_id\n\n,\n                \n        cast(\'dummy_string\' as string) as cause_category\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as cause\n\n,\n                \n        cast(\'dummy_string\' as string) as pull_request_id\n\n,\n                \n        cast(\'dummy_string\' as string) as git_sha\n\n,\n                \n        cast(\'dummy_string\' as string) as orchestrator\n\n,\n                \n        cast(\'dummy_string\' as string) as dbt_user\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.data_monitoring_metrics','model.elementary.data_monitoring_metrics','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','data_monitoring_metrics','MERGE (0.0 rows, 0 processed)','success','model',5.089501857757568,'2023-04-20T22:59:26.170407Z','2023-04-20T22:59:30.890971Z','2023-04-20T22:59:25.811767Z','2023-04-20T22:59:26.102865Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as id\n\n,\n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as metric_name\n\n,\n                \n        cast(123456789.99 as FLOAT64) as metric_value\n\n,\n                \n        cast(\'dummy_string\' as string) as source_value\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as bucket_start\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as bucket_end\n\n,\n                \n        cast(123456789 as INT64) as bucket_duration_hours\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as updated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as dimension\n\n,\n                \n        cast(\'dummy_string\' as string) as dimension_value\n\n,\n                \n        cast(\'dummy_string\' as string) as metric_properties\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_exposures','model.elementary.dbt_exposures','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_exposures','MERGE (0.0 rows, 0 processed)','success','model',8.684144735336304,'2023-04-20T22:59:26.074695Z','2023-04-20T22:59:34.485954Z','2023-04-20T22:59:25.845821Z','2023-04-20T22:59:26.007031Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as maturity\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'dummy_string\' as string) as owner_email\n\n,\n                \n        cast(\'dummy_string\' as string) as owner_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as url\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_run_results','model.elementary.dbt_run_results','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_run_results','MERGE (0.0 rows, 48.6 KB processed)','success','model',4.669889688491821,'2023-04-20T22:59:30.942067Z','2023-04-20T22:59:35.564055Z','2023-04-20T22:59:30.896801Z','2023-04-20T22:59:30.941016Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_execution_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as message\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(\'dummy_string\' as string) as resource_type\n\n,\n                \n        cast(123456789.99 as FLOAT64) as execution_time\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_completed_at\n\n,\n                \n        cast(31474836478 as bigint) as rows_affected\n\n,\n                \n        cast (True as BOOL) as full_refresh\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as compiled_code\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast(\'dummy_string\' as string) as query_id\n\n,\n                \n        cast(\'dummy_string\' as string) as thread_id\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_metrics','model.elementary.dbt_metrics','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_metrics','MERGE (0.0 rows, 0 processed)','success','model',8.906903743743896,'2023-04-20T22:59:28.162445Z','2023-04-20T22:59:37.024328Z','2023-04-20T22:59:28.119355Z','2023-04-20T22:59:28.160819Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as label\n\n,\n                \n        cast(\'dummy_string\' as string) as model\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as sql\n\n,\n                \n        cast(\'dummy_string\' as string) as timestamp\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as filters\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as time_grains\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as dimensions\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_models','model.elementary.dbt_models','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_models','MERGE (0.0 rows, 20.7 KB processed)','success','model',10.591103076934814,'2023-04-20T22:59:30.754901Z','2023-04-20T22:59:41.301286Z','2023-04-20T22:59:30.712365Z','2023-04-20T22:59:30.753867Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'dummy_string\' as string) as materialization\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_source_freshness_results','model.elementary.dbt_source_freshness_results','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_source_freshness_results','MERGE (0.0 rows, 0 processed)','success','model',4.7178990840911865,'2023-04-20T22:59:37.051317Z','2023-04-20T22:59:41.746965Z','2023-04-20T22:59:37.031014Z','2023-04-20T22:59:37.050707Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as source_freshness_execution_id\n\n,\n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as max_loaded_at\n\n,\n                \n        cast(\'dummy_string\' as string) as snapshotted_at\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(123456789.99 as FLOAT64) as max_loaded_at_time_ago_in_s\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(\'dummy_string\' as string) as error\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_seeds','model.elementary.dbt_seeds','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_seeds','MERGE (0.0 rows, 0 processed)','success','model',8.681229829788208,'2023-04-20T22:59:34.517736Z','2023-04-20T22:59:43.170321Z','2023-04-20T22:59:34.491022Z','2023-04-20T22:59:34.517240Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_snapshots','model.elementary.dbt_snapshots','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_snapshots','MERGE (0.0 rows, 0 processed)','success','model',8.281895875930786,'2023-04-20T22:59:35.597172Z','2023-04-20T22:59:43.849039Z','2023-04-20T22:59:35.569683Z','2023-04-20T22:59:35.596442Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'dummy_string\' as string) as materialization\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.filtered_information_schema_columns','model.elementary.filtered_information_schema_columns','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','filtered_information_schema_columns','CREATE VIEW (0 processed)','success','model',1.156484842300415,'2023-04-20T22:59:43.881720Z','2023-04-20T22:59:45.009898Z','2023-04-20T22:59:43.855754Z','2023-04-20T22:59:43.880631Z',NULL,False,'\n\n\n\nwith filtered_information_schema_columns as (\n        with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as data_type\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n\n)\n\nselect *\nfrom filtered_information_schema_columns\nwhere full_table_name is not null',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.filtered_information_schema_tables','model.elementary.filtered_information_schema_tables','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','filtered_information_schema_tables','CREATE VIEW (0 processed)','success','model',1.9534940719604492,'2023-04-20T22:59:45.031989Z','2023-04-20T22:59:46.966750Z','2023-04-20T22:59:45.015146Z','2023-04-20T22:59:45.028333Z',NULL,False,'\n\n\n\nwith filtered_information_schema_tables as (\n        with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as full_schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n\n)\n\nselect *\nfrom filtered_information_schema_tables\nwhere schema_name is not null',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.elementary_test_results','model.elementary.elementary_test_results','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','elementary_test_results','MERGE (0.0 rows, 0 processed)','success','model',5.360974073410034,'2023-04-20T22:59:43.215143Z','2023-04-20T22:59:48.534880Z','2023-04-20T22:59:43.175981Z','2023-04-20T22:59:43.213926Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as id\n\n,\n                \n        cast(\'dummy_string\' as string) as data_issue_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_execution_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_unique_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as test_type\n\n,\n                \n        cast(\'dummy_string\' as string) as test_sub_type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_results_description\n\n,\n                \n        cast(\'dummy_string\' as string) as owners\n\n,\n                \n        cast(\'dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_results_query\n\n,\n                \n        cast(\'dummy_string\' as string) as other\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_params\n\n,\n                \n        cast(\'dummy_string\' as string) as severity\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast(\'dummy_string\' as string) as test_short_name\n\n,\n                \n        cast(\'dummy_string\' as string) as test_alias\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as result_rows\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_tests','model.elementary.dbt_tests','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_tests','MERGE (0.0 rows, 0 processed)','success','model',7.942589044570923,'2023-04-20T22:59:41.832251Z','2023-04-20T22:59:49.691372Z','2023-04-20T22:59:41.752047Z','2023-04-20T22:59:41.830923Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as short_name\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as test_column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as severity\n\n,\n                \n        cast(\'dummy_string\' as string) as warn_if\n\n,\n                \n        cast(\'dummy_string\' as string) as error_if\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_params\n\n,\n                \n        cast(\'dummy_string\' as string) as test_namespace\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_owners\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'dummy_string\' as string) as parent_model_unique_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.metadata','model.elementary.metadata','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','metadata','CREATE TABLE (1.0 rows, 0 processed)','success','model',2.7391839027404785,'2023-04-20T22:59:46.990309Z','2023-04-20T22:59:49.706231Z','2023-04-20T22:59:46.970776Z','2023-04-20T22:59:46.989718Z',1,False,'\n\nSELECT\n    \'0.7.5\' as dbt_pkg_version',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.job_run_results','model.elementary.job_run_results','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','job_run_results','CREATE VIEW (0 processed)','success','model',1.0546362400054932,'2023-04-20T22:59:49.750898Z','2023-04-20T22:59:50.779387Z','2023-04-20T22:59:49.726946Z','2023-04-20T22:59:49.749895Z',NULL,False,'\n\n\n\n\n\nwith jobs as (\n  select\n    job_name,\n    job_id,\n    job_run_id,\n    \nmin(cast(run_started_at as TIMESTAMP))\n as job_run_started_at,\n    \nmax(cast(run_completed_at as TIMESTAMP))\n as job_run_completed_at,\n    \n    timestamp_diff(\nmax(cast(run_completed_at as TIMESTAMP))\n, \nmin(cast(run_started_at as TIMESTAMP))\n, second)\n as job_run_execution_time\n  from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`\n  where job_id is not null\n  group by job_name, job_id, job_run_id\n)\n\nselect\n  job_name as name,\n  job_id as id,\n  job_run_id as run_id,\n  job_run_started_at as run_started_at,\n  job_run_completed_at as run_completed_at,\n  job_run_execution_time as run_execution_time\nfrom jobs',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.de_project.land_and_property_transform','model.de_project.land_and_property_transform','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','land_and_property_transform','CREATE VIEW (0 processed)','success','model',1.1238501071929932,'2023-04-20T22:59:49.742379Z','2023-04-20T22:59:50.819818Z','2023-04-20T22:59:49.711609Z','2023-04-20T22:59:49.732432Z',NULL,False,'with source AS (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`\n\n),\n\nrenamed as (\n    select\n        `Account_Customer` AS customer,\n        `FR`,\n        `DFL`,\n        `TP`,\n        `DLG`,\n        `OS_W_`,\n        `OS_NPW_`,\n        `OS_P_`,\n        `OS_NPP_`,\n        `SIMS`,\n        `OC1`,\n        `OC2`,\n        `date_added`\n\n    from source\n)\nselect * from renamed',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.schema_columns_snapshot','model.elementary.schema_columns_snapshot','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','schema_columns_snapshot','MERGE (0.0 rows, 0 processed)','success','model',2.499725103378296,'2023-04-20T22:59:48.566251Z','2023-04-20T22:59:51.037922Z','2023-04-20T22:59:48.541609Z','2023-04-20T22:59:48.565645Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as column_state_id\n\n,\n                \n        cast(\'dummy_string\' as string) as full_column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as data_type\n\n,\n                \n        cast (True as BOOL) as is_new\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_sources','model.elementary.dbt_sources','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_sources','MERGE (0.0 rows, 412.0 Bytes processed)','success','model',10.443569898605347,'2023-04-20T22:59:41.343800Z','2023-04-20T22:59:51.748828Z','2023-04-20T22:59:41.306753Z','2023-04-20T22:59:41.343139Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as source_name\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as identifier\n\n,\n                \n        cast(\'dummy_string\' as string) as loaded_at_field\n\n,\n                \n        cast(\'dummy_string\' as string) as freshness_warn_after\n\n,\n                \n        cast(\'dummy_string\' as string) as freshness_error_after\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as freshness_filter\n\n,\n                \n        cast(\'dummy_string\' as string) as relation_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as source_description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.monitors_runs','model.elementary.monitors_runs','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','monitors_runs','CREATE VIEW (0 processed)','success','model',0.9313831329345703,'2023-04-20T22:59:50.863193Z','2023-04-20T22:59:51.766996Z','2023-04-20T22:59:50.846301Z','2023-04-20T22:59:50.861941Z',NULL,False,'\n\nwith data_monitoring_metrics as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`\n\n),\n\nmax_bucket_end as (\n\n    select full_table_name,\n           column_name,\n           metric_name,\n           metric_properties,\n           max(bucket_end) as last_bucket_end,\n           min(bucket_end) as first_bucket_end\n    from data_monitoring_metrics\n    group by 1,2,3,4\n\n)\n\nselect * from max_bucket_end',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.metrics_anomaly_score','model.elementary.metrics_anomaly_score','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','metrics_anomaly_score','CREATE VIEW (0 processed)','success','model',1.1011850833892822,'2023-04-20T22:59:50.834535Z','2023-04-20T22:59:51.883081Z','2023-04-20T22:59:50.784956Z','2023-04-20T22:59:50.832993Z',NULL,False,'\n\nwith data_monitoring_metrics as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`\n\n),\n\ntime_window_aggregation as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        metric_value,\n        source_value,\n        bucket_start,\n        bucket_end,\n        bucket_duration_hours,\n        updated_at,\n        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,\n        stddev(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,\n        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,\n        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,\n        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start\n    from data_monitoring_metrics\n    group by 1,2,3,4,5,6,7,8,9,10,11,12\n),\n\nmetrics_anomaly_score as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        case\n            when training_stddev is null then null\n            when training_stddev = 0 then 0\n            else (metric_value - training_avg) / (training_stddev)\n        end as anomaly_score,\n        metric_value as latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        max(updated_at) as updated_at\n    from time_window_aggregation\n        where\n            metric_value is not null\n            and training_avg is not null\n            and training_set_size >= 14\n            and bucket_end >= \n       timestamp_add(cast(\n    timestamp_trunc(cast(current_timestamp as timestamp), day)\n as TIMESTAMP), INTERVAL cast(-7 as INT64) day)\n\n    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\n    order by bucket_end desc\n\n\n),\n\nfinal as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        anomaly_score,\n        latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        updated_at,\n        case\n            when abs(anomaly_score) > 3 then true\n            else false end\n        as is_anomaly\n    from metrics_anomaly_score\n)\n\nselect * from final',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.model_run_results','model.elementary.model_run_results','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','model_run_results','CREATE VIEW (0 processed)','success','model',1.2587368488311768,'2023-04-20T22:59:51.063330Z','2023-04-20T22:59:52.301838Z','2023-04-20T22:59:51.045458Z','2023-04-20T22:59:51.062151Z',NULL,False,'\n\nwith dbt_run_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`\n),\n\ndbt_models as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.thread_id,\n    models.database_name,\n    models.schema_name,\n    models.materialization,\n    models.tags,\n    models.package_name,\n    models.path,\n    models.original_path,\n    models.owner,\n    models.alias,\n    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,\n    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY \n    timestamp_trunc(cast(run_results.generated_at as timestamp), day)\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_first_invocation_of_the_day,\n    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY \n    timestamp_trunc(cast(run_results.generated_at as timestamp), day)\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_last_invocation_of_the_day\n    \nFROM dbt_run_results run_results\nJOIN dbt_models models ON run_results.unique_id = models.unique_id',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.alerts_dbt_tests','model.elementary.alerts_dbt_tests','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','alerts_dbt_tests','CREATE VIEW (0 processed)','success','model',0.9367868900299072,'2023-04-20T22:59:51.922471Z','2023-04-20T22:59:52.832999Z','2023-04-20T22:59:51.902357Z','2023-04-20T22:59:51.921499Z',NULL,False,'\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_dbt_tests as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'dbt_test\'\n)\n\nselect * from alerts_dbt_tests',NULL,NULL,'Thread-2 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.alerts_anomaly_detection','model.elementary.alerts_anomaly_detection','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','alerts_anomaly_detection','CREATE VIEW (0 processed)','success','model',1.3532612323760986,'2023-04-20T22:59:52.016951Z','2023-04-20T22:59:53.135686Z','2023-04-20T22:59:51.784231Z','2023-04-20T22:59:52.015404Z',NULL,False,'\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_anomaly_detection as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'anomaly_detection\'\n)\n\nselect * from alerts_anomaly_detection',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.snapshot_run_results','model.elementary.snapshot_run_results','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','snapshot_run_results','CREATE VIEW (0 processed)','success','model',1.5222530364990234,'2023-04-20T22:59:51.769303Z','2023-04-20T22:59:53.272769Z','2023-04-20T22:59:51.753709Z','2023-04-20T22:59:51.764650Z',NULL,False,'\n\nwith dbt_run_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`\n),\n\ndbt_snapshots as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.thread_id,\n    snapshots.database_name,\n    snapshots.schema_name,\n    snapshots.materialization,\n    snapshots.tags,\n    snapshots.package_name,\n    snapshots.path,\n    snapshots.original_path,\n    snapshots.owner,\n    snapshots.alias\nFROM dbt_run_results run_results\nJOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id',NULL,NULL,'Thread-4 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.alerts_schema_changes','model.elementary.alerts_schema_changes','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','alerts_schema_changes','CREATE VIEW (0 processed)','success','model',1.4716486930847168,'2023-04-20T22:59:52.320820Z','2023-04-20T22:59:53.775489Z','2023-04-20T22:59:52.305711Z','2023-04-20T22:59:52.319273Z',NULL,False,'\n\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_schema_changes as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'schema_change\'\n)\n\nselect * from alerts_schema_changes',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.de_project.final_land_and_property','model.de_project.final_land_and_property','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','final_land_and_property','CREATE VIEW (0 processed)','success','model',1.849376916885376,'2023-04-20T22:59:53.144713Z','2023-04-20T22:59:54.987287Z','2023-04-20T22:59:53.139451Z','2023-04-20T22:59:53.144216Z',NULL,False,'with source as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_transform`\n\n)\nSELECT\n*\nFROM source',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.dbt_artifacts_hashes','model.elementary.dbt_artifacts_hashes','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','dbt_artifacts_hashes','CREATE VIEW (0 processed)','success','model',1.119800090789795,'2023-04-20T22:59:54.872964Z','2023-04-20T22:59:55.970994Z','2023-04-20T22:59:54.864795Z','2023-04-20T22:59:54.871268Z',NULL,False,'\n\n\n\n\nselect\n  \'dbt_models\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_models`\n union all \n\nselect\n  \'dbt_tests\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`\n union all \n\nselect\n  \'dbt_sources\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`\n union all \n\nselect\n  \'dbt_snapshots\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`\n union all \n\nselect\n  \'dbt_metrics\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`\n union all \n\nselect\n  \'dbt_exposures\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`\n union all \n\nselect\n  \'dbt_seeds\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`\n\n\norder by metadata_hash',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.alerts_dbt_source_freshness','model.elementary.alerts_dbt_source_freshness','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','alerts_dbt_source_freshness','CREATE VIEW (0 processed)','success','model',1.1678190231323242,'2023-04-20T22:59:54.881822Z','2023-04-20T22:59:56.017648Z','2023-04-20T22:59:54.854503Z','2023-04-20T22:59:54.872602Z',NULL,False,'\n\nwith results as (\n  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`\n),\n\nsources as (\n  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`\n)\n\nselect\n  results.source_freshness_execution_id as alert_id,\n  results.max_loaded_at,\n  results.snapshotted_at,\n  results.generated_at as detected_at,\n  results.max_loaded_at_time_ago_in_s,\n  results.status,\n  results.error,\n  sources.unique_id,\n  sources.database_name,\n  sources.schema_name,\n  sources.source_name,\n  sources.identifier,\n  sources.freshness_error_after,\n  sources.freshness_warn_after,\n  sources.freshness_filter,\n  sources.tags,\n  sources.meta,\n  sources.owner,\n  sources.package_name,\n  sources.path\nfrom results\njoin sources on results.unique_id = sources.unique_id\nwhere True and lower(status) != \'pass\'',NULL,NULL,'Thread-4 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.anomaly_threshold_sensitivity','model.elementary.anomaly_threshold_sensitivity','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','anomaly_threshold_sensitivity','CREATE VIEW (0 processed)','success','model',1.156599998474121,'2023-04-20T22:59:55.010112Z','2023-04-20T22:59:56.145255Z','2023-04-20T22:59:54.991563Z','2023-04-20T22:59:55.008588Z',NULL,False,'\n\nwith metrics_anomaly_score as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`\n\n),\n\nscore_sensitivity as (\n\n    select\n        full_table_name,\n        column_name,\n        metric_name,\n        latest_metric_value,\n        training_avg as metric_avg,\n        training_stddev as metric_stddev,\n        anomaly_score,\n        case when abs(anomaly_score) >= 1.5 then true else false end as `is_anomaly_1_5`,\n        case when abs(anomaly_score) >= 2 then true else false end as `is_anomaly_2`,\n        case when abs(anomaly_score) >= 2.5 then true else false end as `is_anomaly_2_5`,\n        case when abs(anomaly_score) >= 3 then true else false end as `is_anomaly_3`,\n        case when abs(anomaly_score) >= 3.5 then true else false end as `is_anomaly_3_5`,\n        case when abs(anomaly_score) >= 4 then true else false end as `is_anomaly_4`,\n        case when abs(anomaly_score) >= 4.5 then true else false end as `is_anomaly_4_5`\n    from metrics_anomaly_score\n    where abs(anomaly_score) >= 1.5\n\n)\n\nselect * from score_sensitivity',NULL,NULL,'Thread-1 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.alerts_dbt_models','model.elementary.alerts_dbt_models','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','alerts_dbt_models','CREATE VIEW (0 processed)','success','model',1.0720467567443848,'2023-04-20T22:59:55.991831Z','2023-04-20T22:59:57.046552Z','2023-04-20T22:59:55.976712Z','2023-04-20T22:59:55.990137Z',NULL,False,'\n\nwith error_models as (\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias \n    from `dtc-de-383113`.`de_data_warehouse`.`model_run_results`\n  \n    union all\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias  \n  from `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`\n)\n\n\nselect model_execution_id as alert_id,\n       unique_id,\n       generated_at as detected_at,\n       database_name,\n       materialization,\n       path,\n       original_path,\n       schema_name,\n       message,\n       owner as owners,\n       tags,\n       alias,\n       status,\n       full_refresh\nfrom error_models\nwhere True and lower(status) != \'success\'and lower(status) != \'skipped\'',NULL,NULL,'Thread-3 (worker)'),('9f3fc660-72f8-4b44-97ce-7042bae015c7.model.elementary.test_result_rows','model.elementary.test_result_rows','9f3fc660-72f8-4b44-97ce-7042bae015c7','2023-04-20 22:59:59','test_result_rows','MERGE (0.0 rows, 0 processed)','success','model',4.507535219192505,'2023-04-20T22:59:52.856129Z','2023-04-20T22:59:57.344710Z','2023-04-20T22:59:52.839196Z','2023-04-20T22:59:52.855488Z',0,False,'\n\n-- depends_on: `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as elementary_test_results_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as result_row\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-2 (worker)')
  
[0m23:00:01.530048 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:43dc1a4f-8e49-47e1-825c-07df76ec385b&page=queryresults
[0m23:00:01.531109 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:00:01.545850 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:00:02.042458 [debug] [MainThread]: Elementary: Inserting 1 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
[0m23:00:02.076255 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:00:02.077930 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user) values
    ('9f3fc660-72f8-4b44-97ce-7042bae015c7',NULL,NULL,NULL,'2023-04-20 22:59:22','2023-04-20 23:00:01','2023-04-20 23:00:01','run','1.4.5','0.7.5',False,'{}','{}','dev','dtc-de-383113','de_data_warehouse','de_project',4,'[]','[]',NULL,'de_project',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL)
  
[0m23:00:03.809807 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:4bf55e2e-ca13-4997-bab8-072289c74134&page=queryresults
[0m23:00:03.811258 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:00:03.813219 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:00:03.814805 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:00:03.815566 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.00s]
[0m23:00:03.816423 [info ] [MainThread]: 
[0m23:00:03.818108 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:00:03.818568 [debug] [MainThread]: Connection 'model.elementary.anomaly_threshold_sensitivity' was properly closed.
[0m23:00:03.818869 [debug] [MainThread]: Connection 'model.elementary.test_result_rows' was properly closed.
[0m23:00:03.819106 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_models' was properly closed.
[0m23:00:03.819336 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_source_freshness' was properly closed.
[0m23:00:03.819760 [info ] [MainThread]: 
[0m23:00:03.820149 [info ] [MainThread]: Finished running 17 view models, 14 incremental models, 1 table model, 2 hooks in 0 hours 0 minutes and 39.99 seconds (39.99s).
[0m23:00:03.822622 [debug] [MainThread]: Command end result
[0m23:00:03.863052 [info ] [MainThread]: 
[0m23:00:03.863557 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:00:03.863955 [info ] [MainThread]: 
[0m23:00:03.864372 [info ] [MainThread]: Done. PASS=32 WARN=0 ERROR=0 SKIP=0 TOTAL=32
[0m23:00:03.865184 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1295bf750>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1295f4290>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x1293aee90>]}
[0m23:00:03.865774 [debug] [MainThread]: Flushing usage events


============================== 2023-04-20 23:02:09.845629 | 2e1b5e67-9716-41f4-a7ef-021ca13b4f2e ==============================
[0m23:02:09.845629 [info ] [MainThread]: Running with dbt=1.4.5
[0m23:02:09.850844 [debug] [MainThread]: running dbt with arguments {'write_json': True, 'use_colors': True, 'printer_width': 80, 'version_check': True, 'partial_parse': True, 'static_parser': True, 'profiles_dir': '/Users/yalcin/.dbt', 'send_anonymous_usage_stats': True, 'quiet': False, 'no_print': False, 'cache_selected_only': False, 'which': 'run', 'rpc_method': 'run', 'indirect_selection': 'eager'}
[0m23:02:09.851325 [debug] [MainThread]: Tracking: tracking
[0m23:02:09.904080 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'start', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11bf58650>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109643d10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cd7c810>]}
[0m23:02:09.956897 [debug] [MainThread]: checksum: e05dd7cee44d39ae8ac27965cacd8a6d8d0ab4e8185101e0db84e98f79bee0b6, vars: {}, profile: None, target: None, version: 1.4.5
[0m23:02:10.204307 [debug] [MainThread]: Partial parsing enabled: 0 files deleted, 0 files added, 0 files changed.
[0m23:02:10.204698 [debug] [MainThread]: Partial parsing enabled, no changes found, skipping parsing
[0m23:02:10.214529 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'load_project', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109627c90>]}
[0m23:02:10.238378 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'resource_counts', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cdcfe50>]}
[0m23:02:10.238898 [info ] [MainThread]: Found 32 models, 0 tests, 0 snapshots, 0 analyses, 880 macros, 2 operations, 0 seed files, 1 source, 0 exposures, 0 metrics
[0m23:02:10.239244 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cd96390>]}
[0m23:02:10.242650 [info ] [MainThread]: 
[0m23:02:10.245129 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m23:02:10.248106 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dtc-de-383113'
[0m23:02:10.249081 [debug] [ThreadPool]: Opening a new connection, currently in state init
[0m23:02:11.234231 [debug] [ThreadPool]: Acquiring new bigquery connection 'list_dtc-de-383113_de_data_warehouse'
[0m23:02:11.235254 [debug] [ThreadPool]: Opening a new connection, currently in state closed
[0m23:02:12.082108 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'runnable_timing', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x105f38fd0>]}
[0m23:02:12.082691 [info ] [MainThread]: 
[0m23:02:12.083129 [info ] [MainThread]: Running 1 on-run-start hook
[0m23:02:12.119412 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-start-0"
[0m23:02:12.124598 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-start.0 ................................... [RUN]
[0m23:02:12.125373 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-start.0 ...................................... [[32mOK[0m in 0.00s]
[0m23:02:12.125832 [info ] [MainThread]: 
[0m23:02:12.126822 [info ] [MainThread]: Concurrency: 4 threads (target='dev')
[0m23:02:12.127256 [info ] [MainThread]: 
[0m23:02:12.222829 [debug] [Thread-1 (]: Began running node model.de_project.land_and_property_optimized_raw
[0m23:02:12.223162 [debug] [Thread-2 (]: Began running node model.elementary.data_monitoring_metrics
[0m23:02:12.223454 [debug] [Thread-3 (]: Began running node model.elementary.dbt_exposures
[0m23:02:12.224000 [info ] [Thread-1 (]: 1 of 32 START sql view model de_data_warehouse.land_and_property_optimized_raw . [RUN]
[0m23:02:12.224541 [debug] [Thread-4 (]: Began running node model.elementary.dbt_invocations
[0m23:02:12.224857 [info ] [Thread-2 (]: 2 of 32 START sql incremental model de_data_warehouse.data_monitoring_metrics .. [RUN]
[0m23:02:12.225450 [info ] [Thread-3 (]: 3 of 32 START sql incremental model de_data_warehouse.dbt_exposures ............ [RUN]
[0m23:02:12.226254 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.de_project.land_and_property_optimized_raw'
[0m23:02:12.226615 [info ] [Thread-4 (]: 4 of 32 START sql incremental model de_data_warehouse.dbt_invocations .......... [RUN]
[0m23:02:12.227246 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.data_monitoring_metrics'
[0m23:02:12.227737 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_exposures'
[0m23:02:12.227961 [debug] [Thread-1 (]: Began compiling node model.de_project.land_and_property_optimized_raw
[0m23:02:12.228373 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_invocations'
[0m23:02:12.228569 [debug] [Thread-2 (]: Began compiling node model.elementary.data_monitoring_metrics
[0m23:02:12.228932 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_exposures
[0m23:02:12.232276 [debug] [Thread-1 (]: Writing injected SQL for node "model.de_project.land_and_property_optimized_raw"
[0m23:02:12.232667 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_invocations
[0m23:02:12.312230 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.data_monitoring_metrics"
[0m23:02:12.323384 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_exposures"
[0m23:02:12.330304 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_optimized_raw (compile): 2023-04-20 23:02:12.229191 => 2023-04-20 23:02:12.330152
[0m23:02:12.358369 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_invocations"
[0m23:02:12.359211 [debug] [Thread-1 (]: Began executing node model.de_project.land_and_property_optimized_raw
[0m23:02:12.359512 [debug] [Thread-2 (]: Timing info for model.elementary.data_monitoring_metrics (compile): 2023-04-20 23:02:12.232842 => 2023-04-20 23:02:12.359430
[0m23:02:12.359880 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_exposures (compile): 2023-04-20 23:02:12.250054 => 2023-04-20 23:02:12.359817
[0m23:02:12.379934 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_invocations (compile): 2023-04-20 23:02:12.323765 => 2023-04-20 23:02:12.379836
[0m23:02:12.396422 [debug] [Thread-1 (]: Writing runtime sql for node "model.de_project.land_and_property_optimized_raw"
[0m23:02:12.396908 [debug] [Thread-2 (]: Began executing node model.elementary.data_monitoring_metrics
[0m23:02:12.397545 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_exposures
[0m23:02:12.398148 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_invocations
[0m23:02:12.416855 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:12.470158 [debug] [Thread-2 (]: Opening a new connection, currently in state init
[0m23:02:12.472465 [debug] [Thread-3 (]: Opening a new connection, currently in state init
[0m23:02:12.477583 [debug] [Thread-4 (]: Opening a new connection, currently in state init
[0m23:02:12.532017 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.data_monitoring_metrics"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as id

,
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as metric_name

,
                
        cast(123456789.99 as FLOAT64) as metric_value

,
                
        cast('dummy_string' as string) as source_value

,
                cast('2091-02-17' as TIMESTAMP) as bucket_start

,
                cast('2091-02-17' as TIMESTAMP) as bucket_end

,
                
        cast(123456789 as INT64) as bucket_duration_hours

,
                cast('2091-02-17' as TIMESTAMP) as updated_at

,
                
        cast('dummy_string' as string) as dimension

,
                
        cast('dummy_string' as string) as dimension_value

,
                
        cast('dummy_string' as string) as metric_properties


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m23:02:12.532668 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_invocations"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as invocation_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as job_run_id

,
                
        cast('dummy_string' as string) as run_started_at

,
                
        cast('dummy_string' as string) as run_completed_at

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as command

,
                
        cast('dummy_string' as string) as dbt_version

,
                
        cast('dummy_string' as string) as elementary_version

,
                
        cast (True as BOOL) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as string) as invocation_vars

,
                
        cast('this_is_just_a_long_dummy_string' as string) as vars

,
                
        cast('dummy_string' as string) as target_name

,
                
        cast('dummy_string' as string) as target_database

,
                
        cast('dummy_string' as string) as target_schema

,
                
        cast('dummy_string' as string) as target_profile_name

,
                
        cast(123456789 as INT64) as threads

,
                
        cast('this_is_just_a_long_dummy_string' as string) as selected

,
                
        cast('this_is_just_a_long_dummy_string' as string) as yaml_selector

,
                
        cast('dummy_string' as string) as project_id

,
                
        cast('dummy_string' as string) as project_name

,
                
        cast('dummy_string' as string) as env

,
                
        cast('dummy_string' as string) as env_id

,
                
        cast('dummy_string' as string) as cause_category

,
                
        cast('this_is_just_a_long_dummy_string' as string) as cause

,
                
        cast('dummy_string' as string) as pull_request_id

,
                
        cast('dummy_string' as string) as git_sha

,
                
        cast('dummy_string' as string) as orchestrator

,
                
        cast('dummy_string' as string) as dbt_user


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:12.534283 [debug] [Thread-1 (]: On model.de_project.land_and_property_optimized_raw: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.land_and_property_optimized_raw"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`
  OPTIONS()
  as with source as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized`
)
select * from source;


[0m23:02:12.537264 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as maturity

,
                
        cast('dummy_string' as string) as type

,
                
        cast('dummy_string' as string) as owner_email

,
                
        cast('dummy_string' as string) as owner_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as url

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:13.643188 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:4f4b9d4c-725f-46c7-a74e-bc3cea817ff2&page=queryresults
[0m23:02:13.666934 [debug] [Thread-1 (]: Timing info for model.de_project.land_and_property_optimized_raw (execute): 2023-04-20 23:02:12.360108 => 2023-04-20 23:02:13.666867
[0m23:02:13.667682 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cd7e650>]}
[0m23:02:13.668224 [info ] [Thread-1 (]: 1 of 32 OK created sql view model de_data_warehouse.land_and_property_optimized_raw  [[32mCREATE VIEW (0 processed)[0m in 1.44s]
[0m23:02:13.670050 [debug] [Thread-1 (]: Finished running node model.de_project.land_and_property_optimized_raw
[0m23:02:13.670537 [debug] [Thread-1 (]: Began running node model.elementary.dbt_metrics
[0m23:02:13.671236 [info ] [Thread-1 (]: 5 of 32 START sql incremental model de_data_warehouse.dbt_metrics .............. [RUN]
[0m23:02:13.672049 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_metrics'
[0m23:02:13.672315 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_metrics
[0m23:02:13.704422 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_metrics"
[0m23:02:13.705542 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_metrics (compile): 2023-04-20 23:02:13.672464 => 2023-04-20 23:02:13.705387
[0m23:02:13.706169 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_metrics
[0m23:02:13.716962 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:13.769385 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as label

,
                
        cast('dummy_string' as string) as model

,
                
        cast('dummy_string' as string) as type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as sql

,
                
        cast('dummy_string' as string) as timestamp

,
                
        cast('this_is_just_a_long_dummy_string' as string) as filters

,
                
        cast('this_is_just_a_long_dummy_string' as string) as time_grains

,
                
        cast('this_is_just_a_long_dummy_string' as string) as dimensions

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:14.844050 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b6ce1009-8ac9-4d90-ab4f-33b5fccd9fd4&page=queryresults
[0m23:02:15.953155 [debug] [Thread-3 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:16.002619 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_exposures"
[0m23:02:16.004344 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`maturity` = DBT_INTERNAL_SOURCE.`maturity`,`type` = DBT_INTERNAL_SOURCE.`type`,`owner_email` = DBT_INTERNAL_SOURCE.`owner_email`,`owner_name` = DBT_INTERNAL_SOURCE.`owner_name`,`url` = DBT_INTERNAL_SOURCE.`url`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `name`, `maturity`, `type`, `owner_email`, `owner_name`, `url`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `name`, `maturity`, `type`, `owner_email`, `owner_name`, `url`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m23:02:16.395301 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:bd669e43-15da-4b64-9c25-bdaf4444c247&page=queryresults
[0m23:02:16.442585 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5d8414a7-cb59-4481-b122-13e3a6deaf02&page=queryresults
[0m23:02:16.701244 [debug] [Thread-1 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:16.705411 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_metrics"
[0m23:02:16.706286 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`name` = DBT_INTERNAL_SOURCE.`name`,`label` = DBT_INTERNAL_SOURCE.`label`,`model` = DBT_INTERNAL_SOURCE.`model`,`type` = DBT_INTERNAL_SOURCE.`type`,`sql` = DBT_INTERNAL_SOURCE.`sql`,`timestamp` = DBT_INTERNAL_SOURCE.`timestamp`,`filters` = DBT_INTERNAL_SOURCE.`filters`,`time_grains` = DBT_INTERNAL_SOURCE.`time_grains`,`dimensions` = DBT_INTERNAL_SOURCE.`dimensions`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `name`, `label`, `model`, `type`, `sql`, `timestamp`, `filters`, `time_grains`, `dimensions`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `name`, `label`, `model`, `type`, `sql`, `timestamp`, `filters`, `time_grains`, `dimensions`, `depends_on_macros`, `depends_on_nodes`, `description`, `tags`, `meta`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m23:02:16.795418 [debug] [Thread-2 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:16.799230 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.data_monitoring_metrics"
[0m23:02:16.800442 [debug] [Thread-2 (]: On model.elementary.data_monitoring_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.data_monitoring_metrics"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
            )

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`full_table_name` = DBT_INTERNAL_SOURCE.`full_table_name`,`column_name` = DBT_INTERNAL_SOURCE.`column_name`,`metric_name` = DBT_INTERNAL_SOURCE.`metric_name`,`metric_value` = DBT_INTERNAL_SOURCE.`metric_value`,`source_value` = DBT_INTERNAL_SOURCE.`source_value`,`bucket_start` = DBT_INTERNAL_SOURCE.`bucket_start`,`bucket_end` = DBT_INTERNAL_SOURCE.`bucket_end`,`bucket_duration_hours` = DBT_INTERNAL_SOURCE.`bucket_duration_hours`,`updated_at` = DBT_INTERNAL_SOURCE.`updated_at`,`dimension` = DBT_INTERNAL_SOURCE.`dimension`,`dimension_value` = DBT_INTERNAL_SOURCE.`dimension_value`,`metric_properties` = DBT_INTERNAL_SOURCE.`metric_properties`
    

    when not matched then insert
        (`id`, `full_table_name`, `column_name`, `metric_name`, `metric_value`, `source_value`, `bucket_start`, `bucket_end`, `bucket_duration_hours`, `updated_at`, `dimension`, `dimension_value`, `metric_properties`)
    values
        (`id`, `full_table_name`, `column_name`, `metric_name`, `metric_value`, `source_value`, `bucket_start`, `bucket_end`, `bucket_duration_hours`, `updated_at`, `dimension`, `dimension_value`, `metric_properties`)


    
[0m23:02:17.838275 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:693d1c28-3639-456c-8b3b-7e3e29b88af4&page=queryresults
[0m23:02:17.876891 [debug] [Thread-3 (]: Elementary: [dbt_exposures] Flattening the artifacts.
[0m23:02:17.880932 [debug] [Thread-3 (]: Elementary: [dbt_exposures] Flattened 0 artifacts.
[0m23:02:17.907985 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__tmp_20230420230217891884`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
        WHERE 1 = 0
    
    );
  
  
[0m23:02:18.369278 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5648b934-955c-4c36-a6d3-084e8ae4fdf0&page=queryresults
[0m23:02:18.485669 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:f9b91278-684d-4d58-9918-817031d0a236&page=queryresults
[0m23:02:18.488438 [debug] [Thread-2 (]: Timing info for model.elementary.data_monitoring_metrics (execute): 2023-04-20 23:02:12.398932 => 2023-04-20 23:02:18.488368
[0m23:02:18.489229 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ce02610>]}
[0m23:02:18.489722 [info ] [Thread-2 (]: 2 of 32 OK created sql incremental model de_data_warehouse.data_monitoring_metrics  [[32mMERGE (0.0 rows, 0 processed)[0m in 6.26s]
[0m23:02:18.490190 [debug] [Thread-2 (]: Finished running node model.elementary.data_monitoring_metrics
[0m23:02:18.490666 [debug] [Thread-2 (]: Began running node model.elementary.dbt_models
[0m23:02:18.491346 [info ] [Thread-2 (]: 6 of 32 START sql incremental model de_data_warehouse.dbt_models ............... [RUN]
[0m23:02:18.492048 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.dbt_models'
[0m23:02:18.492367 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_models
[0m23:02:18.536450 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_models"
[0m23:02:18.537748 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_models (compile): 2023-04-20 23:02:18.492619 => 2023-04-20 23:02:18.537654
[0m23:02:18.538170 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_models
[0m23:02:18.546775 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:18.577909 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:15738f6d-da4e-442c-ba43-670869024317&page=queryresults
[0m23:02:18.583940 [debug] [Thread-1 (]: Elementary: [dbt_metrics] Flattening the artifacts.
[0m23:02:18.586642 [debug] [Thread-1 (]: Elementary: [dbt_metrics] Flattened 0 artifacts.
[0m23:02:18.591031 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__tmp_20230420230218588735`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
        WHERE 1 = 0
    
    );
  
  
[0m23:02:18.598820 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('dummy_string' as string) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:18.756166 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:18.759980 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_invocations"
[0m23:02:18.760920 [debug] [Thread-4 (]: On model.elementary.dbt_invocations: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_invocations"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.invocation_id = DBT_INTERNAL_DEST.invocation_id
            )

    
    when matched then update set
        `invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`,`job_id` = DBT_INTERNAL_SOURCE.`job_id`,`job_name` = DBT_INTERNAL_SOURCE.`job_name`,`job_run_id` = DBT_INTERNAL_SOURCE.`job_run_id`,`run_started_at` = DBT_INTERNAL_SOURCE.`run_started_at`,`run_completed_at` = DBT_INTERNAL_SOURCE.`run_completed_at`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`command` = DBT_INTERNAL_SOURCE.`command`,`dbt_version` = DBT_INTERNAL_SOURCE.`dbt_version`,`elementary_version` = DBT_INTERNAL_SOURCE.`elementary_version`,`full_refresh` = DBT_INTERNAL_SOURCE.`full_refresh`,`invocation_vars` = DBT_INTERNAL_SOURCE.`invocation_vars`,`vars` = DBT_INTERNAL_SOURCE.`vars`,`target_name` = DBT_INTERNAL_SOURCE.`target_name`,`target_database` = DBT_INTERNAL_SOURCE.`target_database`,`target_schema` = DBT_INTERNAL_SOURCE.`target_schema`,`target_profile_name` = DBT_INTERNAL_SOURCE.`target_profile_name`,`threads` = DBT_INTERNAL_SOURCE.`threads`,`selected` = DBT_INTERNAL_SOURCE.`selected`,`yaml_selector` = DBT_INTERNAL_SOURCE.`yaml_selector`,`project_id` = DBT_INTERNAL_SOURCE.`project_id`,`project_name` = DBT_INTERNAL_SOURCE.`project_name`,`env` = DBT_INTERNAL_SOURCE.`env`,`env_id` = DBT_INTERNAL_SOURCE.`env_id`,`cause_category` = DBT_INTERNAL_SOURCE.`cause_category`,`cause` = DBT_INTERNAL_SOURCE.`cause`,`pull_request_id` = DBT_INTERNAL_SOURCE.`pull_request_id`,`git_sha` = DBT_INTERNAL_SOURCE.`git_sha`,`orchestrator` = DBT_INTERNAL_SOURCE.`orchestrator`,`dbt_user` = DBT_INTERNAL_SOURCE.`dbt_user`
    

    when not matched then insert
        (`invocation_id`, `job_id`, `job_name`, `job_run_id`, `run_started_at`, `run_completed_at`, `generated_at`, `command`, `dbt_version`, `elementary_version`, `full_refresh`, `invocation_vars`, `vars`, `target_name`, `target_database`, `target_schema`, `target_profile_name`, `threads`, `selected`, `yaml_selector`, `project_id`, `project_name`, `env`, `env_id`, `cause_category`, `cause`, `pull_request_id`, `git_sha`, `orchestrator`, `dbt_user`)
    values
        (`invocation_id`, `job_id`, `job_name`, `job_run_id`, `run_started_at`, `run_completed_at`, `generated_at`, `command`, `dbt_version`, `elementary_version`, `full_refresh`, `invocation_vars`, `vars`, `target_name`, `target_database`, `target_schema`, `target_profile_name`, `threads`, `selected`, `yaml_selector`, `project_id`, `project_name`, `env`, `env_id`, `cause_category`, `cause`, `pull_request_id`, `git_sha`, `orchestrator`, `dbt_user`)


    
[0m23:02:19.648773 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:977e28da-ccc8-47b1-9fc3-5cd931c708c5&page=queryresults
[0m23:02:19.672994 [debug] [Thread-3 (]: On model.elementary.dbt_exposures: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_exposures"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures__tmp_20230420230217891884`
    );
  
  
[0m23:02:20.557372 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:44fbf216-80ac-4b1b-9526-00fd98a101ea&page=queryresults
[0m23:02:20.559525 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_invocations (execute): 2023-04-20 23:02:12.472705 => 2023-04-20 23:02:20.559464
[0m23:02:20.560231 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d164810>]}
[0m23:02:20.560789 [info ] [Thread-4 (]: 4 of 32 OK created sql incremental model de_data_warehouse.dbt_invocations ..... [[32mMERGE (0.0 rows, 416.0 Bytes processed)[0m in 8.33s]
[0m23:02:20.562752 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_invocations
[0m23:02:20.563551 [debug] [Thread-4 (]: Began running node model.elementary.dbt_run_results
[0m23:02:20.564202 [info ] [Thread-4 (]: 7 of 32 START sql incremental model de_data_warehouse.dbt_run_results .......... [RUN]
[0m23:02:20.564938 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_run_results'
[0m23:02:20.565269 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_run_results
[0m23:02:20.613584 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_run_results"
[0m23:02:20.615872 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_run_results (compile): 2023-04-20 23:02:20.565474 => 2023-04-20 23:02:20.615752
[0m23:02:20.616340 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_run_results
[0m23:02:20.624583 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:20.676181 [debug] [Thread-4 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_run_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as model_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as invocation_id

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('this_is_just_a_long_dummy_string' as string) as name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as message

,
                
        cast('dummy_string' as string) as status

,
                
        cast('dummy_string' as string) as resource_type

,
                
        cast(123456789.99 as FLOAT64) as execution_time

,
                
        cast('dummy_string' as string) as execute_started_at

,
                
        cast('dummy_string' as string) as execute_completed_at

,
                
        cast('dummy_string' as string) as compile_started_at

,
                
        cast('dummy_string' as string) as compile_completed_at

,
                
        cast(31474836478 as bigint) as rows_affected

,
                
        cast (True as BOOL) as full_refresh

,
                
        cast('this_is_just_a_long_dummy_string' as string) as compiled_code

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as string) as query_id

,
                
        cast('dummy_string' as string) as thread_id


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:20.749295 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ac3baa73-58fd-45c2-86ba-308c777747e8&page=queryresults
[0m23:02:20.751691 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c7acb347-fb93-4e69-8ecc-3afc0226cf95&page=queryresults
[0m23:02:20.755214 [debug] [Thread-1 (]: On model.elementary.dbt_metrics: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_metrics"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics__tmp_20230420230218588735`
    );
  
  
[0m23:02:21.113511 [debug] [Thread-2 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_models`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:21.115602 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_models"
[0m23:02:21.116649 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_models` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`checksum` = DBT_INTERNAL_SOURCE.`checksum`,`materialization` = DBT_INTERNAL_SOURCE.`materialization`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`name` = DBT_INTERNAL_SOURCE.`name`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m23:02:21.509888 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b792544d-b92d-443c-80ca-2ae71ded49e0&page=queryresults
[0m23:02:21.517392 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_exposures (execute): 2023-04-20 23:02:12.447586 => 2023-04-20 23:02:21.517164
[0m23:02:21.520993 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d39c810>]}
[0m23:02:21.522378 [info ] [Thread-3 (]: 3 of 32 OK created sql incremental model de_data_warehouse.dbt_exposures ....... [[32mMERGE (0.0 rows, 0 processed)[0m in 9.29s]
[0m23:02:21.523521 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_exposures
[0m23:02:21.524586 [debug] [Thread-3 (]: Began running node model.elementary.dbt_seeds
[0m23:02:21.525568 [info ] [Thread-3 (]: 8 of 32 START sql incremental model de_data_warehouse.dbt_seeds ................ [RUN]
[0m23:02:21.528679 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_seeds'
[0m23:02:21.529642 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_seeds
[0m23:02:21.557929 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_seeds"
[0m23:02:21.559246 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_seeds (compile): 2023-04-20 23:02:21.531009 => 2023-04-20 23:02:21.559050
[0m23:02:21.559847 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_seeds
[0m23:02:21.567244 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m23:02:21.613440 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:22.556567 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ea245abe-b22c-4a0d-ad59-941dd75a247a&page=queryresults
[0m23:02:22.558694 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_metrics (execute): 2023-04-20 23:02:13.706609 => 2023-04-20 23:02:22.558641
[0m23:02:22.559376 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d332f50>]}
[0m23:02:22.559917 [info ] [Thread-1 (]: 5 of 32 OK created sql incremental model de_data_warehouse.dbt_metrics ......... [[32mMERGE (0.0 rows, 0 processed)[0m in 8.89s]
[0m23:02:22.560322 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_metrics
[0m23:02:22.560856 [debug] [Thread-1 (]: Began running node model.elementary.dbt_snapshots
[0m23:02:22.561382 [info ] [Thread-1 (]: 9 of 32 START sql incremental model de_data_warehouse.dbt_snapshots ............ [RUN]
[0m23:02:22.562040 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.dbt_snapshots'
[0m23:02:22.562368 [debug] [Thread-1 (]: Began compiling node model.elementary.dbt_snapshots
[0m23:02:22.585613 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.dbt_snapshots"
[0m23:02:22.586560 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_snapshots (compile): 2023-04-20 23:02:22.562576 => 2023-04-20 23:02:22.586427
[0m23:02:22.586858 [debug] [Thread-1 (]: Began executing node model.elementary.dbt_snapshots
[0m23:02:22.596427 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:22.649471 [debug] [Thread-1 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as checksum

,
                
        cast('dummy_string' as string) as materialization

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:22.948674 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:7010e2d1-080c-4f7e-95b4-ddb769479759&page=queryresults
[0m23:02:23.084606 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:2907184d-a4dc-487a-b0b2-40d87977ccf5&page=queryresults
[0m23:02:23.095701 [debug] [Thread-2 (]: Elementary: [dbt_models] Flattening the artifacts.
[0m23:02:23.277168 [debug] [Thread-2 (]: Elementary: [dbt_models] Flattened 32 artifacts.
[0m23:02:23.286628 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:23.323515 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420230223318561`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
        WHERE 1 = 0
    
    );
  
  
[0m23:02:23.327074 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_run_results"
[0m23:02:23.329052 [debug] [Thread-4 (]: On model.elementary.dbt_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_run_results"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.model_execution_id = DBT_INTERNAL_DEST.model_execution_id
            )

    
    when matched then update set
        `model_execution_id` = DBT_INTERNAL_SOURCE.`model_execution_id`,`unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`name` = DBT_INTERNAL_SOURCE.`name`,`message` = DBT_INTERNAL_SOURCE.`message`,`status` = DBT_INTERNAL_SOURCE.`status`,`resource_type` = DBT_INTERNAL_SOURCE.`resource_type`,`execution_time` = DBT_INTERNAL_SOURCE.`execution_time`,`execute_started_at` = DBT_INTERNAL_SOURCE.`execute_started_at`,`execute_completed_at` = DBT_INTERNAL_SOURCE.`execute_completed_at`,`compile_started_at` = DBT_INTERNAL_SOURCE.`compile_started_at`,`compile_completed_at` = DBT_INTERNAL_SOURCE.`compile_completed_at`,`rows_affected` = DBT_INTERNAL_SOURCE.`rows_affected`,`full_refresh` = DBT_INTERNAL_SOURCE.`full_refresh`,`compiled_code` = DBT_INTERNAL_SOURCE.`compiled_code`,`failures` = DBT_INTERNAL_SOURCE.`failures`,`query_id` = DBT_INTERNAL_SOURCE.`query_id`,`thread_id` = DBT_INTERNAL_SOURCE.`thread_id`
    

    when not matched then insert
        (`model_execution_id`, `unique_id`, `invocation_id`, `generated_at`, `name`, `message`, `status`, `resource_type`, `execution_time`, `execute_started_at`, `execute_completed_at`, `compile_started_at`, `compile_completed_at`, `rows_affected`, `full_refresh`, `compiled_code`, `failures`, `query_id`, `thread_id`)
    values
        (`model_execution_id`, `unique_id`, `invocation_id`, `generated_at`, `name`, `message`, `status`, `resource_type`, `execution_time`, `execute_started_at`, `execute_completed_at`, `compile_started_at`, `compile_completed_at`, `rows_affected`, `full_refresh`, `compiled_code`, `failures`, `query_id`, `thread_id`)


    
[0m23:02:23.842997 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:060396ef-4e10-47ce-b833-2f196298c774&page=queryresults
[0m23:02:24.323379 [debug] [Thread-3 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:24.325313 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_seeds"
[0m23:02:24.325965 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`checksum` = DBT_INTERNAL_SOURCE.`checksum`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`description` = DBT_INTERNAL_SOURCE.`description`,`name` = DBT_INTERNAL_SOURCE.`name`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `alias`, `checksum`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `alias`, `checksum`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m23:02:25.309764 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:4f9d2e1a-b1e5-4fe1-a732-00683789af65&page=queryresults
[0m23:02:25.312468 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:d85c545a-25fe-4d45-b547-c40fb0a2169b&page=queryresults
[0m23:02:25.412381 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b8bdafca-97d4-4eb9-8d41-6170ffa2d68a&page=queryresults
[0m23:02:25.414537 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_run_results (execute): 2023-04-20 23:02:20.616801 => 2023-04-20 23:02:25.414488
[0m23:02:25.415413 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cd03410>]}
[0m23:02:25.416041 [info ] [Thread-4 (]: 7 of 32 OK created sql incremental model de_data_warehouse.dbt_run_results ..... [[32mMERGE (0.0 rows, 97.7 KB processed)[0m in 4.85s]
[0m23:02:25.416498 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_run_results
[0m23:02:25.417020 [debug] [Thread-4 (]: Began running node model.elementary.dbt_source_freshness_results
[0m23:02:25.418299 [info ] [Thread-4 (]: 10 of 32 START sql incremental model de_data_warehouse.dbt_source_freshness_results  [RUN]
[0m23:02:25.420168 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.dbt_source_freshness_results'
[0m23:02:25.420700 [debug] [Thread-4 (]: Began compiling node model.elementary.dbt_source_freshness_results
[0m23:02:25.444383 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.dbt_source_freshness_results"
[0m23:02:25.448246 [debug] [Thread-2 (]: Elementary: Inserting 32 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420230223318561`
[0m23:02:25.470954 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_source_freshness_results (compile): 2023-04-20 23:02:25.421025 => 2023-04-20 23:02:25.470861
[0m23:02:25.498957 [debug] [Thread-4 (]: Began executing node model.elementary.dbt_source_freshness_results
[0m23:02:25.518110 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:25.623011 [debug] [Thread-4 (]: On model.elementary.dbt_source_freshness_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_source_freshness_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as source_freshness_execution_id

,
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as max_loaded_at

,
                
        cast('dummy_string' as string) as snapshotted_at

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast(123456789.99 as FLOAT64) as max_loaded_at_time_ago_in_s

,
                
        cast('dummy_string' as string) as status

,
                
        cast('dummy_string' as string) as error

,
                
        cast('dummy_string' as string) as compile_started_at

,
                
        cast('dummy_string' as string) as compile_completed_at

,
                
        cast('dummy_string' as string) as execute_started_at

,
                
        cast('dummy_string' as string) as execute_completed_at

,
                
        cast('dummy_string' as string) as invocation_id


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m23:02:25.845617 [debug] [Thread-1 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:25.852875 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.dbt_snapshots"
[0m23:02:25.890800 [debug] [Thread-1 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`checksum` = DBT_INTERNAL_SOURCE.`checksum`,`materialization` = DBT_INTERNAL_SOURCE.`materialization`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`description` = DBT_INTERNAL_SOURCE.`description`,`name` = DBT_INTERNAL_SOURCE.`name`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `alias`, `checksum`, `materialization`, `tags`, `meta`, `owner`, `database_name`, `schema_name`, `depends_on_macros`, `depends_on_nodes`, `description`, `name`, `package_name`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m23:02:26.246268 [debug] [Thread-2 (]: Elementary: [1/1] Running insert query.
[0m23:02:26.248308 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:08ae496f-0fdc-4238-8cc9-a1e5ee926a1d&page=queryresults
[0m23:02:26.251855 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420230223318561`
         (unique_id,alias,checksum,materialization,tags,meta,owner,database_name,schema_name,depends_on_macros,depends_on_nodes,description,name,package_name,original_path,path,generated_at,metadata_hash) values
    ('model.elementary.snapshot_run_results','snapshot_run_results','25bf33e62e7405e06cff77de7ee9e748c7d9c6f28889e88eeb2975cdec933457','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.dbt_run_results", "model.elementary.dbt_snapshots"]','Run results of dbt snapshots, enriched with snapshots metadata. Each row is the result of a single snapshot. This is a view that joins data from `dbt_run_results` and `dbt_snapshots`.\n','snapshot_run_results','elementary','models/edr/run_results/snapshot_run_results.sql','edr/run_results/snapshot_run_results.sql','2023-04-20 23:02:23','b2e8ee2ee6429401a1749565ce18bbb8'),('model.elementary.job_run_results','job_run_results','4f77bef7722550578b36f29135d6c77fc2f0985e3e9362881f857f2bdf99ccdf','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_cast_as_timestamp", "macro.elementary.timediff"]','["model.elementary.dbt_invocations"]','Run results of dbt invocations, enriched with jobs metadata. Each row is the result of a single job. This is a view on `dbt_invocations`.','job_run_results','elementary','models/edr/run_results/job_run_results.sql','edr/run_results/job_run_results.sql','2023-04-20 23:02:23','cfe6d470f7287227f3b9d941e5ed6763'),('model.elementary.model_run_results','model_run_results','b13f8a6604ca22e1f7b968c6383ca9333cf443c852cc677e4b25985a5750d42c','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_time_trunc"]','["model.elementary.dbt_models", "model.elementary.dbt_run_results"]','Run results of dbt models, enriched with models metadata. Each row is the result of a single model. This is a view that joins data from `dbt_run_results` and `dbt_models`.\n','model_run_results','elementary','models/edr/run_results/model_run_results.sql','edr/run_results/model_run_results.sql','2023-04-20 23:02:23','b1b27b2c855f8f443b7a29ad7caf349f'),('model.elementary.test_result_rows','test_result_rows','f882d86b0cf618b35fd6f0825316eacf1be69fe55009f74551898a5be31962fc','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.backfill_result_rows", "macro.elementary.empty_table", "macro.elementary.get_config_var"]','["model.elementary.elementary_test_results", "model.elementary.elementary_test_results", "model.elementary.elementary_test_results"]','','test_result_rows','elementary','models/edr/run_results/test_result_rows.sql','edr/run_results/test_result_rows.sql','2023-04-20 23:02:23','aa11986de0436f139683e212b22e9e9b'),('model.elementary.elementary_test_results','elementary_test_results','7b92ed7eb8aa32dd1af920bc70ab408480f469992371aaa6e2fa9722927beb08','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_elementary_test_results", "macro.elementary.get_config_var"]','[]','Run results of all dbt tests, with fields and metadata needed to produce the Elementary report UI. Each row is the result of a single test, including native dbt tests, packages tests and elementary tests. New data is loaded to this model on an on-run-end hook named `elementary.handle_tests_results`.\n','elementary_test_results','elementary','models/edr/run_results/elementary_test_results.sql','edr/run_results/elementary_test_results.sql','2023-04-20 23:02:23','a24cdc13f2a59ca31fce11149bf64905'),('model.elementary.dbt_source_freshness_results','dbt_source_freshness_results','400e5c6af2b56ab6dc10bb33edfecb74988b768bf1091087e13795a5a32a0cdf','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_dbt_source_freshness_results", "macro.elementary.get_config_var"]','[]','','dbt_source_freshness_results','elementary','models/edr/run_results/dbt_source_freshness_results.sql','edr/run_results/dbt_source_freshness_results.sql','2023-04-20 23:02:23','1168a7a7f029edabcf6dc34051f5ca37'),('model.elementary.alerts_dbt_tests','alerts_dbt_tests','644e6360ece0829a8d77509903a110b8fca81b1dedf34b8cb8b5bdcc75f83922','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate dbt tests alerts, including all the fields the alert will include such as owner, tags, error message, etc. This view includes data about all dbt tests except elementary tests. It filters alerts according to configuration.\n','alerts_dbt_tests','elementary','models/edr/alerts/alerts_dbt_tests.sql','edr/alerts/alerts_dbt_tests.sql','2023-04-20 23:02:23','277e4a40cf57ab225729f6aa6a27be08'),('model.elementary.alerts_schema_changes','alerts_schema_changes','96c9a42ca06d726bff66c903a314b13c6beb1641347aba54d93710161d2391e1','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on schema changes detected using elementary tests. The view filters alerts according to configuration.','alerts_schema_changes','elementary','models/edr/alerts/alerts_schema_changes.sql','edr/alerts/alerts_schema_changes.sql','2023-04-20 23:02:23','257b4ac15bd154e52b832da313def902'),('model.elementary.alerts_dbt_source_freshness','alerts_dbt_source_freshness','ec03b412a62d28d45853ddb68502724c9bee8ae8bf16d203391711546f5904b0','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.dbt_source_freshness_results", "model.elementary.dbt_sources"]','','alerts_dbt_source_freshness','elementary','models/edr/alerts/alerts_dbt_source_freshness.sql','edr/alerts/alerts_dbt_source_freshness.sql','2023-04-20 23:02:23','f8d27490eeb21de3c129459fedd42899'),('model.elementary.alerts_anomaly_detection','alerts_anomaly_detection','0d2bb9c33ded81e6501643abeeacde1b21695f406b861f748923e4bd9ce0c4c8','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.elementary_test_results"]','A view that is used by the Elementary CLI to generate alerts on data anomalies detected using the elementary anomaly detection tests. The view filters alerts according to configuration.\n','alerts_anomaly_detection','elementary','models/edr/alerts/alerts_anomaly_detection.sql','edr/alerts/alerts_anomaly_detection.sql','2023-04-20 23:02:23','abc8859218c6d0216fac24f1207f1bd9'),('model.elementary.alerts_dbt_models','alerts_dbt_models','aad00742146b5339efa4fbb9e8f475745116c1a6603d7a0999a2ba5d9e4392c6','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var"]','["model.elementary.model_run_results", "model.elementary.snapshot_run_results"]','A view that is used by the Elementary CLI to generate models alerts, including all the fields the alert will include such as owner, tags, error message, etc. It joins data about models and snapshots run results, and filters alerts according to configuration.\n','alerts_dbt_models','elementary','models/edr/alerts/alerts_dbt_models.sql','edr/alerts/alerts_dbt_models.sql','2023-04-20 23:02:23','853e5956cb3d5201c1f6ab18a3194491'),('model.elementary.monitors_runs','monitors_runs','3720e206635d4f2f95c193835727b0d533ec1a5fa56e5dec79331418d07e934f','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that is used to determine when a specific anomaly detection test was last executed. Each anomaly detection test queries this view to decide on a start time for collecting metrics.\n','monitors_runs','elementary','models/edr/system/monitors_runs.sql','edr/system/monitors_runs.sql','2023-04-20 23:02:23','fc5b979579f0fd4a9060a6f588a30220'),('model.elementary.metadata','metadata','08d0f5a6af1433ddf3b0077d85b594442a49901cd430729fd050c0417c48b5a2','table','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_elementary_package_version"]','[]','','metadata','elementary','models/edr/system/metadata.sql','edr/system/metadata.sql','2023-04-20 23:02:23','2d7e3e5b23a516456a352ca0fbc1603f'),('model.elementary.dbt_tests','dbt_tests','741409041141e4601052d37da988d545419809fd0c630fa7cfee31d75e66a5c2','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_tests_empty_table_query", "macro.elementary.upload_dbt_tests"]','[]','Metadata about tests in the project, including configuration and properties from the dbt graph. Each row contains information about a single test. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_tests','elementary','models/edr/dbt_artifacts/dbt_tests.sql','edr/dbt_artifacts/dbt_tests.sql','2023-04-20 23:02:23','582352ecff6170098dc8b5fd9c6b2de4'),('model.elementary.dbt_models','dbt_models','593b000e1d5ce7b219e4de4086c067491fb0333274ab375e793ccb2fb9fd3759','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.upload_dbt_models"]','[]','Metadata about models in the project, including configuration and properties from the dbt graph. Each row contains information about a single model. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_models','elementary','models/edr/dbt_artifacts/dbt_models.sql','edr/dbt_artifacts/dbt_models.sql','2023-04-20 23:02:23','45a6667f857b50814c08963227979fb7'),('model.elementary.dbt_sources','dbt_sources','d8a8439c596b52172075bc5b4106ba6c38d6dbfddbb83677b08815ea400bc712','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_sources_empty_table_query", "macro.elementary.upload_dbt_sources"]','[]','Metadata about sources in the project, including configuration and properties from the dbt graph. Each row contains information about a single source. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_sources','elementary','models/edr/dbt_artifacts/dbt_sources.sql','edr/dbt_artifacts/dbt_sources.sql','2023-04-20 23:02:23','4f5a6af3fc8463f8cba80ff847ac92e9'),('model.elementary.dbt_snapshots','dbt_snapshots','e9a4dd4bf0b0a9ec362d517a263768f9c09d319b49297618b0e68201241db006','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_models_empty_table_query", "macro.elementary.upload_dbt_snapshots"]','[]','Metadata about snapshots in the project, including configuration and properties from the dbt graph. Each row contains information about a single snapshot. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_snapshots','elementary','models/edr/dbt_artifacts/dbt_snapshots.sql','edr/dbt_artifacts/dbt_snapshots.sql','2023-04-20 23:02:23','1fad44195b8c7d17da299adf691e5839'),('model.elementary.dbt_invocations','dbt_invocations','eb905380b5a7d9d7a1daab283bae14bea8800fff22a3a6d25f5d44fea739717f','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_invocations_empty_table_query"]','[]','Attributes associated with each dbt invocation. Inserted at the end of each invocation.\n','dbt_invocations','elementary','models/edr/dbt_artifacts/dbt_invocations.sql','edr/dbt_artifacts/dbt_invocations.sql','2023-04-20 23:02:23','21c91fb0fa00307fdb36d4ccfc5d13f5'),('model.elementary.dbt_metrics','dbt_metrics','346d0ae98ddf568e9102387d30aa7d9ee4c8c3c3ea58cd254e5e57fcb800f7e9','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_metrics_empty_table_query", "macro.elementary.upload_dbt_metrics"]','[]','Metadata about metics in the project, including configuration and properties from the dbt graph. Each row contains information about a single metric. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_metrics','elementary','models/edr/dbt_artifacts/dbt_metrics.sql','edr/dbt_artifacts/dbt_metrics.sql','2023-04-20 23:02:23','3996cb4cd74bfefd0fd9a88f5b170024'),('model.elementary.dbt_seeds','dbt_seeds','8daecb4cb68c55a0ad53ba73468d4537965acf2ccdc5c4343b9e1f4e3ae6f197','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_seeds_empty_table_query", "macro.elementary.upload_dbt_seeds"]','[]','','dbt_seeds','elementary','models/edr/dbt_artifacts/dbt_seeds.sql','edr/dbt_artifacts/dbt_seeds.sql','2023-04-20 23:02:23','f1d124eda9e29d0b21e9c31e6cf99aee'),('model.elementary.dbt_artifacts_hashes','dbt_artifacts_hashes','a493a63069e8e18354eb9fe4d6e0cd21f83f7efb7c9ffc1ff5cece8943b74f85','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.elementary.dbt_exposures", "model.elementary.dbt_metrics", "model.elementary.dbt_models", "model.elementary.dbt_seeds", "model.elementary.dbt_snapshots", "model.elementary.dbt_sources", "model.elementary.dbt_tests"]','','dbt_artifacts_hashes','elementary','models/edr/dbt_artifacts/dbt_artifacts_hashes.sql','edr/dbt_artifacts/dbt_artifacts_hashes.sql','2023-04-20 23:02:23','c11fe71d307067d4412509b15de1ed21'),('model.elementary.dbt_run_results','dbt_run_results','ecee798e20623bd3fe0d1822356a14c63f8a99e251ccf1aff743b0b3759c548d','incremental','[]','{"timestamp_column": "generated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_run_results_empty_table_query"]','[]','Run results of dbt invocations, inserted at the end of each invocation. Each row is the invocation result of a single resource (model, test, snapshot, etc). New data is loaded to this model on an on-run-end hook named \'elementary.upload_run_results\' from each invocation that produces a result object. This is an incremental model.\n','dbt_run_results','elementary','models/edr/dbt_artifacts/dbt_run_results.sql','edr/dbt_artifacts/dbt_run_results.sql','2023-04-20 23:02:23','2bff3e8c2c1d0e9f67b04bb75ea7007e'),('model.elementary.dbt_exposures','dbt_exposures','8a682af36a6af01c41098c007da5b2fbe040cc282350e2817269b1b20b0f0e36','incremental','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.get_config_var", "macro.elementary.get_dbt_exposures_empty_table_query", "macro.elementary.upload_dbt_exposures"]','[]','Metadata about exposures in the project, including configuration and properties from the dbt graph. Each row contains information about a single exposure. Data is loaded every time this model is executed. It is recommended to execute the model every time a change is merged to the project.\n','dbt_exposures','elementary','models/edr/dbt_artifacts/dbt_exposures.sql','edr/dbt_artifacts/dbt_exposures.sql','2023-04-20 23:02:23','3db9239b91b8669ccd9a93cdc10b8901'),('model.elementary.metrics_anomaly_score','metrics_anomaly_score','abfd27ad29f3a4da67885dfd0c82ed98c043958f705c4258175db6c306d0795e','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.dbt_utils.group_by", "macro.elementary.edr_current_timestamp", "macro.elementary.edr_date_trunc", "macro.elementary.edr_timeadd", "macro.elementary.get_config_var"]','["model.elementary.data_monitoring_metrics"]','This is a view on `data_monitoring_metrics` that runs the same query the anomaly detection tests run to calculate anomaly scores. The purpose of this view is to provide visibility to the results of anomaly detection tests.\n','metrics_anomaly_score','elementary','models/edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','edr/data_monitoring/anomaly_detection/metrics_anomaly_score.sql','2023-04-20 23:02:23','40815ab8a31b1886c8776436d0eeb6be'),('model.elementary.anomaly_threshold_sensitivity','anomaly_threshold_sensitivity','193ea3f501e775b7e3865e489edfff8936fed64d1f9063393292082e8a69d005','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.edr_quote_column"]','["model.elementary.metrics_anomaly_score"]','This is a view on `metrics_anomaly_score` that calculates if values of metrics from latest runs would have been considered anomalies in different anomaly scores. This can help you decide if there is a need to adjust the `anomaly_score_threshold`.\n','anomaly_threshold_sensitivity','elementary','models/edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','edr/data_monitoring/anomaly_detection/anomaly_threshold_sensitivity.sql','2023-04-20 23:02:23','19252671a087e268e34e867f994c44ba'),('model.elementary.schema_columns_snapshot','schema_columns_snapshot','4026dd4e8a55d4d5811bdb27cd4214398607ed24bc5b3940ee40dbb4b42a4f2f','incremental','[]','{"timestamp_column": "detected_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_schema_columns_snapshot", "macro.elementary.get_config_var"]','[]','Stores the schema details for tables that are monitored with elementary schema changes test. In order to compare current schema to previous state, we must store the previous state. The data is from a view that queries the data warehouse information schema. This is an incremental table.\n','schema_columns_snapshot','elementary','models/edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','edr/data_monitoring/schema_changes/schema_columns_snapshot.sql','2023-04-20 23:02:23','85e17bc2cee1e746f638449c1f9c0dce'),('model.elementary.data_monitoring_metrics','data_monitoring_metrics','4654d1519d81eca2b622d05e7fd6a0c85fea9126025078173a6b99ff3418bbd2','incremental','[]','{"timestamp_column": "updated_at"}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_data_monitoring_metrics", "macro.elementary.get_config_var"]','[]','Elementary anomaly detection tests monitor metrics such as volume, freshness and data quality metrics. This incremental table is used to store the metrics over time. On each anomaly detection test, the test queries this table for historical metrics, and compares to the latest values. The table is updated with new metrics on the on-run-end named handle_test_results that is executed at the end of dbt test invocations.\n','data_monitoring_metrics','elementary','models/edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','edr/data_monitoring/data_monitoring/data_monitoring_metrics.sql','2023-04-20 23:02:23','f04d74fc1abcf2f5ccce035084f09076'),('model.elementary.filtered_information_schema_columns','filtered_information_schema_columns','8b0602cbf990730afd02271c018d6843414aaff35c5d6e191c8711e570178d7b','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_table", "macro.elementary.get_configured_schemas_from_graph"]','[]','Queries the columns view from the information schema of the schemas in the project. This view is generated using an adapter specific macro, as information schema is different between platforms. This is a view to make the work with the information schema more convinient.\n','filtered_information_schema_columns','elementary','models/edr/metadata_store/filtered_information_schema_columns.sql','edr/metadata_store/filtered_information_schema_columns.sql','2023-04-20 23:02:23','7770ea68471155c6ad930fa2c688dcd7'),('model.elementary.filtered_information_schema_tables','filtered_information_schema_tables','89284ddd42994a960605b4f4de200adbdfc7e467e4bebb7d1debefbe8718839d','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','["macro.elementary.empty_table", "macro.elementary.get_configured_schemas_from_graph"]','[]','Queries the tables and schemas views from the information schema of the schemas in the project. This view is generated using an adapter specific macro, as information schema is different between platforms. This is a view to make the work with the information schema more convinient.','filtered_information_schema_tables','elementary','models/edr/metadata_store/filtered_information_schema_tables.sql','edr/metadata_store/filtered_information_schema_tables.sql','2023-04-20 23:02:23','2d8307a460561db81f97c4a08828ee9f'),('model.de_project.final_land_and_property','final_land_and_property','630617aeffb59ffe66475bed6ccc49f56b5c1b14ad0d98b3bf06fdf56b9beeef','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.de_project.land_and_property_transform"]','','final_land_and_property','de_project','models/core/final_land_and_property.sql','core/final_land_and_property.sql','2023-04-20 23:02:23','e00a803282655eab912faaa4afa92cf4'),('model.de_project.land_and_property_transform','land_and_property_transform','705aa5a5fe5a0d2d7e54e62b9cad3c679e12969b56a45015a64b4fe8d843ed80','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["model.de_project.land_and_property_optimized_raw"]','','land_and_property_transform','de_project','models/transform/land_and_property_transform.sql','transform/land_and_property_transform.sql','2023-04-20 23:02:23','77f3e269736e203f5c332cf385ce803b'),('model.de_project.land_and_property_optimized_raw','land_and_property_optimized_raw','0b0a8a2e95020e232cd3ed84bf2551afc5ebdfb1efc67917e581e4eaeec65128','view','[]','{}','[]','dtc-de-383113','de_data_warehouse','[]','["source.de_project.de_data_warehouse.land_and_property_optimized"]','','land_and_property_optimized_raw','de_project','models/raw/land_and_property_optimized_raw.sql','raw/land_and_property_optimized_raw.sql','2023-04-20 23:02:23','51c344cfd702e3e2a83eb973b1a324b4')
  
[0m23:02:26.259847 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Flattening the artifacts.
[0m23:02:26.262661 [debug] [Thread-3 (]: Elementary: [dbt_seeds] Flattened 0 artifacts.
[0m23:02:26.267319 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__tmp_20230420230226264558`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`
        WHERE 1 = 0
    
    );
  
  
[0m23:02:27.931604 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:dc61de03-e63b-4f54-8e99-a4e5090b8d6b&page=queryresults
[0m23:02:27.934821 [debug] [Thread-2 (]: On model.elementary.dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_models"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models__tmp_20230420230223318561`
    );
  
  
[0m23:02:27.996625 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e54cac43-67eb-4b76-a742-4dadd8432d0e&page=queryresults
[0m23:02:28.000576 [debug] [Thread-3 (]: On model.elementary.dbt_seeds: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_seeds"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds__tmp_20230420230226264558`
    );
  
  
[0m23:02:28.070506 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5866bcc0-1434-4ce3-894d-d41bccacb066&page=queryresults
[0m23:02:28.352377 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:28.357547 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.dbt_source_freshness_results"
[0m23:02:28.358410 [debug] [Thread-4 (]: On model.elementary.dbt_source_freshness_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_source_freshness_results"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.source_freshness_execution_id = DBT_INTERNAL_DEST.source_freshness_execution_id
            )

    
    when matched then update set
        `source_freshness_execution_id` = DBT_INTERNAL_SOURCE.`source_freshness_execution_id`,`unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`max_loaded_at` = DBT_INTERNAL_SOURCE.`max_loaded_at`,`snapshotted_at` = DBT_INTERNAL_SOURCE.`snapshotted_at`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`max_loaded_at_time_ago_in_s` = DBT_INTERNAL_SOURCE.`max_loaded_at_time_ago_in_s`,`status` = DBT_INTERNAL_SOURCE.`status`,`error` = DBT_INTERNAL_SOURCE.`error`,`compile_started_at` = DBT_INTERNAL_SOURCE.`compile_started_at`,`compile_completed_at` = DBT_INTERNAL_SOURCE.`compile_completed_at`,`execute_started_at` = DBT_INTERNAL_SOURCE.`execute_started_at`,`execute_completed_at` = DBT_INTERNAL_SOURCE.`execute_completed_at`,`invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`
    

    when not matched then insert
        (`source_freshness_execution_id`, `unique_id`, `max_loaded_at`, `snapshotted_at`, `generated_at`, `max_loaded_at_time_ago_in_s`, `status`, `error`, `compile_started_at`, `compile_completed_at`, `execute_started_at`, `execute_completed_at`, `invocation_id`)
    values
        (`source_freshness_execution_id`, `unique_id`, `max_loaded_at`, `snapshotted_at`, `generated_at`, `max_loaded_at_time_ago_in_s`, `status`, `error`, `compile_started_at`, `compile_completed_at`, `execute_started_at`, `execute_completed_at`, `invocation_id`)


    
[0m23:02:28.849107 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:fbd64b65-0e17-4b3f-b717-ca4ded78c288&page=queryresults
[0m23:02:28.858495 [debug] [Thread-1 (]: Elementary: [dbt_snapshots] Flattening the artifacts.
[0m23:02:28.860906 [debug] [Thread-1 (]: Elementary: [dbt_snapshots] Flattened 0 artifacts.
[0m23:02:28.865888 [debug] [Thread-1 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__tmp_20230420230228862832`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
        WHERE 1 = 0
    
    );
  
  
[0m23:02:29.587166 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:f8695b5c-7ba0-4d8c-a96c-0038c5fbc335&page=queryresults
[0m23:02:29.589798 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_seeds (execute): 2023-04-20 23:02:21.560058 => 2023-04-20 23:02:29.589739
[0m23:02:29.591111 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d3cafd0>]}
[0m23:02:29.591643 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:f397f55f-5fd9-4aea-a0aa-b39fadb7ec3b&page=queryresults
[0m23:02:29.592137 [info ] [Thread-3 (]: 8 of 32 OK created sql incremental model de_data_warehouse.dbt_seeds ........... [[32mMERGE (0.0 rows, 0 processed)[0m in 8.06s]
[0m23:02:29.594210 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_models (execute): 2023-04-20 23:02:18.538384 => 2023-04-20 23:02:29.594066
[0m23:02:29.594710 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_seeds
[0m23:02:29.595927 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cd66650>]}
[0m23:02:29.596633 [debug] [Thread-3 (]: Began running node model.elementary.dbt_sources
[0m23:02:29.597508 [info ] [Thread-3 (]: 11 of 32 START sql incremental model de_data_warehouse.dbt_sources ............. [RUN]
[0m23:02:29.598130 [info ] [Thread-2 (]: 6 of 32 OK created sql incremental model de_data_warehouse.dbt_models .......... [[32mMERGE (0.0 rows, 20.7 KB processed)[0m in 11.10s]
[0m23:02:29.599214 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.dbt_sources'
[0m23:02:29.599614 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_models
[0m23:02:29.600006 [debug] [Thread-3 (]: Began compiling node model.elementary.dbt_sources
[0m23:02:29.600485 [debug] [Thread-2 (]: Began running node model.elementary.dbt_tests
[0m23:02:29.636466 [info ] [Thread-2 (]: 12 of 32 START sql incremental model de_data_warehouse.dbt_tests ............... [RUN]
[0m23:02:29.637828 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.dbt_tests'
[0m23:02:29.638647 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_tests
[0m23:02:29.646305 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.dbt_sources"
[0m23:02:29.680096 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_tests"
[0m23:02:29.680707 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_sources (compile): 2023-04-20 23:02:29.601318 => 2023-04-20 23:02:29.680606
[0m23:02:29.681090 [debug] [Thread-3 (]: Began executing node model.elementary.dbt_sources
[0m23:02:29.689224 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_tests (compile): 2023-04-20 23:02:29.646574 => 2023-04-20 23:02:29.689030
[0m23:02:29.689671 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m23:02:29.690177 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_tests
[0m23:02:29.700014 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:29.754253 [debug] [Thread-2 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as short_name

,
                
        cast('dummy_string' as string) as alias

,
                
        cast('dummy_string' as string) as test_column_name

,
                
        cast('dummy_string' as string) as severity

,
                
        cast('dummy_string' as string) as warn_if

,
                
        cast('dummy_string' as string) as error_if

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_params

,
                
        cast('dummy_string' as string) as test_namespace

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_owners

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_macros

,
                
        cast('this_is_just_a_long_dummy_string' as string) as depends_on_nodes

,
                
        cast('dummy_string' as string) as parent_model_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('dummy_string' as string) as type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:29.755443 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

with empty_table as (
            select
            
                
        cast('dummy_string' as string) as unique_id

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as source_name

,
                
        cast('dummy_string' as string) as name

,
                
        cast('dummy_string' as string) as identifier

,
                
        cast('dummy_string' as string) as loaded_at_field

,
                
        cast('dummy_string' as string) as freshness_warn_after

,
                
        cast('dummy_string' as string) as freshness_error_after

,
                
        cast('this_is_just_a_long_dummy_string' as string) as freshness_filter

,
                
        cast('dummy_string' as string) as relation_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as meta

,
                
        cast('dummy_string' as string) as owner

,
                
        cast('dummy_string' as string) as package_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as original_path

,
                
        cast('dummy_string' as string) as path

,
                
        cast('this_is_just_a_long_dummy_string' as string) as source_description

,
                
        cast('this_is_just_a_long_dummy_string' as string) as description

,
                
        cast('dummy_string' as string) as generated_at

,
                
        cast('dummy_string' as string) as metadata_hash


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:30.125939 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c5f197ba-9091-4129-8f0d-1333fa13775a&page=queryresults
[0m23:02:30.128722 [debug] [Thread-4 (]: Timing info for model.elementary.dbt_source_freshness_results (execute): 2023-04-20 23:02:25.505872 => 2023-04-20 23:02:30.128666
[0m23:02:30.129370 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ce2d8d0>]}
[0m23:02:30.129860 [info ] [Thread-4 (]: 10 of 32 OK created sql incremental model de_data_warehouse.dbt_source_freshness_results  [[32mMERGE (0.0 rows, 0 processed)[0m in 4.71s]
[0m23:02:30.130489 [debug] [Thread-4 (]: Finished running node model.elementary.dbt_source_freshness_results
[0m23:02:30.130845 [debug] [Thread-4 (]: Began running node model.elementary.elementary_test_results
[0m23:02:30.131114 [info ] [Thread-4 (]: 13 of 32 START sql incremental model de_data_warehouse.elementary_test_results . [RUN]
[0m23:02:30.132016 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.elementary_test_results'
[0m23:02:30.132449 [debug] [Thread-4 (]: Began compiling node model.elementary.elementary_test_results
[0m23:02:30.176697 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.elementary_test_results"
[0m23:02:30.178503 [debug] [Thread-4 (]: Timing info for model.elementary.elementary_test_results (compile): 2023-04-20 23:02:30.132700 => 2023-04-20 23:02:30.178190
[0m23:02:30.179451 [debug] [Thread-4 (]: Began executing node model.elementary.elementary_test_results
[0m23:02:30.186648 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:30.234483 [debug] [Thread-4 (]: On model.elementary.elementary_test_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.elementary_test_results"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      


    with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as id

,
                
        cast('dummy_string' as string) as data_issue_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_execution_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_unique_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as model_unique_id

,
                
        cast('dummy_string' as string) as invocation_id

,
                cast('2091-02-17' as TIMESTAMP) as detected_at

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as test_type

,
                
        cast('dummy_string' as string) as test_sub_type

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_results_description

,
                
        cast('dummy_string' as string) as owners

,
                
        cast('dummy_string' as string) as tags

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_results_query

,
                
        cast('dummy_string' as string) as other

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_name

,
                
        cast('this_is_just_a_long_dummy_string' as string) as test_params

,
                
        cast('dummy_string' as string) as severity

,
                
        cast('dummy_string' as string) as status

,
                
        cast(31474836478 as bigint) as failures

,
                
        cast('dummy_string' as string) as test_short_name

,
                
        cast('dummy_string' as string) as test_alias

,
                
        cast('this_is_just_a_long_dummy_string' as string) as result_rows


            )
        select * from empty_table
        where 1 = 0

    );
  
[0m23:02:30.945676 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:2ffd3ff4-5852-4e39-9cea-9579e415de69&page=queryresults
[0m23:02:30.950475 [debug] [Thread-1 (]: On model.elementary.dbt_snapshots: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_snapshots"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots__tmp_20230420230228862832`
    );
  
  
[0m23:02:32.535611 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:e781f45a-baac-4cc7-a21d-4a1d8a918dc0&page=queryresults
[0m23:02:32.650633 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:74d96614-6fe3-4cd3-b7ce-bdd99bde05c7&page=queryresults
[0m23:02:32.662846 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c6fbdd59-e5cd-487e-9652-3d53b016debb&page=queryresults
[0m23:02:32.667307 [debug] [Thread-1 (]: Timing info for model.elementary.dbt_snapshots (execute): 2023-04-20 23:02:22.587079 => 2023-04-20 23:02:32.667177
[0m23:02:32.669964 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d295390>]}
[0m23:02:32.670586 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:0177d7cd-32e3-45da-9629-8a7bf3ab8fa8&page=queryresults
[0m23:02:32.671081 [info ] [Thread-1 (]: 9 of 32 OK created sql incremental model de_data_warehouse.dbt_snapshots ....... [[32mMERGE (0.0 rows, 0 processed)[0m in 10.11s]
[0m23:02:32.673480 [debug] [Thread-1 (]: Finished running node model.elementary.dbt_snapshots
[0m23:02:32.675265 [debug] [Thread-1 (]: Began running node model.elementary.filtered_information_schema_columns
[0m23:02:32.676665 [info ] [Thread-1 (]: 14 of 32 START sql view model de_data_warehouse.filtered_information_schema_columns  [RUN]
[0m23:02:32.678073 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.filtered_information_schema_columns'
[0m23:02:32.678855 [debug] [Thread-1 (]: Began compiling node model.elementary.filtered_information_schema_columns
[0m23:02:32.708618 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.filtered_information_schema_columns"
[0m23:02:32.709274 [debug] [Thread-1 (]: Timing info for model.elementary.filtered_information_schema_columns (compile): 2023-04-20 23:02:32.679247 => 2023-04-20 23:02:32.709204
[0m23:02:32.709643 [debug] [Thread-1 (]: Began executing node model.elementary.filtered_information_schema_columns
[0m23:02:32.717825 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.filtered_information_schema_columns"
[0m23:02:32.718902 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:32.767738 [debug] [Thread-1 (]: On model.elementary.filtered_information_schema_columns: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.filtered_information_schema_columns"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`filtered_information_schema_columns`
  OPTIONS()
  as 



with filtered_information_schema_columns as (
        with empty_table as (
            select
            
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as data_type


            )
        select * from empty_table
        where 1 = 0

)

select *
from filtered_information_schema_columns
where full_table_name is not null;


[0m23:02:32.791274 [debug] [Thread-2 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:32.794408 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_tests"
[0m23:02:32.795245 [debug] [Thread-2 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_tests` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`name` = DBT_INTERNAL_SOURCE.`name`,`short_name` = DBT_INTERNAL_SOURCE.`short_name`,`alias` = DBT_INTERNAL_SOURCE.`alias`,`test_column_name` = DBT_INTERNAL_SOURCE.`test_column_name`,`severity` = DBT_INTERNAL_SOURCE.`severity`,`warn_if` = DBT_INTERNAL_SOURCE.`warn_if`,`error_if` = DBT_INTERNAL_SOURCE.`error_if`,`test_params` = DBT_INTERNAL_SOURCE.`test_params`,`test_namespace` = DBT_INTERNAL_SOURCE.`test_namespace`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`model_tags` = DBT_INTERNAL_SOURCE.`model_tags`,`model_owners` = DBT_INTERNAL_SOURCE.`model_owners`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`depends_on_macros` = DBT_INTERNAL_SOURCE.`depends_on_macros`,`depends_on_nodes` = DBT_INTERNAL_SOURCE.`depends_on_nodes`,`parent_model_unique_id` = DBT_INTERNAL_SOURCE.`parent_model_unique_id`,`description` = DBT_INTERNAL_SOURCE.`description`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`type` = DBT_INTERNAL_SOURCE.`type`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `database_name`, `schema_name`, `name`, `short_name`, `alias`, `test_column_name`, `severity`, `warn_if`, `error_if`, `test_params`, `test_namespace`, `tags`, `model_tags`, `model_owners`, `meta`, `depends_on_macros`, `depends_on_nodes`, `parent_model_unique_id`, `description`, `package_name`, `type`, `original_path`, `path`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `database_name`, `schema_name`, `name`, `short_name`, `alias`, `test_column_name`, `severity`, `warn_if`, `error_if`, `test_params`, `test_namespace`, `tags`, `model_tags`, `model_owners`, `meta`, `depends_on_macros`, `depends_on_nodes`, `parent_model_unique_id`, `description`, `package_name`, `type`, `original_path`, `path`, `generated_at`, `metadata_hash`)


    
[0m23:02:33.048062 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:33.052291 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.elementary_test_results"
[0m23:02:33.053171 [debug] [Thread-4 (]: On model.elementary.elementary_test_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.elementary_test_results"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.id = DBT_INTERNAL_DEST.id
            )

    
    when matched then update set
        `id` = DBT_INTERNAL_SOURCE.`id`,`data_issue_id` = DBT_INTERNAL_SOURCE.`data_issue_id`,`test_execution_id` = DBT_INTERNAL_SOURCE.`test_execution_id`,`test_unique_id` = DBT_INTERNAL_SOURCE.`test_unique_id`,`model_unique_id` = DBT_INTERNAL_SOURCE.`model_unique_id`,`invocation_id` = DBT_INTERNAL_SOURCE.`invocation_id`,`detected_at` = DBT_INTERNAL_SOURCE.`detected_at`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`table_name` = DBT_INTERNAL_SOURCE.`table_name`,`column_name` = DBT_INTERNAL_SOURCE.`column_name`,`test_type` = DBT_INTERNAL_SOURCE.`test_type`,`test_sub_type` = DBT_INTERNAL_SOURCE.`test_sub_type`,`test_results_description` = DBT_INTERNAL_SOURCE.`test_results_description`,`owners` = DBT_INTERNAL_SOURCE.`owners`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`test_results_query` = DBT_INTERNAL_SOURCE.`test_results_query`,`other` = DBT_INTERNAL_SOURCE.`other`,`test_name` = DBT_INTERNAL_SOURCE.`test_name`,`test_params` = DBT_INTERNAL_SOURCE.`test_params`,`severity` = DBT_INTERNAL_SOURCE.`severity`,`status` = DBT_INTERNAL_SOURCE.`status`,`failures` = DBT_INTERNAL_SOURCE.`failures`,`test_short_name` = DBT_INTERNAL_SOURCE.`test_short_name`,`test_alias` = DBT_INTERNAL_SOURCE.`test_alias`,`result_rows` = DBT_INTERNAL_SOURCE.`result_rows`
    

    when not matched then insert
        (`id`, `data_issue_id`, `test_execution_id`, `test_unique_id`, `model_unique_id`, `invocation_id`, `detected_at`, `database_name`, `schema_name`, `table_name`, `column_name`, `test_type`, `test_sub_type`, `test_results_description`, `owners`, `tags`, `test_results_query`, `other`, `test_name`, `test_params`, `severity`, `status`, `failures`, `test_short_name`, `test_alias`, `result_rows`)
    values
        (`id`, `data_issue_id`, `test_execution_id`, `test_unique_id`, `model_unique_id`, `invocation_id`, `detected_at`, `database_name`, `schema_name`, `table_name`, `column_name`, `test_type`, `test_sub_type`, `test_results_description`, `owners`, `tags`, `test_results_query`, `other`, `test_name`, `test_params`, `severity`, `status`, `failures`, `test_short_name`, `test_alias`, `result_rows`)


    
[0m23:02:33.238954 [debug] [Thread-3 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:33.243041 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.dbt_sources"
[0m23:02:33.244001 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`dbt_sources` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.unique_id = DBT_INTERNAL_DEST.unique_id
            )

    
    when matched then update set
        `unique_id` = DBT_INTERNAL_SOURCE.`unique_id`,`database_name` = DBT_INTERNAL_SOURCE.`database_name`,`schema_name` = DBT_INTERNAL_SOURCE.`schema_name`,`source_name` = DBT_INTERNAL_SOURCE.`source_name`,`name` = DBT_INTERNAL_SOURCE.`name`,`identifier` = DBT_INTERNAL_SOURCE.`identifier`,`loaded_at_field` = DBT_INTERNAL_SOURCE.`loaded_at_field`,`freshness_warn_after` = DBT_INTERNAL_SOURCE.`freshness_warn_after`,`freshness_error_after` = DBT_INTERNAL_SOURCE.`freshness_error_after`,`freshness_filter` = DBT_INTERNAL_SOURCE.`freshness_filter`,`relation_name` = DBT_INTERNAL_SOURCE.`relation_name`,`tags` = DBT_INTERNAL_SOURCE.`tags`,`meta` = DBT_INTERNAL_SOURCE.`meta`,`owner` = DBT_INTERNAL_SOURCE.`owner`,`package_name` = DBT_INTERNAL_SOURCE.`package_name`,`original_path` = DBT_INTERNAL_SOURCE.`original_path`,`path` = DBT_INTERNAL_SOURCE.`path`,`source_description` = DBT_INTERNAL_SOURCE.`source_description`,`description` = DBT_INTERNAL_SOURCE.`description`,`generated_at` = DBT_INTERNAL_SOURCE.`generated_at`,`metadata_hash` = DBT_INTERNAL_SOURCE.`metadata_hash`
    

    when not matched then insert
        (`unique_id`, `database_name`, `schema_name`, `source_name`, `name`, `identifier`, `loaded_at_field`, `freshness_warn_after`, `freshness_error_after`, `freshness_filter`, `relation_name`, `tags`, `meta`, `owner`, `package_name`, `original_path`, `path`, `source_description`, `description`, `generated_at`, `metadata_hash`)
    values
        (`unique_id`, `database_name`, `schema_name`, `source_name`, `name`, `identifier`, `loaded_at_field`, `freshness_warn_after`, `freshness_error_after`, `freshness_filter`, `relation_name`, `tags`, `meta`, `owner`, `package_name`, `original_path`, `path`, `source_description`, `description`, `generated_at`, `metadata_hash`)


    
[0m23:02:34.308441 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:c61376a6-40ae-48ae-b4d2-7e876a4fe369&page=queryresults
[0m23:02:34.317447 [debug] [Thread-2 (]: Elementary: [dbt_tests] Flattening the artifacts.
[0m23:02:34.319478 [debug] [Thread-2 (]: Elementary: [dbt_tests] Flattened 0 artifacts.
[0m23:02:34.327421 [debug] [Thread-2 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__tmp_20230420230234322191`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
        WHERE 1 = 0
    
    );
  
  
[0m23:02:34.482344 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ae41c068-611e-4e0a-986b-b6ada8798321&page=queryresults
[0m23:02:34.486780 [debug] [Thread-1 (]: Timing info for model.elementary.filtered_information_schema_columns (execute): 2023-04-20 23:02:32.709860 => 2023-04-20 23:02:34.486723
[0m23:02:34.488175 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cfe5b10>]}
[0m23:02:34.488995 [info ] [Thread-1 (]: 14 of 32 OK created sql view model de_data_warehouse.filtered_information_schema_columns  [[32mCREATE VIEW (0 processed)[0m in 1.81s]
[0m23:02:34.489804 [debug] [Thread-1 (]: Finished running node model.elementary.filtered_information_schema_columns
[0m23:02:34.490510 [debug] [Thread-1 (]: Began running node model.elementary.filtered_information_schema_tables
[0m23:02:34.491056 [info ] [Thread-1 (]: 15 of 32 START sql view model de_data_warehouse.filtered_information_schema_tables  [RUN]
[0m23:02:34.492116 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.filtered_information_schema_tables'
[0m23:02:34.492680 [debug] [Thread-1 (]: Began compiling node model.elementary.filtered_information_schema_tables
[0m23:02:34.511444 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.filtered_information_schema_tables"
[0m23:02:34.512328 [debug] [Thread-1 (]: Timing info for model.elementary.filtered_information_schema_tables (compile): 2023-04-20 23:02:34.493081 => 2023-04-20 23:02:34.512218
[0m23:02:34.512762 [debug] [Thread-1 (]: Began executing node model.elementary.filtered_information_schema_tables
[0m23:02:34.522845 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.filtered_information_schema_tables"
[0m23:02:34.524183 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:34.625868 [debug] [Thread-1 (]: On model.elementary.filtered_information_schema_tables: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.filtered_information_schema_tables"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`filtered_information_schema_tables`
  OPTIONS()
  as 



with filtered_information_schema_tables as (
        with empty_table as (
            select
            
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as full_schema_name

,
                
        cast('dummy_string' as string) as database_name

,
                
        cast('dummy_string' as string) as schema_name

,
                
        cast('dummy_string' as string) as table_name


            )
        select * from empty_table
        where 1 = 0

)

select *
from filtered_information_schema_tables
where schema_name is not null;


[0m23:02:35.255048 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b8d74473-a66e-46f9-9b27-62d4f112c12d&page=queryresults
[0m23:02:35.262026 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ef7b5a4f-28f2-4c2d-93f2-8118651fa75d&page=queryresults
[0m23:02:35.270136 [debug] [Thread-3 (]: Elementary: [dbt_sources] Flattening the artifacts.
[0m23:02:35.272350 [debug] [Thread-4 (]: Timing info for model.elementary.elementary_test_results (execute): 2023-04-20 23:02:30.179868 => 2023-04-20 23:02:35.272297
[0m23:02:35.279524 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11ce2e090>]}
[0m23:02:35.280319 [info ] [Thread-4 (]: 13 of 32 OK created sql incremental model de_data_warehouse.elementary_test_results  [[32mMERGE (0.0 rows, 0 processed)[0m in 5.15s]
[0m23:02:35.287331 [debug] [Thread-4 (]: Finished running node model.elementary.elementary_test_results
[0m23:02:35.293047 [debug] [Thread-3 (]: Elementary: [dbt_sources] Flattened 1 artifacts.
[0m23:02:35.293734 [debug] [Thread-4 (]: Began running node model.elementary.metadata
[0m23:02:35.304698 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420230235297064`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      
        SELECT
        
            *
        
        FROM `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
        WHERE 1 = 0
    
    );
  
  
[0m23:02:35.305263 [info ] [Thread-4 (]: 16 of 32 START sql table model de_data_warehouse.metadata ...................... [RUN]
[0m23:02:35.307231 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.metadata'
[0m23:02:35.307714 [debug] [Thread-4 (]: Began compiling node model.elementary.metadata
[0m23:02:35.322832 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.metadata"
[0m23:02:35.328117 [debug] [Thread-4 (]: Timing info for model.elementary.metadata (compile): 2023-04-20 23:02:35.308058 => 2023-04-20 23:02:35.327985
[0m23:02:35.328596 [debug] [Thread-4 (]: Began executing node model.elementary.metadata
[0m23:02:35.348690 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:35.792273 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:3795686f-ef62-43da-9082-8e599c20674e&page=queryresults
[0m23:02:35.796388 [debug] [Thread-2 (]: On model.elementary.dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_tests"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests__tmp_20230420230234322191`
    );
  
  
[0m23:02:35.914617 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b48423c6-39fe-46e5-9523-192b5605b746&page=queryresults
[0m23:02:35.918158 [debug] [Thread-1 (]: Timing info for model.elementary.filtered_information_schema_tables (execute): 2023-04-20 23:02:34.512968 => 2023-04-20 23:02:35.918094
[0m23:02:35.918879 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1daa50>]}
[0m23:02:35.919504 [info ] [Thread-1 (]: 15 of 32 OK created sql view model de_data_warehouse.filtered_information_schema_tables  [[32mCREATE VIEW (0 processed)[0m in 1.43s]
[0m23:02:35.919952 [debug] [Thread-1 (]: Finished running node model.elementary.filtered_information_schema_tables
[0m23:02:35.920485 [debug] [Thread-1 (]: Began running node model.elementary.schema_columns_snapshot
[0m23:02:35.921194 [info ] [Thread-1 (]: 17 of 32 START sql incremental model de_data_warehouse.schema_columns_snapshot . [RUN]
[0m23:02:35.923021 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.schema_columns_snapshot'
[0m23:02:35.923805 [debug] [Thread-1 (]: Began compiling node model.elementary.schema_columns_snapshot
[0m23:02:35.947986 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.schema_columns_snapshot"
[0m23:02:35.955821 [debug] [Thread-1 (]: Timing info for model.elementary.schema_columns_snapshot (compile): 2023-04-20 23:02:35.924229 => 2023-04-20 23:02:35.955668
[0m23:02:35.956238 [debug] [Thread-1 (]: Began executing node model.elementary.schema_columns_snapshot
[0m23:02:35.960919 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:36.193923 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.metadata"
[0m23:02:36.195481 [debug] [Thread-4 (]: On model.elementary.metadata: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.metadata"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`metadata`
    
    
    OPTIONS()
    as (
      

SELECT
    '0.7.5' as dbt_pkg_version
    );
  
[0m23:02:36.869594 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.schema_columns_snapshot"
[0m23:02:36.870488 [debug] [Thread-1 (]: On model.elementary.schema_columns_snapshot: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.schema_columns_snapshot"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`schema_columns_snapshot` as DBT_INTERNAL_DEST
        using (


    with empty_table as (
            select
            
                
        cast('dummy_string' as string) as column_state_id

,
                
        cast('dummy_string' as string) as full_column_name

,
                
        cast('dummy_string' as string) as full_table_name

,
                
        cast('dummy_string' as string) as column_name

,
                
        cast('dummy_string' as string) as data_type

,
                
        cast (True as BOOL) as is_new

,
                cast('2091-02-17' as TIMESTAMP) as detected_at


            )
        select * from empty_table
        where 1 = 0

        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.column_state_id = DBT_INTERNAL_DEST.column_state_id
            )

    
    when matched then update set
        `column_state_id` = DBT_INTERNAL_SOURCE.`column_state_id`,`full_column_name` = DBT_INTERNAL_SOURCE.`full_column_name`,`full_table_name` = DBT_INTERNAL_SOURCE.`full_table_name`,`column_name` = DBT_INTERNAL_SOURCE.`column_name`,`data_type` = DBT_INTERNAL_SOURCE.`data_type`,`is_new` = DBT_INTERNAL_SOURCE.`is_new`,`detected_at` = DBT_INTERNAL_SOURCE.`detected_at`
    

    when not matched then insert
        (`column_state_id`, `full_column_name`, `full_table_name`, `column_name`, `data_type`, `is_new`, `detected_at`)
    values
        (`column_state_id`, `full_column_name`, `full_table_name`, `column_name`, `data_type`, `is_new`, `detected_at`)


    
[0m23:02:37.629513 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ba3d1f5a-7d4f-42bc-a1fa-26439c9b7500&page=queryresults
[0m23:02:37.634377 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_tests (execute): 2023-04-20 23:02:29.690856 => 2023-04-20 23:02:37.634298
[0m23:02:37.635614 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11cdcc710>]}
[0m23:02:37.636869 [info ] [Thread-2 (]: 12 of 32 OK created sql incremental model de_data_warehouse.dbt_tests .......... [[32mMERGE (0.0 rows, 0 processed)[0m in 8.00s]
[0m23:02:37.638720 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_tests
[0m23:02:37.639853 [debug] [Thread-2 (]: Began running node model.de_project.land_and_property_transform
[0m23:02:37.640876 [info ] [Thread-2 (]: 18 of 32 START sql view model de_data_warehouse.land_and_property_transform .... [RUN]
[0m23:02:37.642036 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.de_project.land_and_property_transform'
[0m23:02:37.642565 [debug] [Thread-2 (]: Began compiling node model.de_project.land_and_property_transform
[0m23:02:37.656018 [debug] [Thread-2 (]: Writing injected SQL for node "model.de_project.land_and_property_transform"
[0m23:02:37.659474 [debug] [Thread-2 (]: Timing info for model.de_project.land_and_property_transform (compile): 2023-04-20 23:02:37.642956 => 2023-04-20 23:02:37.659364
[0m23:02:37.659817 [debug] [Thread-2 (]: Began executing node model.de_project.land_and_property_transform
[0m23:02:37.667449 [debug] [Thread-2 (]: Writing runtime sql for node "model.de_project.land_and_property_transform"
[0m23:02:37.668168 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:37.718128 [debug] [Thread-2 (]: On model.de_project.land_and_property_transform: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.land_and_property_transform"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`land_and_property_transform`
  OPTIONS()
  as with source AS (

    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`

),

renamed as (
    select
        `Account_Customer` AS customer,
        `FR`,
        `DFL`,
        `TP`,
        `DLG`,
        `OS_W_`,
        `OS_NPW_`,
        `OS_P_`,
        `OS_NPP_`,
        `SIMS`,
        `OC1`,
        `OC2`,
        `date_added`

    from source
)
select * from renamed;


[0m23:02:37.877372 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ce2f4208-bfee-4214-b84b-e53beed1bf4b&page=queryresults
[0m23:02:37.880862 [debug] [Thread-4 (]: Timing info for model.elementary.metadata (execute): 2023-04-20 23:02:35.329240 => 2023-04-20 23:02:37.880775
[0m23:02:37.882004 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d3a6510>]}
[0m23:02:37.882826 [info ] [Thread-4 (]: 16 of 32 OK created sql table model de_data_warehouse.metadata ................. [[32mCREATE TABLE (1.0 rows, 0 processed)[0m in 2.57s]
[0m23:02:37.883810 [debug] [Thread-4 (]: Finished running node model.elementary.metadata
[0m23:02:37.884698 [debug] [Thread-4 (]: Began running node model.elementary.metrics_anomaly_score
[0m23:02:37.885811 [info ] [Thread-4 (]: 19 of 32 START sql view model de_data_warehouse.metrics_anomaly_score .......... [RUN]
[0m23:02:37.887005 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.metrics_anomaly_score'
[0m23:02:37.887563 [debug] [Thread-4 (]: Began compiling node model.elementary.metrics_anomaly_score
[0m23:02:37.927154 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.metrics_anomaly_score"
[0m23:02:37.931997 [debug] [Thread-4 (]: Timing info for model.elementary.metrics_anomaly_score (compile): 2023-04-20 23:02:37.887833 => 2023-04-20 23:02:37.931854
[0m23:02:37.932497 [debug] [Thread-4 (]: Began executing node model.elementary.metrics_anomaly_score
[0m23:02:37.938648 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.metrics_anomaly_score"
[0m23:02:37.939653 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:37.990469 [debug] [Thread-4 (]: On model.elementary.metrics_anomaly_score: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.metrics_anomaly_score"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`
  OPTIONS()
  as 

with data_monitoring_metrics as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`

),

time_window_aggregation as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        metric_value,
        source_value,
        bucket_start,
        bucket_end,
        bucket_duration_hours,
        updated_at,
        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,
        stddev(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,
        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,
        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,
        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start
    from data_monitoring_metrics
    group by 1,2,3,4,5,6,7,8,9,10,11,12
),

metrics_anomaly_score as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        case
            when training_stddev is null then null
            when training_stddev = 0 then 0
            else (metric_value - training_avg) / (training_stddev)
        end as anomaly_score,
        metric_value as latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        max(updated_at) as updated_at
    from time_window_aggregation
        where
            metric_value is not null
            and training_avg is not null
            and training_set_size >= 14
            and bucket_end >= 
       timestamp_add(cast(
    timestamp_trunc(cast(current_timestamp as timestamp), day)
 as TIMESTAMP), INTERVAL cast(-7 as INT64) day)

    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15
    order by bucket_end desc


),

final as (

    select
        id,
        full_table_name,
        column_name,
        dimension,
        dimension_value,
        metric_name,
        anomaly_score,
        latest_metric_value,
        bucket_start,
        bucket_end,
        training_avg,
        training_stddev,
        training_start,
        training_end,
        training_set_size,
        updated_at,
        case
            when abs(anomaly_score) > 3 then true
            else false end
        as is_anomaly
    from metrics_anomaly_score
)

select * from final;


[0m23:02:38.688900 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:2fb38aa3-726a-4248-a893-a24b5597b5d4&page=queryresults
[0m23:02:38.817035 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8826c620-2cda-4350-a891-fbd0b4973ae4&page=queryresults
[0m23:02:38.821330 [debug] [Thread-2 (]: Timing info for model.de_project.land_and_property_transform (execute): 2023-04-20 23:02:37.659991 => 2023-04-20 23:02:38.821144
[0m23:02:38.824223 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d5a6910>]}
[0m23:02:38.824928 [info ] [Thread-2 (]: 18 of 32 OK created sql view model de_data_warehouse.land_and_property_transform  [[32mCREATE VIEW (0 processed)[0m in 1.18s]
[0m23:02:38.826031 [debug] [Thread-2 (]: Finished running node model.de_project.land_and_property_transform
[0m23:02:38.828036 [debug] [Thread-2 (]: Began running node model.elementary.monitors_runs
[0m23:02:38.830314 [info ] [Thread-2 (]: 20 of 32 START sql view model de_data_warehouse.monitors_runs .................. [RUN]
[0m23:02:38.831841 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.monitors_runs'
[0m23:02:38.835359 [debug] [Thread-3 (]: Elementary: Inserting 1 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420230235297064`
[0m23:02:38.836407 [debug] [Thread-2 (]: Began compiling node model.elementary.monitors_runs
[0m23:02:38.871424 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.monitors_runs"
[0m23:02:38.875907 [debug] [Thread-3 (]: Elementary: [1/1] Running insert query.
[0m23:02:38.878170 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420230235297064`
         (unique_id,database_name,schema_name,source_name,name,identifier,loaded_at_field,freshness_warn_after,freshness_error_after,freshness_filter,relation_name,tags,meta,owner,package_name,original_path,path,source_description,description,generated_at,metadata_hash) values
    ('source.de_project.de_data_warehouse.land_and_property_optimized','dtc-de-383113','de_data_warehouse','de_data_warehouse','land_and_property_optimized','land_and_property_optimized',NULL,'{"count": null, "period": null}','{"count": null, "period": null}',NULL,'`dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized`','[]','{}',NULL,'de_project','models/raw/sources.yml','models/raw/sources.yml','','','2023-04-20 23:02:35','fc4865e15760a1575b8bb1dab7c24692')
  
[0m23:02:38.881385 [debug] [Thread-2 (]: Timing info for model.elementary.monitors_runs (compile): 2023-04-20 23:02:38.867422 => 2023-04-20 23:02:38.881036
[0m23:02:38.883609 [debug] [Thread-2 (]: Began executing node model.elementary.monitors_runs
[0m23:02:38.896125 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.monitors_runs"
[0m23:02:38.896846 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:38.953386 [debug] [Thread-2 (]: On model.elementary.monitors_runs: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.monitors_runs"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`monitors_runs`
  OPTIONS()
  as 

with data_monitoring_metrics as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`

),

max_bucket_end as (

    select full_table_name,
           column_name,
           metric_name,
           metric_properties,
           max(bucket_end) as last_bucket_end,
           min(bucket_end) as first_bucket_end
    from data_monitoring_metrics
    group by 1,2,3,4

)

select * from max_bucket_end;


[0m23:02:39.056474 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ef1834cc-6310-47be-b0da-0a59edf48a58&page=queryresults
[0m23:02:39.061297 [debug] [Thread-1 (]: Timing info for model.elementary.schema_columns_snapshot (execute): 2023-04-20 23:02:35.956421 => 2023-04-20 23:02:39.061226
[0m23:02:39.062454 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1f77d0>]}
[0m23:02:39.063465 [info ] [Thread-1 (]: 17 of 32 OK created sql incremental model de_data_warehouse.schema_columns_snapshot  [[32mMERGE (0.0 rows, 0 processed)[0m in 3.14s]
[0m23:02:39.065777 [debug] [Thread-1 (]: Finished running node model.elementary.schema_columns_snapshot
[0m23:02:39.066451 [debug] [Thread-1 (]: Began running node model.elementary.job_run_results
[0m23:02:39.067046 [info ] [Thread-1 (]: 21 of 32 START sql view model de_data_warehouse.job_run_results ................ [RUN]
[0m23:02:39.067831 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.job_run_results'
[0m23:02:39.068168 [debug] [Thread-1 (]: Began compiling node model.elementary.job_run_results
[0m23:02:39.083089 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.job_run_results"
[0m23:02:39.085537 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:2dc263d2-61af-472c-ae3b-994d10e804b3&page=queryresults
[0m23:02:39.089961 [debug] [Thread-4 (]: Timing info for model.elementary.metrics_anomaly_score (execute): 2023-04-20 23:02:37.932956 => 2023-04-20 23:02:39.089874
[0m23:02:39.090973 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d45e910>]}
[0m23:02:39.092113 [info ] [Thread-4 (]: 19 of 32 OK created sql view model de_data_warehouse.metrics_anomaly_score ..... [[32mCREATE VIEW (0 processed)[0m in 1.20s]
[0m23:02:39.092590 [debug] [Thread-1 (]: Timing info for model.elementary.job_run_results (compile): 2023-04-20 23:02:39.068377 => 2023-04-20 23:02:39.092491
[0m23:02:39.093022 [debug] [Thread-4 (]: Finished running node model.elementary.metrics_anomaly_score
[0m23:02:39.093512 [debug] [Thread-1 (]: Began executing node model.elementary.job_run_results
[0m23:02:39.093894 [debug] [Thread-4 (]: Began running node model.elementary.model_run_results
[0m23:02:39.101141 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.job_run_results"
[0m23:02:39.101853 [info ] [Thread-4 (]: 22 of 32 START sql view model de_data_warehouse.model_run_results .............. [RUN]
[0m23:02:39.103477 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.model_run_results'
[0m23:02:39.104135 [debug] [Thread-4 (]: Began compiling node model.elementary.model_run_results
[0m23:02:39.114123 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.model_run_results"
[0m23:02:39.114718 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:39.115518 [debug] [Thread-4 (]: Timing info for model.elementary.model_run_results (compile): 2023-04-20 23:02:39.104653 => 2023-04-20 23:02:39.115441
[0m23:02:39.116010 [debug] [Thread-4 (]: Began executing node model.elementary.model_run_results
[0m23:02:39.121222 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.model_run_results"
[0m23:02:39.122352 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:39.171002 [debug] [Thread-1 (]: On model.elementary.job_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.job_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`job_run_results`
  OPTIONS()
  as 





with jobs as (
  select
    job_name,
    job_id,
    job_run_id,
    
min(cast(run_started_at as TIMESTAMP))
 as job_run_started_at,
    
max(cast(run_completed_at as TIMESTAMP))
 as job_run_completed_at,
    
    timestamp_diff(
max(cast(run_completed_at as TIMESTAMP))
, 
min(cast(run_started_at as TIMESTAMP))
, second)
 as job_run_execution_time
  from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
  where job_id is not null
  group by job_name, job_id, job_run_id
)

select
  job_name as name,
  job_id as id,
  job_run_id as run_id,
  job_run_started_at as run_started_at,
  job_run_completed_at as run_completed_at,
  job_run_execution_time as run_execution_time
from jobs;


[0m23:02:39.172922 [debug] [Thread-4 (]: On model.elementary.model_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.model_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`model_run_results`
  OPTIONS()
  as 

with dbt_run_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
),

dbt_models as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.thread_id,
    models.database_name,
    models.schema_name,
    models.materialization,
    models.tags,
    models.package_name,
    models.path,
    models.original_path,
    models.owner,
    models.alias,
    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,
    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY 
    timestamp_trunc(cast(run_results.generated_at as timestamp), day)
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_first_invocation_of_the_day,
    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY 
    timestamp_trunc(cast(run_results.generated_at as timestamp), day)
 ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id
              THEN TRUE
              ELSE FALSE 
         END                                                               AS is_the_last_invocation_of_the_day
    
FROM dbt_run_results run_results
JOIN dbt_models models ON run_results.unique_id = models.unique_id;


[0m23:02:39.957925 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:a40adb51-b5e9-4916-87fb-878409ca4eff&page=queryresults
[0m23:02:39.963003 [debug] [Thread-2 (]: Timing info for model.elementary.monitors_runs (execute): 2023-04-20 23:02:38.884760 => 2023-04-20 23:02:39.962924
[0m23:02:39.966726 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d512a50>]}
[0m23:02:39.967778 [info ] [Thread-2 (]: 20 of 32 OK created sql view model de_data_warehouse.monitors_runs ............. [[32mCREATE VIEW (0 processed)[0m in 1.14s]
[0m23:02:39.968551 [debug] [Thread-2 (]: Finished running node model.elementary.monitors_runs
[0m23:02:39.968998 [debug] [Thread-2 (]: Began running node model.elementary.snapshot_run_results
[0m23:02:39.969475 [info ] [Thread-2 (]: 23 of 32 START sql view model de_data_warehouse.snapshot_run_results ........... [RUN]
[0m23:02:39.970140 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.snapshot_run_results'
[0m23:02:39.970742 [debug] [Thread-2 (]: Began compiling node model.elementary.snapshot_run_results
[0m23:02:39.979320 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.snapshot_run_results"
[0m23:02:39.980467 [debug] [Thread-2 (]: Timing info for model.elementary.snapshot_run_results (compile): 2023-04-20 23:02:39.971112 => 2023-04-20 23:02:39.980303
[0m23:02:39.981028 [debug] [Thread-2 (]: Began executing node model.elementary.snapshot_run_results
[0m23:02:40.003643 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.snapshot_run_results"
[0m23:02:40.004589 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:40.068165 [debug] [Thread-2 (]: On model.elementary.snapshot_run_results: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.snapshot_run_results"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`
  OPTIONS()
  as 

with dbt_run_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
),

dbt_snapshots as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
)

SELECT
    run_results.model_execution_id,
    run_results.unique_id,
    run_results.invocation_id,
    run_results.query_id,
    run_results.name,
    run_results.generated_at,
    run_results.status,
    run_results.full_refresh,
    run_results.message,
    run_results.execution_time,
    run_results.execute_started_at,
    run_results.execute_completed_at,
    run_results.compile_started_at,
    run_results.compile_completed_at,
    run_results.compiled_code,
    run_results.thread_id,
    snapshots.database_name,
    snapshots.schema_name,
    snapshots.materialization,
    snapshots.tags,
    snapshots.package_name,
    snapshots.path,
    snapshots.original_path,
    snapshots.owner,
    snapshots.alias
FROM dbt_run_results run_results
JOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id;


[0m23:02:40.473497 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:6562b468-ae77-4422-9cd8-e5dbf09e0414&page=queryresults
[0m23:02:40.476857 [debug] [Thread-4 (]: Timing info for model.elementary.model_run_results (execute): 2023-04-20 23:02:39.116243 => 2023-04-20 23:02:40.476803
[0m23:02:40.477658 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d479bd0>]}
[0m23:02:40.478613 [info ] [Thread-4 (]: 22 of 32 OK created sql view model de_data_warehouse.model_run_results ......... [[32mCREATE VIEW (0 processed)[0m in 1.37s]
[0m23:02:40.479489 [debug] [Thread-4 (]: Finished running node model.elementary.model_run_results
[0m23:02:40.480581 [debug] [Thread-4 (]: Began running node model.elementary.alerts_anomaly_detection
[0m23:02:40.481422 [info ] [Thread-4 (]: 24 of 32 START sql view model de_data_warehouse.alerts_anomaly_detection ....... [RUN]
[0m23:02:40.482796 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.alerts_anomaly_detection'
[0m23:02:40.483398 [debug] [Thread-4 (]: Began compiling node model.elementary.alerts_anomaly_detection
[0m23:02:40.494601 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.alerts_anomaly_detection"
[0m23:02:40.500091 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:981581be-5dee-48cb-8d27-c5aeac81d488&page=queryresults
[0m23:02:40.504146 [debug] [Thread-1 (]: Timing info for model.elementary.job_run_results (execute): 2023-04-20 23:02:39.094230 => 2023-04-20 23:02:40.504043
[0m23:02:40.505503 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d5a6ad0>]}
[0m23:02:40.506266 [info ] [Thread-1 (]: 21 of 32 OK created sql view model de_data_warehouse.job_run_results ........... [[32mCREATE VIEW (0 processed)[0m in 1.44s]
[0m23:02:40.507489 [debug] [Thread-1 (]: Finished running node model.elementary.job_run_results
[0m23:02:40.514429 [debug] [Thread-1 (]: Began running node model.elementary.alerts_dbt_tests
[0m23:02:40.515187 [info ] [Thread-1 (]: 25 of 32 START sql view model de_data_warehouse.alerts_dbt_tests ............... [RUN]
[0m23:02:40.516517 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_tests'
[0m23:02:40.516952 [debug] [Thread-1 (]: Began compiling node model.elementary.alerts_dbt_tests
[0m23:02:40.560024 [debug] [Thread-4 (]: Timing info for model.elementary.alerts_anomaly_detection (compile): 2023-04-20 23:02:40.483640 => 2023-04-20 23:02:40.544683
[0m23:02:40.560484 [debug] [Thread-4 (]: Began executing node model.elementary.alerts_anomaly_detection
[0m23:02:40.565984 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.alerts_anomaly_detection"
[0m23:02:40.569728 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:40.579736 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.alerts_dbt_tests"
[0m23:02:40.581007 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_dbt_tests (compile): 2023-04-20 23:02:40.517133 => 2023-04-20 23:02:40.580880
[0m23:02:40.581738 [debug] [Thread-1 (]: Began executing node model.elementary.alerts_dbt_tests
[0m23:02:40.596783 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.alerts_dbt_tests"
[0m23:02:40.597780 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:40.654021 [debug] [Thread-4 (]: On model.elementary.alerts_anomaly_detection: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_anomaly_detection"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_anomaly_detection`
  OPTIONS()
  as 

with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_anomaly_detection as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'anomaly_detection'
)

select * from alerts_anomaly_detection;


[0m23:02:40.672369 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_tests: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_tests"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_tests`
  OPTIONS()
  as 

with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_dbt_tests as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'dbt_test'
)

select * from alerts_dbt_tests;


[0m23:02:40.774574 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:d878ecf9-30a7-4e3d-be44-bb25740812bf&page=queryresults
[0m23:02:40.779245 [debug] [Thread-3 (]: On model.elementary.dbt_sources: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_sources"} */

    
  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
    
    
    OPTIONS()
    as (
      select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources__tmp_20230420230235297064`
    );
  
  
[0m23:02:41.434667 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:1a1d2c1e-738a-4b9b-b0e9-61e4bf59b2c0&page=queryresults
[0m23:02:41.440478 [debug] [Thread-2 (]: Timing info for model.elementary.snapshot_run_results (execute): 2023-04-20 23:02:39.981243 => 2023-04-20 23:02:41.440420
[0m23:02:41.441604 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d291a50>]}
[0m23:02:41.442910 [info ] [Thread-2 (]: 23 of 32 OK created sql view model de_data_warehouse.snapshot_run_results ...... [[32mCREATE VIEW (0 processed)[0m in 1.47s]
[0m23:02:41.444150 [debug] [Thread-2 (]: Finished running node model.elementary.snapshot_run_results
[0m23:02:41.444731 [debug] [Thread-2 (]: Began running node model.elementary.alerts_schema_changes
[0m23:02:41.445996 [info ] [Thread-2 (]: 26 of 32 START sql view model de_data_warehouse.alerts_schema_changes .......... [RUN]
[0m23:02:41.447473 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.alerts_schema_changes'
[0m23:02:41.448669 [debug] [Thread-2 (]: Began compiling node model.elementary.alerts_schema_changes
[0m23:02:41.467411 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.alerts_schema_changes"
[0m23:02:41.468275 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_schema_changes (compile): 2023-04-20 23:02:41.449040 => 2023-04-20 23:02:41.468146
[0m23:02:41.468637 [debug] [Thread-2 (]: Began executing node model.elementary.alerts_schema_changes
[0m23:02:41.779646 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.alerts_schema_changes"
[0m23:02:41.781708 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:f73fc9f9-bc1d-442d-b0d1-171fc14f2df3&page=queryresults
[0m23:02:41.783166 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:ec9bf32b-af95-444c-8f87-66a1eb926328&page=queryresults
[0m23:02:41.787002 [debug] [Thread-4 (]: Timing info for model.elementary.alerts_anomaly_detection (execute): 2023-04-20 23:02:40.560698 => 2023-04-20 23:02:41.786941
[0m23:02:41.789026 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_dbt_tests (execute): 2023-04-20 23:02:40.582480 => 2023-04-20 23:02:41.788980
[0m23:02:41.789286 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:41.789866 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d752e10>]}
[0m23:02:41.790378 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d626990>]}
[0m23:02:41.790946 [info ] [Thread-4 (]: 24 of 32 OK created sql view model de_data_warehouse.alerts_anomaly_detection .. [[32mCREATE VIEW (0 processed)[0m in 1.31s]
[0m23:02:41.791738 [info ] [Thread-1 (]: 25 of 32 OK created sql view model de_data_warehouse.alerts_dbt_tests .......... [[32mCREATE VIEW (0 processed)[0m in 1.27s]
[0m23:02:41.792368 [debug] [Thread-4 (]: Finished running node model.elementary.alerts_anomaly_detection
[0m23:02:41.792707 [debug] [Thread-1 (]: Finished running node model.elementary.alerts_dbt_tests
[0m23:02:41.793053 [debug] [Thread-4 (]: Began running node model.elementary.test_result_rows
[0m23:02:41.793573 [debug] [Thread-1 (]: Began running node model.de_project.final_land_and_property
[0m23:02:41.793967 [info ] [Thread-4 (]: 27 of 32 START sql incremental model de_data_warehouse.test_result_rows ........ [RUN]
[0m23:02:41.794561 [info ] [Thread-1 (]: 28 of 32 START sql view model de_data_warehouse.final_land_and_property ........ [RUN]
[0m23:02:41.795753 [debug] [Thread-4 (]: Acquiring new bigquery connection 'model.elementary.test_result_rows'
[0m23:02:41.796898 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.de_project.final_land_and_property'
[0m23:02:41.797789 [debug] [Thread-4 (]: Began compiling node model.elementary.test_result_rows
[0m23:02:41.798337 [debug] [Thread-1 (]: Began compiling node model.de_project.final_land_and_property
[0m23:02:41.810059 [debug] [Thread-4 (]: Writing injected SQL for node "model.elementary.test_result_rows"
[0m23:02:41.815117 [debug] [Thread-1 (]: Writing injected SQL for node "model.de_project.final_land_and_property"
[0m23:02:41.816766 [debug] [Thread-1 (]: Timing info for model.de_project.final_land_and_property (compile): 2023-04-20 23:02:41.810472 => 2023-04-20 23:02:41.816637
[0m23:02:41.817145 [debug] [Thread-4 (]: Timing info for model.elementary.test_result_rows (compile): 2023-04-20 23:02:41.798859 => 2023-04-20 23:02:41.817048
[0m23:02:41.818018 [debug] [Thread-1 (]: Began executing node model.de_project.final_land_and_property
[0m23:02:41.819162 [debug] [Thread-4 (]: Began executing node model.elementary.test_result_rows
[0m23:02:41.823330 [debug] [Thread-1 (]: Writing runtime sql for node "model.de_project.final_land_and_property"
[0m23:02:41.832448 [debug] [Thread-4 (]: Opening a new connection, currently in state closed
[0m23:02:41.833158 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:41.848478 [debug] [Thread-2 (]: On model.elementary.alerts_schema_changes: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_schema_changes"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_schema_changes`
  OPTIONS()
  as 


with elementary_test_results as (
    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
),

alerts_schema_changes as (
    select id as alert_id,
           data_issue_id,
           test_execution_id,
           test_unique_id,
           model_unique_id,
           detected_at,
           database_name,
           schema_name,
           table_name,
           column_name,
           test_type as alert_type,
           test_sub_type as sub_type,
           test_results_description as alert_description,
           owners,
           tags,
           test_results_query as alert_results_query,
           other,
           test_name,
           test_short_name,
           test_params,
           severity,
           status,
           result_rows
        from elementary_test_results
        where True and lower(status) != 'pass'and lower(status) != 'skipped'and test_type = 'schema_change'
)

select * from alerts_schema_changes;


[0m23:02:41.886158 [debug] [Thread-1 (]: On model.de_project.final_land_and_property: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.de_project.final_land_and_property"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`final_land_and_property`
  OPTIONS()
  as with source as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_transform`

)
SELECT
*
FROM source;


[0m23:02:41.886761 [debug] [Thread-4 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.test_result_rows"} */

  
    

    create or replace table `dtc-de-383113`.`de_data_warehouse`.`test_result_rows__dbt_tmp`
    
    
    OPTIONS(
      expiration_timestamp=TIMESTAMP_ADD(CURRENT_TIMESTAMP(), INTERVAL 12 hour)
    )
    as (
      

-- depends_on: `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`
with empty_table as (
            select
            
                
        cast('this_is_just_a_long_dummy_string' as string) as elementary_test_results_id

,
                
        cast('this_is_just_a_long_dummy_string' as string) as result_row

,
                cast('2091-02-17' as TIMESTAMP) as detected_at


            )
        select * from empty_table
        where 1 = 0
    );
  
[0m23:02:42.675603 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:5f9f0a2f-6d4b-4e46-b13e-af619071a63e&page=queryresults
[0m23:02:42.683967 [debug] [Thread-3 (]: Timing info for model.elementary.dbt_sources (execute): 2023-04-20 23:02:29.681428 => 2023-04-20 23:02:42.683884
[0m23:02:42.685904 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d45e6d0>]}
[0m23:02:43.264338 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:eaef1366-b2f6-44a6-83b0-1880cfa35af5&page=queryresults
[0m23:02:43.267527 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_schema_changes (execute): 2023-04-20 23:02:41.468794 => 2023-04-20 23:02:43.267473
[0m23:02:43.268214 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d627150>]}
[0m23:02:43.271039 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:8bec1bec-8cad-4388-bc16-d70596d7e6e4&page=queryresults
[0m23:02:43.272914 [debug] [Thread-1 (]: Timing info for model.de_project.final_land_and_property (execute): 2023-04-20 23:02:41.819836 => 2023-04-20 23:02:43.272864
[0m23:02:43.273580 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d624e50>]}
[0m23:02:43.918298 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:303c13c5-5d22-4953-9ab6-59e3b71f9f7e&page=queryresults
[0m23:02:44.109624 [info ] [Thread-3 (]: 11 of 32 OK created sql incremental model de_data_warehouse.dbt_sources ........ [[32mMERGE (0.0 rows, 436.0 Bytes processed)[0m in 13.09s]
[0m23:02:44.110621 [info ] [Thread-2 (]: 26 of 32 OK created sql view model de_data_warehouse.alerts_schema_changes ..... [[32mCREATE VIEW (0 processed)[0m in 1.82s]
[0m23:02:44.111558 [info ] [Thread-1 (]: 28 of 32 OK created sql view model de_data_warehouse.final_land_and_property ... [[32mCREATE VIEW (0 processed)[0m in 1.48s]
[0m23:02:44.113630 [debug] [Thread-3 (]: Finished running node model.elementary.dbt_sources
[0m23:02:44.114364 [debug] [Thread-2 (]: Finished running node model.elementary.alerts_schema_changes
[0m23:02:44.114994 [debug] [Thread-1 (]: Finished running node model.de_project.final_land_and_property
[0m23:02:44.115612 [debug] [Thread-3 (]: Began running node model.elementary.anomaly_threshold_sensitivity
[0m23:02:44.116456 [debug] [Thread-2 (]: Began running node model.elementary.alerts_dbt_models
[0m23:02:44.117045 [debug] [Thread-1 (]: Began running node model.elementary.alerts_dbt_source_freshness
[0m23:02:44.117628 [info ] [Thread-3 (]: 29 of 32 START sql view model de_data_warehouse.anomaly_threshold_sensitivity .. [RUN]
[0m23:02:44.118219 [info ] [Thread-2 (]: 30 of 32 START sql view model de_data_warehouse.alerts_dbt_models .............. [RUN]
[0m23:02:44.119181 [info ] [Thread-1 (]: 31 of 32 START sql view model de_data_warehouse.alerts_dbt_source_freshness .... [RUN]
[0m23:02:44.120238 [debug] [Thread-3 (]: Acquiring new bigquery connection 'model.elementary.anomaly_threshold_sensitivity'
[0m23:02:44.121085 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_models'
[0m23:02:44.121796 [debug] [Thread-1 (]: Acquiring new bigquery connection 'model.elementary.alerts_dbt_source_freshness'
[0m23:02:44.122143 [debug] [Thread-3 (]: Began compiling node model.elementary.anomaly_threshold_sensitivity
[0m23:02:44.122461 [debug] [Thread-2 (]: Began compiling node model.elementary.alerts_dbt_models
[0m23:02:44.122768 [debug] [Thread-1 (]: Began compiling node model.elementary.alerts_dbt_source_freshness
[0m23:02:44.139708 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.alerts_dbt_models"
[0m23:02:44.150709 [debug] [Thread-1 (]: Writing injected SQL for node "model.elementary.alerts_dbt_source_freshness"
[0m23:02:44.162141 [debug] [Thread-3 (]: Writing injected SQL for node "model.elementary.anomaly_threshold_sensitivity"
[0m23:02:44.163099 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_dbt_models (compile): 2023-04-20 23:02:44.131480 => 2023-04-20 23:02:44.162956
[0m23:02:44.163725 [debug] [Thread-2 (]: Began executing node model.elementary.alerts_dbt_models
[0m23:02:44.171761 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.alerts_dbt_models"
[0m23:02:44.172170 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_dbt_source_freshness (compile): 2023-04-20 23:02:44.141996 => 2023-04-20 23:02:44.172078
[0m23:02:44.172979 [debug] [Thread-3 (]: Timing info for model.elementary.anomaly_threshold_sensitivity (compile): 2023-04-20 23:02:44.123299 => 2023-04-20 23:02:44.172884
[0m23:02:44.173427 [debug] [Thread-1 (]: Began executing node model.elementary.alerts_dbt_source_freshness
[0m23:02:44.173954 [debug] [Thread-3 (]: Began executing node model.elementary.anomaly_threshold_sensitivity
[0m23:02:44.174303 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:44.182420 [debug] [Thread-4 (]: 
    In `dtc-de-383113`.`de_data_warehouse`.`test_result_rows`:
        Schema changed: False
        Source columns not in target: []
        Target columns not in source: []
        New column types: []
  
[0m23:02:44.182980 [debug] [Thread-1 (]: Writing runtime sql for node "model.elementary.alerts_dbt_source_freshness"
[0m23:02:44.188187 [debug] [Thread-3 (]: Writing runtime sql for node "model.elementary.anomaly_threshold_sensitivity"
[0m23:02:44.190581 [debug] [Thread-4 (]: Writing runtime sql for node "model.elementary.test_result_rows"
[0m23:02:44.191585 [debug] [Thread-1 (]: Opening a new connection, currently in state closed
[0m23:02:44.192219 [debug] [Thread-3 (]: Opening a new connection, currently in state closed
[0m23:02:44.193100 [debug] [Thread-4 (]: On model.elementary.test_result_rows: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.test_result_rows"} */
-- back compat for old kwarg name
  
  
        
            
            
        
    

    

    merge into `dtc-de-383113`.`de_data_warehouse`.`test_result_rows` as DBT_INTERNAL_DEST
        using (
        select
        * from `dtc-de-383113`.`de_data_warehouse`.`test_result_rows__dbt_tmp`
        ) as DBT_INTERNAL_SOURCE
        on (
                DBT_INTERNAL_SOURCE.elementary_test_results_id = DBT_INTERNAL_DEST.elementary_test_results_id
            )

    
    when matched then update set
        `elementary_test_results_id` = DBT_INTERNAL_SOURCE.`elementary_test_results_id`,`result_row` = DBT_INTERNAL_SOURCE.`result_row`,`detected_at` = DBT_INTERNAL_SOURCE.`detected_at`
    

    when not matched then insert
        (`elementary_test_results_id`, `result_row`, `detected_at`)
    values
        (`elementary_test_results_id`, `result_row`, `detected_at`)


    
[0m23:02:44.249873 [debug] [Thread-1 (]: On model.elementary.alerts_dbt_source_freshness: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_source_freshness"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_source_freshness`
  OPTIONS()
  as 

with results as (
  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`
),

sources as (
  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
)

select
  results.source_freshness_execution_id as alert_id,
  results.max_loaded_at,
  results.snapshotted_at,
  results.generated_at as detected_at,
  results.max_loaded_at_time_ago_in_s,
  results.status,
  results.error,
  sources.unique_id,
  sources.database_name,
  sources.schema_name,
  sources.source_name,
  sources.identifier,
  sources.freshness_error_after,
  sources.freshness_warn_after,
  sources.freshness_filter,
  sources.tags,
  sources.meta,
  sources.owner,
  sources.package_name,
  sources.path
from results
join sources on results.unique_id = sources.unique_id
where True and lower(status) != 'pass';


[0m23:02:44.251934 [debug] [Thread-2 (]: On model.elementary.alerts_dbt_models: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.alerts_dbt_models"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`alerts_dbt_models`
  OPTIONS()
  as 

with error_models as (
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias 
    from `dtc-de-383113`.`de_data_warehouse`.`model_run_results`
  
    union all
  
    select  model_execution_id,
            unique_id,
            invocation_id,
            name,
            generated_at,
            status,
            full_refresh,
            message,
            execution_time,
            execute_started_at,
            execute_completed_at,
            compile_started_at,
            compile_completed_at,
            compiled_code,
            database_name,
            schema_name,
            materialization,
            tags,
            package_name,
            path,
            original_path,
            owner,
            alias  
  from `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`
)


select model_execution_id as alert_id,
       unique_id,
       generated_at as detected_at,
       database_name,
       materialization,
       path,
       original_path,
       schema_name,
       message,
       owner as owners,
       tags,
       alias,
       status,
       full_refresh
from error_models
where True and lower(status) != 'success'and lower(status) != 'skipped';


[0m23:02:44.253032 [debug] [Thread-3 (]: On model.elementary.anomaly_threshold_sensitivity: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.anomaly_threshold_sensitivity"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`anomaly_threshold_sensitivity`
  OPTIONS()
  as 

with metrics_anomaly_score as (

    select * from `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`

),

score_sensitivity as (

    select
        full_table_name,
        column_name,
        metric_name,
        latest_metric_value,
        training_avg as metric_avg,
        training_stddev as metric_stddev,
        anomaly_score,
        case when abs(anomaly_score) >= 1.5 then true else false end as `is_anomaly_1_5`,
        case when abs(anomaly_score) >= 2 then true else false end as `is_anomaly_2`,
        case when abs(anomaly_score) >= 2.5 then true else false end as `is_anomaly_2_5`,
        case when abs(anomaly_score) >= 3 then true else false end as `is_anomaly_3`,
        case when abs(anomaly_score) >= 3.5 then true else false end as `is_anomaly_3_5`,
        case when abs(anomaly_score) >= 4 then true else false end as `is_anomaly_4`,
        case when abs(anomaly_score) >= 4.5 then true else false end as `is_anomaly_4_5`
    from metrics_anomaly_score
    where abs(anomaly_score) >= 1.5

)

select * from score_sensitivity;


[0m23:02:45.317198 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:04561bf3-21f2-4b72-82ef-b68ee02a59cc&page=queryresults
[0m23:02:45.319614 [debug] [Thread-2 (]: Timing info for model.elementary.alerts_dbt_models (execute): 2023-04-20 23:02:44.163991 => 2023-04-20 23:02:45.319554
[0m23:02:45.320540 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d567090>]}
[0m23:02:45.321090 [info ] [Thread-2 (]: 30 of 32 OK created sql view model de_data_warehouse.alerts_dbt_models ......... [[32mCREATE VIEW (0 processed)[0m in 1.20s]
[0m23:02:45.321532 [debug] [Thread-2 (]: Finished running node model.elementary.alerts_dbt_models
[0m23:02:45.321949 [debug] [Thread-2 (]: Began running node model.elementary.dbt_artifacts_hashes
[0m23:02:45.322500 [info ] [Thread-2 (]: 32 of 32 START sql view model de_data_warehouse.dbt_artifacts_hashes ........... [RUN]
[0m23:02:45.323156 [debug] [Thread-2 (]: Acquiring new bigquery connection 'model.elementary.dbt_artifacts_hashes'
[0m23:02:45.323533 [debug] [Thread-2 (]: Began compiling node model.elementary.dbt_artifacts_hashes
[0m23:02:45.333234 [debug] [Thread-2 (]: Writing injected SQL for node "model.elementary.dbt_artifacts_hashes"
[0m23:02:45.334222 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_artifacts_hashes (compile): 2023-04-20 23:02:45.323685 => 2023-04-20 23:02:45.334122
[0m23:02:45.334714 [debug] [Thread-2 (]: Began executing node model.elementary.dbt_artifacts_hashes
[0m23:02:45.340213 [debug] [Thread-2 (]: Writing runtime sql for node "model.elementary.dbt_artifacts_hashes"
[0m23:02:45.341192 [debug] [Thread-2 (]: Opening a new connection, currently in state closed
[0m23:02:45.356113 [debug] [Thread-1 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:eabc2e9a-901e-4543-82f8-24bb23bb8dba&page=queryresults
[0m23:02:45.359070 [debug] [Thread-1 (]: Timing info for model.elementary.alerts_dbt_source_freshness (execute): 2023-04-20 23:02:44.174465 => 2023-04-20 23:02:45.358996
[0m23:02:45.360227 [debug] [Thread-1 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d1ec3d0>]}
[0m23:02:45.361157 [info ] [Thread-1 (]: 31 of 32 OK created sql view model de_data_warehouse.alerts_dbt_source_freshness  [[32mCREATE VIEW (0 processed)[0m in 1.24s]
[0m23:02:45.362125 [debug] [Thread-1 (]: Finished running node model.elementary.alerts_dbt_source_freshness
[0m23:02:45.390581 [debug] [Thread-3 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:a625d996-7dbb-4efa-9f43-7d9a0f77b13c&page=queryresults
[0m23:02:45.394799 [debug] [Thread-3 (]: Timing info for model.elementary.anomaly_threshold_sensitivity (execute): 2023-04-20 23:02:44.183224 => 2023-04-20 23:02:45.394686
[0m23:02:45.395611 [debug] [Thread-2 (]: On model.elementary.dbt_artifacts_hashes: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "node_id": "model.elementary.dbt_artifacts_hashes"} */


  create or replace view `dtc-de-383113`.`de_data_warehouse`.`dbt_artifacts_hashes`
  OPTIONS()
  as 




select
  'dbt_models' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`
 union all 

select
  'dbt_tests' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`
 union all 

select
  'dbt_sources' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`
 union all 

select
  'dbt_snapshots' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`
 union all 

select
  'dbt_metrics' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`
 union all 

select
  'dbt_exposures' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`
 union all 

select
  'dbt_seeds' as artifacts_model,
   metadata_hash
from `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`


order by metadata_hash;


[0m23:02:45.396917 [debug] [Thread-3 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x10422f8d0>]}
[0m23:02:45.398892 [info ] [Thread-3 (]: 29 of 32 OK created sql view model de_data_warehouse.anomaly_threshold_sensitivity  [[32mCREATE VIEW (0 processed)[0m in 1.28s]
[0m23:02:45.399625 [debug] [Thread-3 (]: Finished running node model.elementary.anomaly_threshold_sensitivity
[0m23:02:45.847221 [debug] [Thread-4 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:89ddbe8c-63a0-4778-b850-595a22d38771&page=queryresults
[0m23:02:45.872316 [debug] [Thread-4 (]: Timing info for model.elementary.test_result_rows (execute): 2023-04-20 23:02:41.823785 => 2023-04-20 23:02:45.872237
[0m23:02:45.873013 [debug] [Thread-4 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d5f2c10>]}
[0m23:02:45.873505 [info ] [Thread-4 (]: 27 of 32 OK created sql incremental model de_data_warehouse.test_result_rows ... [[32mMERGE (0.0 rows, 0 processed)[0m in 4.08s]
[0m23:02:45.873996 [debug] [Thread-4 (]: Finished running node model.elementary.test_result_rows
[0m23:02:46.777895 [debug] [Thread-2 (]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:a7d576b4-3e47-4e04-9527-a178396e818f&page=queryresults
[0m23:02:46.781561 [debug] [Thread-2 (]: Timing info for model.elementary.dbt_artifacts_hashes (execute): 2023-04-20 23:02:45.335029 => 2023-04-20 23:02:46.781437
[0m23:02:46.782815 [debug] [Thread-2 (]: Sending event: {'category': 'dbt', 'action': 'run_model', 'label': '2e1b5e67-9716-41f4-a7ef-021ca13b4f2e', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d02e910>]}
[0m23:02:46.783417 [info ] [Thread-2 (]: 32 of 32 OK created sql view model de_data_warehouse.dbt_artifacts_hashes ...... [[32mCREATE VIEW (0 processed)[0m in 1.46s]
[0m23:02:46.783928 [debug] [Thread-2 (]: Finished running node model.elementary.dbt_artifacts_hashes
[0m23:02:46.786107 [debug] [MainThread]: Acquiring new bigquery connection 'master'
[0m23:02:46.786510 [info ] [MainThread]: 
[0m23:02:46.787038 [info ] [MainThread]: Running 1 on-run-end hook
[0m23:02:46.826930 [debug] [MainThread]: Opening a new connection, currently in state closed
[0m23:02:46.881283 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
    select artifacts_model, metadata_hash from `dtc-de-383113`.`de_data_warehouse`.`dbt_artifacts_hashes`
    order by metadata_hash
    
  
[0m23:02:48.246173 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:b805ad57-a98d-4c96-8839-320bfd667d5e&page=queryresults
[0m23:02:48.247319 [debug] [MainThread]: Elementary: Uploading dbt artifacts.
[0m23:02:48.252598 [debug] [MainThread]: Elementary: [dbt_models] Artifacts already ran.
[0m23:02:48.254391 [debug] [MainThread]: Elementary: [dbt_tests] Artifacts already ran.
[0m23:02:48.256218 [debug] [MainThread]: Elementary: [dbt_sources] Artifacts already ran.
[0m23:02:48.258679 [debug] [MainThread]: Elementary: [dbt_snapshots] Artifacts already ran.
[0m23:02:48.260408 [debug] [MainThread]: Elementary: [dbt_metrics] Artifacts already ran.
[0m23:02:48.262043 [debug] [MainThread]: Elementary: [dbt_exposures] Artifacts already ran.
[0m23:02:48.263750 [debug] [MainThread]: Elementary: [dbt_seeds] Artifacts already ran.
[0m23:02:48.271169 [debug] [MainThread]: Elementary: Uploading run results.
[0m23:02:48.274576 [debug] [MainThread]: Elementary: [dbt_run_results] Flattening the artifacts.
[0m23:02:48.436989 [debug] [MainThread]: Elementary: [dbt_run_results] Flattened 32 artifacts.
[0m23:02:48.770280 [debug] [MainThread]: Elementary: Inserting 32 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
[0m23:02:49.266631 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:02:49.268528 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`
         (model_execution_id,unique_id,invocation_id,generated_at,name,message,status,resource_type,execution_time,execute_started_at,execute_completed_at,compile_started_at,compile_completed_at,rows_affected,full_refresh,compiled_code,failures,query_id,thread_id) values
    ('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.de_project.land_and_property_optimized_raw','model.de_project.land_and_property_optimized_raw','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','land_and_property_optimized_raw','CREATE VIEW (0 processed)','success','model',1.4416871070861816,'2023-04-20T23:02:12.360108Z','2023-04-20T23:02:13.666867Z','2023-04-20T23:02:12.229191Z','2023-04-20T23:02:12.330152Z',NULL,False,'with source as (\n      select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized`\n)\nselect * from source',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.data_monitoring_metrics','model.elementary.data_monitoring_metrics','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','data_monitoring_metrics','MERGE (0.0 rows, 0 processed)','success','model',6.262212753295898,'2023-04-20T23:02:12.398932Z','2023-04-20T23:02:18.488368Z','2023-04-20T23:02:12.232842Z','2023-04-20T23:02:12.359430Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as id\n\n,\n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as metric_name\n\n,\n                \n        cast(123456789.99 as FLOAT64) as metric_value\n\n,\n                \n        cast(\'dummy_string\' as string) as source_value\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as bucket_start\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as bucket_end\n\n,\n                \n        cast(123456789 as INT64) as bucket_duration_hours\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as updated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as dimension\n\n,\n                \n        cast(\'dummy_string\' as string) as dimension_value\n\n,\n                \n        cast(\'dummy_string\' as string) as metric_properties\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_invocations','model.elementary.dbt_invocations','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_invocations','MERGE (0.0 rows, 416.0 Bytes processed)','success','model',8.331990957260132,'2023-04-20T23:02:12.472705Z','2023-04-20T23:02:20.559464Z','2023-04-20T23:02:12.323765Z','2023-04-20T23:02:12.379836Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as invocation_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as job_run_id\n\n,\n                \n        cast(\'dummy_string\' as string) as run_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as run_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as command\n\n,\n                \n        cast(\'dummy_string\' as string) as dbt_version\n\n,\n                \n        cast(\'dummy_string\' as string) as elementary_version\n\n,\n                \n        cast (True as BOOL) as full_refresh\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as invocation_vars\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as vars\n\n,\n                \n        cast(\'dummy_string\' as string) as target_name\n\n,\n                \n        cast(\'dummy_string\' as string) as target_database\n\n,\n                \n        cast(\'dummy_string\' as string) as target_schema\n\n,\n                \n        cast(\'dummy_string\' as string) as target_profile_name\n\n,\n                \n        cast(123456789 as INT64) as threads\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as selected\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as yaml_selector\n\n,\n                \n        cast(\'dummy_string\' as string) as project_id\n\n,\n                \n        cast(\'dummy_string\' as string) as project_name\n\n,\n                \n        cast(\'dummy_string\' as string) as env\n\n,\n                \n        cast(\'dummy_string\' as string) as env_id\n\n,\n                \n        cast(\'dummy_string\' as string) as cause_category\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as cause\n\n,\n                \n        cast(\'dummy_string\' as string) as pull_request_id\n\n,\n                \n        cast(\'dummy_string\' as string) as git_sha\n\n,\n                \n        cast(\'dummy_string\' as string) as orchestrator\n\n,\n                \n        cast(\'dummy_string\' as string) as dbt_user\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_exposures','model.elementary.dbt_exposures','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_exposures','MERGE (0.0 rows, 0 processed)','success','model',9.293116092681885,'2023-04-20T23:02:12.447586Z','2023-04-20T23:02:21.517164Z','2023-04-20T23:02:12.250054Z','2023-04-20T23:02:12.359817Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as maturity\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'dummy_string\' as string) as owner_email\n\n,\n                \n        cast(\'dummy_string\' as string) as owner_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as url\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-3 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_metrics','model.elementary.dbt_metrics','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_metrics','MERGE (0.0 rows, 0 processed)','success','model',8.887686729431152,'2023-04-20T23:02:13.706609Z','2023-04-20T23:02:22.558641Z','2023-04-20T23:02:13.672464Z','2023-04-20T23:02:13.705387Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as label\n\n,\n                \n        cast(\'dummy_string\' as string) as model\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as sql\n\n,\n                \n        cast(\'dummy_string\' as string) as timestamp\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as filters\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as time_grains\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as dimensions\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_run_results','model.elementary.dbt_run_results','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_run_results','MERGE (0.0 rows, 97.7 KB processed)','success','model',4.850771903991699,'2023-04-20T23:02:20.616801Z','2023-04-20T23:02:25.414488Z','2023-04-20T23:02:20.565474Z','2023-04-20T23:02:20.615752Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_execution_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as message\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(\'dummy_string\' as string) as resource_type\n\n,\n                \n        cast(123456789.99 as FLOAT64) as execution_time\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_completed_at\n\n,\n                \n        cast(31474836478 as bigint) as rows_affected\n\n,\n                \n        cast (True as BOOL) as full_refresh\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as compiled_code\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast(\'dummy_string\' as string) as query_id\n\n,\n                \n        cast(\'dummy_string\' as string) as thread_id\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_seeds','model.elementary.dbt_seeds','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_seeds','MERGE (0.0 rows, 0 processed)','success','model',8.063247919082642,'2023-04-20T23:02:21.560058Z','2023-04-20T23:02:29.589739Z','2023-04-20T23:02:21.531009Z','2023-04-20T23:02:21.559050Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-3 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_models','model.elementary.dbt_models','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_models','MERGE (0.0 rows, 20.7 KB processed)','success','model',11.103865146636963,'2023-04-20T23:02:18.538384Z','2023-04-20T23:02:29.594066Z','2023-04-20T23:02:18.492619Z','2023-04-20T23:02:18.537654Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'dummy_string\' as string) as materialization\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_source_freshness_results','model.elementary.dbt_source_freshness_results','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_source_freshness_results','MERGE (0.0 rows, 0 processed)','success','model',4.709769010543823,'2023-04-20T23:02:25.505872Z','2023-04-20T23:02:30.128666Z','2023-04-20T23:02:25.421025Z','2023-04-20T23:02:25.470861Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as source_freshness_execution_id\n\n,\n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as max_loaded_at\n\n,\n                \n        cast(\'dummy_string\' as string) as snapshotted_at\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(123456789.99 as FLOAT64) as max_loaded_at_time_ago_in_s\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(\'dummy_string\' as string) as error\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as compile_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_started_at\n\n,\n                \n        cast(\'dummy_string\' as string) as execute_completed_at\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_snapshots','model.elementary.dbt_snapshots','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_snapshots','MERGE (0.0 rows, 0 processed)','success','model',10.108137845993042,'2023-04-20T23:02:22.587079Z','2023-04-20T23:02:32.667177Z','2023-04-20T23:02:22.562576Z','2023-04-20T23:02:22.586427Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as checksum\n\n,\n                \n        cast(\'dummy_string\' as string) as materialization\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.filtered_information_schema_columns','model.elementary.filtered_information_schema_columns','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','filtered_information_schema_columns','CREATE VIEW (0 processed)','success','model',1.8103432655334473,'2023-04-20T23:02:32.709860Z','2023-04-20T23:02:34.486723Z','2023-04-20T23:02:32.679247Z','2023-04-20T23:02:32.709204Z',NULL,False,'\n\n\n\nwith filtered_information_schema_columns as (\n        with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as data_type\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n\n)\n\nselect *\nfrom filtered_information_schema_columns\nwhere full_table_name is not null',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.elementary_test_results','model.elementary.elementary_test_results','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','elementary_test_results','MERGE (0.0 rows, 0 processed)','success','model',5.148053169250488,'2023-04-20T23:02:30.179868Z','2023-04-20T23:02:35.272297Z','2023-04-20T23:02:30.132700Z','2023-04-20T23:02:30.178190Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as id\n\n,\n                \n        cast(\'dummy_string\' as string) as data_issue_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_execution_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_unique_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as invocation_id\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as test_type\n\n,\n                \n        cast(\'dummy_string\' as string) as test_sub_type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_results_description\n\n,\n                \n        cast(\'dummy_string\' as string) as owners\n\n,\n                \n        cast(\'dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_results_query\n\n,\n                \n        cast(\'dummy_string\' as string) as other\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_params\n\n,\n                \n        cast(\'dummy_string\' as string) as severity\n\n,\n                \n        cast(\'dummy_string\' as string) as status\n\n,\n                \n        cast(31474836478 as bigint) as failures\n\n,\n                \n        cast(\'dummy_string\' as string) as test_short_name\n\n,\n                \n        cast(\'dummy_string\' as string) as test_alias\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as result_rows\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.filtered_information_schema_tables','model.elementary.filtered_information_schema_tables','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','filtered_information_schema_tables','CREATE VIEW (0 processed)','success','model',1.4272949695587158,'2023-04-20T23:02:34.512968Z','2023-04-20T23:02:35.918094Z','2023-04-20T23:02:34.493081Z','2023-04-20T23:02:34.512218Z',NULL,False,'\n\n\n\nwith filtered_information_schema_tables as (\n        with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as full_schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as table_name\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n\n)\n\nselect *\nfrom filtered_information_schema_tables\nwhere schema_name is not null',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_tests','model.elementary.dbt_tests','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_tests','MERGE (0.0 rows, 0 processed)','success','model',7.998254776000977,'2023-04-20T23:02:29.690856Z','2023-04-20T23:02:37.634298Z','2023-04-20T23:02:29.646574Z','2023-04-20T23:02:29.689030Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as short_name\n\n,\n                \n        cast(\'dummy_string\' as string) as alias\n\n,\n                \n        cast(\'dummy_string\' as string) as test_column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as severity\n\n,\n                \n        cast(\'dummy_string\' as string) as warn_if\n\n,\n                \n        cast(\'dummy_string\' as string) as error_if\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as test_params\n\n,\n                \n        cast(\'dummy_string\' as string) as test_namespace\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as model_owners\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_macros\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as depends_on_nodes\n\n,\n                \n        cast(\'dummy_string\' as string) as parent_model_unique_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'dummy_string\' as string) as type\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.metadata','model.elementary.metadata','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','metadata','CREATE TABLE (1.0 rows, 0 processed)','success','model',2.574979782104492,'2023-04-20T23:02:35.329240Z','2023-04-20T23:02:37.880775Z','2023-04-20T23:02:35.308058Z','2023-04-20T23:02:35.327985Z',1,False,'\n\nSELECT\n    \'0.7.5\' as dbt_pkg_version',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.de_project.land_and_property_transform','model.de_project.land_and_property_transform','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','land_and_property_transform','CREATE VIEW (0 processed)','success','model',1.182603120803833,'2023-04-20T23:02:37.659991Z','2023-04-20T23:02:38.821144Z','2023-04-20T23:02:37.642956Z','2023-04-20T23:02:37.659364Z',NULL,False,'with source AS (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_optimized_raw`\n\n),\n\nrenamed as (\n    select\n        `Account_Customer` AS customer,\n        `FR`,\n        `DFL`,\n        `TP`,\n        `DLG`,\n        `OS_W_`,\n        `OS_NPW_`,\n        `OS_P_`,\n        `OS_NPP_`,\n        `SIMS`,\n        `OC1`,\n        `OC2`,\n        `date_added`\n\n    from source\n)\nselect * from renamed',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.schema_columns_snapshot','model.elementary.schema_columns_snapshot','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','schema_columns_snapshot','MERGE (0.0 rows, 0 processed)','success','model',3.1404049396514893,'2023-04-20T23:02:35.956421Z','2023-04-20T23:02:39.061226Z','2023-04-20T23:02:35.924229Z','2023-04-20T23:02:35.955668Z',0,False,'\n\n\n    with empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as column_state_id\n\n,\n                \n        cast(\'dummy_string\' as string) as full_column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as full_table_name\n\n,\n                \n        cast(\'dummy_string\' as string) as column_name\n\n,\n                \n        cast(\'dummy_string\' as string) as data_type\n\n,\n                \n        cast (True as BOOL) as is_new\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n\n            )\n        select * from empty_table\n        where 1 = 0\n',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.metrics_anomaly_score','model.elementary.metrics_anomaly_score','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','metrics_anomaly_score','CREATE VIEW (0 processed)','success','model',1.2044169902801514,'2023-04-20T23:02:37.932956Z','2023-04-20T23:02:39.089874Z','2023-04-20T23:02:37.887833Z','2023-04-20T23:02:37.931854Z',NULL,False,'\n\nwith data_monitoring_metrics as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`\n\n),\n\ntime_window_aggregation as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        metric_value,\n        source_value,\n        bucket_start,\n        bucket_end,\n        bucket_duration_hours,\n        updated_at,\n        avg(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_avg,\n        stddev(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_stddev,\n        count(metric_value) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_set_size,\n        last_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) training_end,\n        first_value(bucket_end) over (partition by metric_name, full_table_name, column_name order by bucket_start asc rows between unbounded preceding and current row) as training_start\n    from data_monitoring_metrics\n    group by 1,2,3,4,5,6,7,8,9,10,11,12\n),\n\nmetrics_anomaly_score as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        case\n            when training_stddev is null then null\n            when training_stddev = 0 then 0\n            else (metric_value - training_avg) / (training_stddev)\n        end as anomaly_score,\n        metric_value as latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        max(updated_at) as updated_at\n    from time_window_aggregation\n        where\n            metric_value is not null\n            and training_avg is not null\n            and training_set_size >= 14\n            and bucket_end >= \n       timestamp_add(cast(\n    timestamp_trunc(cast(current_timestamp as timestamp), day)\n as TIMESTAMP), INTERVAL cast(-7 as INT64) day)\n\n    group by 1,2,3,4,5,6,7,8,9,10,11,12,13,14,15\n    order by bucket_end desc\n\n\n),\n\nfinal as (\n\n    select\n        id,\n        full_table_name,\n        column_name,\n        dimension,\n        dimension_value,\n        metric_name,\n        anomaly_score,\n        latest_metric_value,\n        bucket_start,\n        bucket_end,\n        training_avg,\n        training_stddev,\n        training_start,\n        training_end,\n        training_set_size,\n        updated_at,\n        case\n            when abs(anomaly_score) > 3 then true\n            else false end\n        as is_anomaly\n    from metrics_anomaly_score\n)\n\nselect * from final',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.monitors_runs','model.elementary.monitors_runs','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','monitors_runs','CREATE VIEW (0 processed)','success','model',1.1354360580444336,'2023-04-20T23:02:38.884760Z','2023-04-20T23:02:39.962924Z','2023-04-20T23:02:38.867422Z','2023-04-20T23:02:38.881036Z',NULL,False,'\n\nwith data_monitoring_metrics as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`data_monitoring_metrics`\n\n),\n\nmax_bucket_end as (\n\n    select full_table_name,\n           column_name,\n           metric_name,\n           metric_properties,\n           max(bucket_end) as last_bucket_end,\n           min(bucket_end) as first_bucket_end\n    from data_monitoring_metrics\n    group by 1,2,3,4\n\n)\n\nselect * from max_bucket_end',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.model_run_results','model.elementary.model_run_results','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','model_run_results','CREATE VIEW (0 processed)','success','model',1.3749260902404785,'2023-04-20T23:02:39.116243Z','2023-04-20T23:02:40.476803Z','2023-04-20T23:02:39.104653Z','2023-04-20T23:02:39.115441Z',NULL,False,'\n\nwith dbt_run_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`\n),\n\ndbt_models as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_models`\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.thread_id,\n    models.database_name,\n    models.schema_name,\n    models.materialization,\n    models.tags,\n    models.package_name,\n    models.path,\n    models.original_path,\n    models.owner,\n    models.alias,\n    ROW_NUMBER() OVER (PARTITION BY run_results.unique_id ORDER BY run_results.generated_at DESC) AS model_invocation_reverse_index,\n    CASE WHEN FIRST_VALUE(invocation_id) OVER (PARTITION BY \n    timestamp_trunc(cast(run_results.generated_at as timestamp), day)\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_first_invocation_of_the_day,\n    CASE WHEN LAST_VALUE(invocation_id) OVER (PARTITION BY \n    timestamp_trunc(cast(run_results.generated_at as timestamp), day)\n ORDER BY run_results.generated_at ASC ROWS BETWEEN UNBOUNDED PRECEDING AND UNBOUNDED FOLLOWING ) = invocation_id\n              THEN TRUE\n              ELSE FALSE \n         END                                                               AS is_the_last_invocation_of_the_day\n    \nFROM dbt_run_results run_results\nJOIN dbt_models models ON run_results.unique_id = models.unique_id',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.job_run_results','model.elementary.job_run_results','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','job_run_results','CREATE VIEW (0 processed)','success','model',1.4379429817199707,'2023-04-20T23:02:39.094230Z','2023-04-20T23:02:40.504043Z','2023-04-20T23:02:39.068377Z','2023-04-20T23:02:39.092491Z',NULL,False,'\n\n\n\n\n\nwith jobs as (\n  select\n    job_name,\n    job_id,\n    job_run_id,\n    \nmin(cast(run_started_at as TIMESTAMP))\n as job_run_started_at,\n    \nmax(cast(run_completed_at as TIMESTAMP))\n as job_run_completed_at,\n    \n    timestamp_diff(\nmax(cast(run_completed_at as TIMESTAMP))\n, \nmin(cast(run_started_at as TIMESTAMP))\n, second)\n as job_run_execution_time\n  from `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`\n  where job_id is not null\n  group by job_name, job_id, job_run_id\n)\n\nselect\n  job_name as name,\n  job_id as id,\n  job_run_id as run_id,\n  job_run_started_at as run_started_at,\n  job_run_completed_at as run_completed_at,\n  job_run_execution_time as run_execution_time\nfrom jobs',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.snapshot_run_results','model.elementary.snapshot_run_results','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','snapshot_run_results','CREATE VIEW (0 processed)','success','model',1.471742868423462,'2023-04-20T23:02:39.981243Z','2023-04-20T23:02:41.440420Z','2023-04-20T23:02:39.971112Z','2023-04-20T23:02:39.980303Z',NULL,False,'\n\nwith dbt_run_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_run_results`\n),\n\ndbt_snapshots as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`\n)\n\nSELECT\n    run_results.model_execution_id,\n    run_results.unique_id,\n    run_results.invocation_id,\n    run_results.query_id,\n    run_results.name,\n    run_results.generated_at,\n    run_results.status,\n    run_results.full_refresh,\n    run_results.message,\n    run_results.execution_time,\n    run_results.execute_started_at,\n    run_results.execute_completed_at,\n    run_results.compile_started_at,\n    run_results.compile_completed_at,\n    run_results.compiled_code,\n    run_results.thread_id,\n    snapshots.database_name,\n    snapshots.schema_name,\n    snapshots.materialization,\n    snapshots.tags,\n    snapshots.package_name,\n    snapshots.path,\n    snapshots.original_path,\n    snapshots.owner,\n    snapshots.alias\nFROM dbt_run_results run_results\nJOIN dbt_snapshots snapshots ON run_results.unique_id = snapshots.unique_id',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.alerts_anomaly_detection','model.elementary.alerts_anomaly_detection','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','alerts_anomaly_detection','CREATE VIEW (0 processed)','success','model',1.3075950145721436,'2023-04-20T23:02:40.560698Z','2023-04-20T23:02:41.786941Z','2023-04-20T23:02:40.483640Z','2023-04-20T23:02:40.544683Z',NULL,False,'\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_anomaly_detection as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'anomaly_detection\'\n)\n\nselect * from alerts_anomaly_detection',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.alerts_dbt_tests','model.elementary.alerts_dbt_tests','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','alerts_dbt_tests','CREATE VIEW (0 processed)','success','model',1.2744479179382324,'2023-04-20T23:02:40.582480Z','2023-04-20T23:02:41.788980Z','2023-04-20T23:02:40.517133Z','2023-04-20T23:02:40.580880Z',NULL,False,'\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_dbt_tests as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'dbt_test\'\n)\n\nselect * from alerts_dbt_tests',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_sources','model.elementary.dbt_sources','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_sources','MERGE (0.0 rows, 436.0 Bytes processed)','success','model',13.0869882106781,'2023-04-20T23:02:29.681428Z','2023-04-20T23:02:42.683884Z','2023-04-20T23:02:29.601318Z','2023-04-20T23:02:29.680606Z',0,False,'\n\nwith empty_table as (\n            select\n            \n                \n        cast(\'dummy_string\' as string) as unique_id\n\n,\n                \n        cast(\'dummy_string\' as string) as database_name\n\n,\n                \n        cast(\'dummy_string\' as string) as schema_name\n\n,\n                \n        cast(\'dummy_string\' as string) as source_name\n\n,\n                \n        cast(\'dummy_string\' as string) as name\n\n,\n                \n        cast(\'dummy_string\' as string) as identifier\n\n,\n                \n        cast(\'dummy_string\' as string) as loaded_at_field\n\n,\n                \n        cast(\'dummy_string\' as string) as freshness_warn_after\n\n,\n                \n        cast(\'dummy_string\' as string) as freshness_error_after\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as freshness_filter\n\n,\n                \n        cast(\'dummy_string\' as string) as relation_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as tags\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as meta\n\n,\n                \n        cast(\'dummy_string\' as string) as owner\n\n,\n                \n        cast(\'dummy_string\' as string) as package_name\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as original_path\n\n,\n                \n        cast(\'dummy_string\' as string) as path\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as source_description\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as description\n\n,\n                \n        cast(\'dummy_string\' as string) as generated_at\n\n,\n                \n        cast(\'dummy_string\' as string) as metadata_hash\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-3 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.alerts_schema_changes','model.elementary.alerts_schema_changes','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','alerts_schema_changes','CREATE VIEW (0 processed)','success','model',1.8216211795806885,'2023-04-20T23:02:41.468794Z','2023-04-20T23:02:43.267473Z','2023-04-20T23:02:41.449040Z','2023-04-20T23:02:41.468146Z',NULL,False,'\n\n\nwith elementary_test_results as (\n    select * from `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\n),\n\nalerts_schema_changes as (\n    select id as alert_id,\n           data_issue_id,\n           test_execution_id,\n           test_unique_id,\n           model_unique_id,\n           detected_at,\n           database_name,\n           schema_name,\n           table_name,\n           column_name,\n           test_type as alert_type,\n           test_sub_type as sub_type,\n           test_results_description as alert_description,\n           owners,\n           tags,\n           test_results_query as alert_results_query,\n           other,\n           test_name,\n           test_short_name,\n           test_params,\n           severity,\n           status,\n           result_rows\n        from elementary_test_results\n        where True and lower(status) != \'pass\'and lower(status) != \'skipped\'and test_type = \'schema_change\'\n)\n\nselect * from alerts_schema_changes',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.de_project.final_land_and_property','model.de_project.final_land_and_property','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','final_land_and_property','CREATE VIEW (0 processed)','success','model',1.4771969318389893,'2023-04-20T23:02:41.819836Z','2023-04-20T23:02:43.272864Z','2023-04-20T23:02:41.810472Z','2023-04-20T23:02:41.816637Z',NULL,False,'with source as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`land_and_property_transform`\n\n)\nSELECT\n*\nFROM source',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.alerts_dbt_models','model.elementary.alerts_dbt_models','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','alerts_dbt_models','CREATE VIEW (0 processed)','success','model',1.1995790004730225,'2023-04-20T23:02:44.163991Z','2023-04-20T23:02:45.319554Z','2023-04-20T23:02:44.131480Z','2023-04-20T23:02:44.162956Z',NULL,False,'\n\nwith error_models as (\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias \n    from `dtc-de-383113`.`de_data_warehouse`.`model_run_results`\n  \n    union all\n  \n    select  model_execution_id,\n            unique_id,\n            invocation_id,\n            name,\n            generated_at,\n            status,\n            full_refresh,\n            message,\n            execution_time,\n            execute_started_at,\n            execute_completed_at,\n            compile_started_at,\n            compile_completed_at,\n            compiled_code,\n            database_name,\n            schema_name,\n            materialization,\n            tags,\n            package_name,\n            path,\n            original_path,\n            owner,\n            alias  \n  from `dtc-de-383113`.`de_data_warehouse`.`snapshot_run_results`\n)\n\n\nselect model_execution_id as alert_id,\n       unique_id,\n       generated_at as detected_at,\n       database_name,\n       materialization,\n       path,\n       original_path,\n       schema_name,\n       message,\n       owner as owners,\n       tags,\n       alias,\n       status,\n       full_refresh\nfrom error_models\nwhere True and lower(status) != \'success\'and lower(status) != \'skipped\'',NULL,NULL,'Thread-2 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.alerts_dbt_source_freshness','model.elementary.alerts_dbt_source_freshness','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','alerts_dbt_source_freshness','CREATE VIEW (0 processed)','success','model',1.2386081218719482,'2023-04-20T23:02:44.174465Z','2023-04-20T23:02:45.358996Z','2023-04-20T23:02:44.141996Z','2023-04-20T23:02:44.172078Z',NULL,False,'\n\nwith results as (\n  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_source_freshness_results`\n),\n\nsources as (\n  select * from `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`\n)\n\nselect\n  results.source_freshness_execution_id as alert_id,\n  results.max_loaded_at,\n  results.snapshotted_at,\n  results.generated_at as detected_at,\n  results.max_loaded_at_time_ago_in_s,\n  results.status,\n  results.error,\n  sources.unique_id,\n  sources.database_name,\n  sources.schema_name,\n  sources.source_name,\n  sources.identifier,\n  sources.freshness_error_after,\n  sources.freshness_warn_after,\n  sources.freshness_filter,\n  sources.tags,\n  sources.meta,\n  sources.owner,\n  sources.package_name,\n  sources.path\nfrom results\njoin sources on results.unique_id = sources.unique_id\nwhere True and lower(status) != \'pass\'',NULL,NULL,'Thread-1 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.anomaly_threshold_sensitivity','model.elementary.anomaly_threshold_sensitivity','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','anomaly_threshold_sensitivity','CREATE VIEW (0 processed)','success','model',1.2770130634307861,'2023-04-20T23:02:44.183224Z','2023-04-20T23:02:45.394686Z','2023-04-20T23:02:44.123299Z','2023-04-20T23:02:44.172884Z',NULL,False,'\n\nwith metrics_anomaly_score as (\n\n    select * from `dtc-de-383113`.`de_data_warehouse`.`metrics_anomaly_score`\n\n),\n\nscore_sensitivity as (\n\n    select\n        full_table_name,\n        column_name,\n        metric_name,\n        latest_metric_value,\n        training_avg as metric_avg,\n        training_stddev as metric_stddev,\n        anomaly_score,\n        case when abs(anomaly_score) >= 1.5 then true else false end as `is_anomaly_1_5`,\n        case when abs(anomaly_score) >= 2 then true else false end as `is_anomaly_2`,\n        case when abs(anomaly_score) >= 2.5 then true else false end as `is_anomaly_2_5`,\n        case when abs(anomaly_score) >= 3 then true else false end as `is_anomaly_3`,\n        case when abs(anomaly_score) >= 3.5 then true else false end as `is_anomaly_3_5`,\n        case when abs(anomaly_score) >= 4 then true else false end as `is_anomaly_4`,\n        case when abs(anomaly_score) >= 4.5 then true else false end as `is_anomaly_4_5`\n    from metrics_anomaly_score\n    where abs(anomaly_score) >= 1.5\n\n)\n\nselect * from score_sensitivity',NULL,NULL,'Thread-3 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.test_result_rows','model.elementary.test_result_rows','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','test_result_rows','MERGE (0.0 rows, 0 processed)','success','model',4.077859163284302,'2023-04-20T23:02:41.823785Z','2023-04-20T23:02:45.872237Z','2023-04-20T23:02:41.798859Z','2023-04-20T23:02:41.817048Z',0,False,'\n\n-- depends_on: `dtc-de-383113`.`de_data_warehouse`.`elementary_test_results`\nwith empty_table as (\n            select\n            \n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as elementary_test_results_id\n\n,\n                \n        cast(\'this_is_just_a_long_dummy_string\' as string) as result_row\n\n,\n                cast(\'2091-02-17\' as TIMESTAMP) as detected_at\n\n\n            )\n        select * from empty_table\n        where 1 = 0',NULL,NULL,'Thread-4 (worker)'),('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e.model.elementary.dbt_artifacts_hashes','model.elementary.dbt_artifacts_hashes','2e1b5e67-9716-41f4-a7ef-021ca13b4f2e','2023-04-20 23:02:48','dbt_artifacts_hashes','CREATE VIEW (0 processed)','success','model',1.4598679542541504,'2023-04-20T23:02:45.335029Z','2023-04-20T23:02:46.781437Z','2023-04-20T23:02:45.323685Z','2023-04-20T23:02:45.334122Z',NULL,False,'\n\n\n\n\nselect\n  \'dbt_models\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_models`\n union all \n\nselect\n  \'dbt_tests\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_tests`\n union all \n\nselect\n  \'dbt_sources\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_sources`\n union all \n\nselect\n  \'dbt_snapshots\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_snapshots`\n union all \n\nselect\n  \'dbt_metrics\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_metrics`\n union all \n\nselect\n  \'dbt_exposures\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_exposures`\n union all \n\nselect\n  \'dbt_seeds\' as artifacts_model,\n   metadata_hash\nfrom `dtc-de-383113`.`de_data_warehouse`.`dbt_seeds`\n\n\norder by metadata_hash',NULL,NULL,'Thread-2 (worker)')
  
[0m23:02:50.994161 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:0d3d8ac5-1fe0-4ddc-9efc-84e308a452f2&page=queryresults
[0m23:02:50.995316 [debug] [MainThread]: Elementary: Uploaded run results successfully.
[0m23:02:51.015961 [debug] [MainThread]: Elementary: Uploading dbt invocation.
[0m23:02:51.587089 [debug] [MainThread]: Elementary: Inserting 1 rows to table `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
[0m23:02:51.624694 [debug] [MainThread]: Elementary: [1/1] Running insert query.
[0m23:02:51.627105 [debug] [MainThread]: On master: /* {"app": "dbt", "dbt_version": "1.4.5", "profile_name": "de_project", "target_name": "dev", "connection_name": "master"} */

    
       insert into `dtc-de-383113`.`de_data_warehouse`.`dbt_invocations`
         (invocation_id,job_id,job_name,job_run_id,run_started_at,run_completed_at,generated_at,command,dbt_version,elementary_version,full_refresh,invocation_vars,vars,target_name,target_database,target_schema,target_profile_name,threads,selected,yaml_selector,project_id,project_name,env,env_id,cause_category,cause,pull_request_id,git_sha,orchestrator,dbt_user) values
    ('2e1b5e67-9716-41f4-a7ef-021ca13b4f2e',NULL,NULL,NULL,'2023-04-20 23:02:08','2023-04-20 23:02:51','2023-04-20 23:02:51','run','1.4.5','0.7.5',False,'{}','{}','dev','dtc-de-383113','de_data_warehouse','de_project',4,'[]','[]',NULL,'de_project',NULL,NULL,NULL,NULL,NULL,NULL,NULL,NULL)
  
[0m23:02:53.091611 [debug] [MainThread]: BigQuery adapter: https://console.cloud.google.com/bigquery?project=dtc-de-383113&j=bq:europe-west6:35081b24-859d-4dca-870c-0bc8569a694b&page=queryresults
[0m23:02:53.092489 [debug] [MainThread]: Elementary: Uploaded dbt invocation successfully.
[0m23:02:53.093637 [debug] [MainThread]: Writing injected SQL for node "operation.elementary.elementary-on-run-end-0"
[0m23:02:53.144017 [info ] [MainThread]: 1 of 1 START hook: elementary.on-run-end.0 ..................................... [RUN]
[0m23:02:53.144682 [info ] [MainThread]: 1 of 1 OK hook: elementary.on-run-end.0 ........................................ [[32mOK[0m in 0.00s]
[0m23:02:53.145706 [info ] [MainThread]: 
[0m23:02:53.146846 [debug] [MainThread]: Connection 'master' was properly closed.
[0m23:02:53.147113 [debug] [MainThread]: Connection 'model.elementary.alerts_dbt_source_freshness' was properly closed.
[0m23:02:53.147284 [debug] [MainThread]: Connection 'model.elementary.dbt_artifacts_hashes' was properly closed.
[0m23:02:53.147684 [debug] [MainThread]: Connection 'model.elementary.anomaly_threshold_sensitivity' was properly closed.
[0m23:02:53.148093 [debug] [MainThread]: Connection 'model.elementary.test_result_rows' was properly closed.
[0m23:02:53.148675 [info ] [MainThread]: 
[0m23:02:53.149378 [info ] [MainThread]: Finished running 17 view models, 14 incremental models, 1 table model, 2 hooks in 0 hours 0 minutes and 42.91 seconds (42.91s).
[0m23:02:53.152693 [debug] [MainThread]: Command end result
[0m23:02:53.182330 [info ] [MainThread]: 
[0m23:02:53.183090 [info ] [MainThread]: [32mCompleted successfully[0m
[0m23:02:53.183998 [info ] [MainThread]: 
[0m23:02:53.184799 [info ] [MainThread]: Done. PASS=32 WARN=0 ERROR=0 SKIP=0 TOTAL=32
[0m23:02:53.185857 [debug] [MainThread]: Sending event: {'category': 'dbt', 'action': 'invocation', 'label': 'end', 'context': [<snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d75a850>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x109458a10>, <snowplow_tracker.self_describing_json.SelfDescribingJson object at 0x11d3cf690>]}
[0m23:02:53.187784 [debug] [MainThread]: Flushing usage events
